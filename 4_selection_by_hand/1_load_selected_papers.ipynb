{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658755ba",
   "metadata": {},
   "source": [
    "# Post-processing papers after selection by hand\n",
    "\n",
    "In this file:\n",
    "1. We load the papers that have been selected by hand\n",
    "2. We load papers from the initial pool\n",
    "3. We merge both pools of papers\n",
    "4. We create a new excel file appropriate to do a classification of all papers as: tool creation/ no tool creation, for AI/not for AI\n",
    "\n",
    "***\n",
    "\n",
    "**Loading libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0694ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ce105",
   "metadata": {},
   "source": [
    "## 1. Load initial pool articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2767b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in initial pool:  25\n"
     ]
    }
   ],
   "source": [
    "_path_ini_pool = os.path.join('initial_pool_articles.csv')\n",
    "\n",
    "cols= ['Key', 'Item Type', 'Publication Year', 'Author', 'Title',\n",
    "       'Publication Title', 'ISBN', 'ISSN', 'DOI', 'Url', 'Abstract Note']\n",
    "df_ini = pd.DataFrame(pd.read_csv(_path_ini_pool, sep=';', usecols=cols))\n",
    "\n",
    "df_ini = df_ini.rename(columns={'Title': 'title'})\n",
    "\n",
    "# add columns with lower case titles with letters only\n",
    "t_list = []\n",
    "for title in df_ini['title'].str.lower():\n",
    "    t_list.append(\" \".join(re.findall(\"[A-Za-z]+\",title)))\n",
    "df_ini = pd.concat([df_ini.copy(deep=True), pd.DataFrame(t_list, columns=[\"title_lower\"])], axis=1)\n",
    "\n",
    "df_ini = df_ini.rename(columns={'Key': 'key'})\n",
    "df_ini = df_ini.rename(columns={'ISBN': 'isbn'})\n",
    "df_ini = df_ini.rename(columns={'ISSN': 'issn'})\n",
    "df_ini = df_ini.rename(columns={'DOI': 'doi'})\n",
    "df_ini = df_ini.rename(columns={'Abstract Note': 'abstract'})\n",
    "df_ini = df_ini.rename(columns={'Publication Title': 'pub_info'})\n",
    "df_ini = df_ini.rename(columns={'Publication Year': 'date'})\n",
    "df_ini = df_ini.rename(columns={'Url': 'link'})\n",
    "df_ini = df_ini.rename(columns={'Author': 'authors'})\n",
    "df_ini = df_ini.rename(columns={'Item Type': 'item_type'})\n",
    "\n",
    "print(\"Number of papers in initial pool: \", df_ini.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca195bc",
   "metadata": {},
   "source": [
    "## 2. Load selected papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44756691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers:  2607\n",
      "Number of selected papers:  146\n"
     ]
    }
   ],
   "source": [
    "_path_selected = os.path.join('../4_selection_by_hand/selection_by_hand_2023_09_13.xlsx')\n",
    "usecols = ['id', 'title', 'link', 'date', 'pub_info', 'data_source', 'keep', 'don_t_know',\n",
    "        #    'discard', 'comments_first_reviewer', 'assessor', 'keep_don_t_know', 'keep_correction', 'comments_second_reviewer', 'keep_title']\n",
    "           'discard', 'comments_first_reviewer', 'assessor', 'keep_don_t_know', 'keep_correction', 'keep_title']\n",
    "df_selected = pd.DataFrame(pd.read_excel(_path_selected, usecols = usecols))\n",
    "\n",
    "df_selected = df_selected[['id', 'title', 'link', 'date', 'pub_info', 'data_source', 'keep', 'don_t_know',\n",
    "        #    'discard', 'comments_first_reviewer', 'assessor', 'keep_don_t_know', 'keep_correction', 'comments_second_reviewer', 'keep_title']]\n",
    "           'discard', 'comments_first_reviewer', 'assessor', 'keep_don_t_know', 'keep_correction', 'keep_title']]\n",
    "\n",
    "# If keep_correction is not empty then we use it to replace the current value of keep_title:\n",
    "for i, row in df_selected.iterrows():\n",
    "    if row['keep_correction']==row['keep_correction']:\n",
    "        df_selected.loc[i, 'keep_title'] = row['keep_correction']\n",
    "\n",
    "all_t_list = []\n",
    "for title in df_selected['title'].str.lower():\n",
    "    all_t_list.append(\" \".join(re.findall(\"[A-Za-z]+\",title)))\n",
    "print(\"Total number of papers: \", len(all_t_list))\n",
    "        \n",
    "df_selected = df_selected[df_selected['keep_title']==1]\n",
    "df_selected = df_selected.reset_index(drop=True)\n",
    "\n",
    "# list of lower case titles (and with letters only):\n",
    "t_list = []\n",
    "for title in df_selected['title'].str.lower():\n",
    "    t_list.append(\" \".join(re.findall(\"[A-Za-z]+\",title)))\n",
    "print(\"Number of selected papers: \", len(t_list))\n",
    "\n",
    "# if we want to add t_list as a new column:\n",
    "# df_selected = pd.concat([df_selected.copy(deep=True), pd.DataFrame(t_list, columns=[\"title_lower\"])],\n",
    "#                         axis=1)\n",
    "\n",
    "# print(\"Number of papers in selected pool: \", df_selected.shape[0])\n",
    "# df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f8fbf",
   "metadata": {},
   "source": [
    "## 3. Merge selected papers and initial pool papers\n",
    "\n",
    "Just to check if the initial titles are in the selected articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053c70d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in:  13\n",
      "not in:  12\n"
     ]
    }
   ],
   "source": [
    "titles_ini = df_ini['title_lower'].values\n",
    "already_in = 0\n",
    "not_in = 0\n",
    "for title in titles_ini:\n",
    "    if title in t_list:\n",
    "#         print(\"In\")\n",
    "#         print(title)\n",
    "        already_in += 1\n",
    "    else:\n",
    "#         print(\"Not in\")\n",
    "#         print(title)\n",
    "        not_in += 1\n",
    "#     print('**************')\n",
    "print(\"already in: \", already_in)\n",
    "print(\"not in: \", not_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019bd2f",
   "metadata": {},
   "source": [
    "Just to check if the initial titles are in the papers list (resulting from the automatic selection) at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f02b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in:  13\n",
      "not in:  12\n"
     ]
    }
   ],
   "source": [
    "titles_ini = df_ini['title_lower'].values\n",
    "already_in = 0\n",
    "not_in = 0\n",
    "for title in titles_ini:\n",
    "    if title in all_t_list:\n",
    "#         print(\"In\")\n",
    "#         print(title)\n",
    "        already_in += 1\n",
    "    else:\n",
    "#         print(\"Not in\")\n",
    "#         print(title)\n",
    "        not_in += 1\n",
    "#     print('**************')\n",
    "print(\"already in: \", already_in)\n",
    "print(\"not in: \", not_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea546775",
   "metadata": {},
   "source": [
    "Check if the initial titles are in the initial search results (before automatic selection): todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c47af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311311c",
   "metadata": {},
   "source": [
    "Adding titles not already in the selected papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a08e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers from initial pool we add:  12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>pub_info</th>\n",
       "      <th>data_source</th>\n",
       "      <th>keep_title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Energy Usage Reports: Environmental awareness ...</td>\n",
       "      <td>http://arxiv.org/abs/1911.08354</td>\n",
       "      <td>2019</td>\n",
       "      <td>Lottick, Kadan; Susai, Silvia; Friedler, Sorel...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy of Computing on Multicore CPUs: Predict...</td>\n",
       "      <td>http://arxiv.org/abs/1907.02805</td>\n",
       "      <td>2021</td>\n",
       "      <td>Shahid, Arsalan; Fahad, Muhammad; Manumachu, R...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Energy Predictive Models of Computing: Theory,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>Shahid, Arsalan; Fahad, Muhammad; Manumachu, R...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy and Policy Considerations for Deep Lear...</td>\n",
       "      <td>https://aclanthology.org/P19-1355</td>\n",
       "      <td>2019</td>\n",
       "      <td>Strubell, Emma; Ganesh, Ananya; McCallum, Andr...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIKWID: A Lightweight Performance-Oriented Too...</td>\n",
       "      <td>https://doi.org/10.1109/ICPPW.2010.38</td>\n",
       "      <td>2010</td>\n",
       "      <td>Treibig, Jan; Hager, Georg; Wellein, Gerhard P...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A first look into the carbon footprint of fede...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/A-first-...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Qiu, Xinchi; Parcollet, Titouan; Beutel, Danie...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PMT: Power Measurement Toolkit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>Corda, Stefano; Veenboer, Bram; Tolley, Emma 2...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUMULATOR — a tool to quantify and report the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>Trébaol, Tristan</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Efficient Execution of Convolutional Neural Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>Rodrigues, Crefeda</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Comparative Study of Methods for Measurement...</td>\n",
       "      <td>https://www.mdpi.com/1996-1073/12/11/2204</td>\n",
       "      <td>2019</td>\n",
       "      <td>Fahad, Muhammad; Shahid, Arsalan; Manumachu, R...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A review of energy measurement approaches</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/2553070.2553077</td>\n",
       "      <td>2013</td>\n",
       "      <td>Noureddine, Adel; Rouvoy, Romain; Seinturier, ...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>An experimental comparison of software-based p...</td>\n",
       "      <td>https://ieeexplore.ieee.org/document/10171575/</td>\n",
       "      <td>2023</td>\n",
       "      <td>Jay, Mathilde; Ostapenco, Vladimir; Lefevre, L...</td>\n",
       "      <td>ini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title   \n",
       "0   Energy Usage Reports: Environmental awareness ...  \\\n",
       "1   Energy of Computing on Multicore CPUs: Predict...   \n",
       "2   Energy Predictive Models of Computing: Theory,...   \n",
       "3   Energy and Policy Considerations for Deep Lear...   \n",
       "4   LIKWID: A Lightweight Performance-Oriented Too...   \n",
       "5   A first look into the carbon footprint of fede...   \n",
       "6                      PMT: Power Measurement Toolkit   \n",
       "7   CUMULATOR — a tool to quantify and report the ...   \n",
       "8   Efficient Execution of Convolutional Neural Ne...   \n",
       "9   A Comparative Study of Methods for Measurement...   \n",
       "10          A review of energy measurement approaches   \n",
       "11  An experimental comparison of software-based p...   \n",
       "\n",
       "                                                 link  date   \n",
       "0                     http://arxiv.org/abs/1911.08354  2019  \\\n",
       "1                     http://arxiv.org/abs/1907.02805  2021   \n",
       "2                                                 NaN  2021   \n",
       "3                   https://aclanthology.org/P19-1355  2019   \n",
       "4               https://doi.org/10.1109/ICPPW.2010.38  2010   \n",
       "5   https://www.semanticscholar.org/paper/A-first-...  2020   \n",
       "6                                                 NaN  2022   \n",
       "7                                                 NaN  2020   \n",
       "8                                                 NaN  2020   \n",
       "9           https://www.mdpi.com/1996-1073/12/11/2204  2019   \n",
       "10     https://dl.acm.org/doi/10.1145/2553070.2553077  2013   \n",
       "11     https://ieeexplore.ieee.org/document/10171575/  2023   \n",
       "\n",
       "                                             pub_info data_source  keep_title   \n",
       "0   Lottick, Kadan; Susai, Silvia; Friedler, Sorel...         ini         1.0  \\\n",
       "1   Shahid, Arsalan; Fahad, Muhammad; Manumachu, R...         ini         1.0   \n",
       "2   Shahid, Arsalan; Fahad, Muhammad; Manumachu, R...         ini         1.0   \n",
       "3   Strubell, Emma; Ganesh, Ananya; McCallum, Andr...         ini         1.0   \n",
       "4   Treibig, Jan; Hager, Georg; Wellein, Gerhard P...         ini         1.0   \n",
       "5   Qiu, Xinchi; Parcollet, Titouan; Beutel, Danie...         ini         1.0   \n",
       "6   Corda, Stefano; Veenboer, Bram; Tolley, Emma 2...         ini         1.0   \n",
       "7                                   Trébaol, Tristan          ini         1.0   \n",
       "8                                 Rodrigues, Crefeda          ini         1.0   \n",
       "9   Fahad, Muhammad; Shahid, Arsalan; Manumachu, R...         ini         1.0   \n",
       "10  Noureddine, Adel; Rouvoy, Romain; Seinturier, ...         ini         1.0   \n",
       "11  Jay, Mathilde; Ostapenco, Vladimir; Lefevre, L...         ini         1.0   \n",
       "\n",
       "      id  \n",
       "0   2661  \n",
       "1   2662  \n",
       "2   2663  \n",
       "3   2664  \n",
       "4   2665  \n",
       "5   2666  \n",
       "6   2667  \n",
       "7   2668  \n",
       "8   2669  \n",
       "9   2670  \n",
       "10  2671  \n",
       "11  2672  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in df_ini.iterrows():\n",
    "    # rewrite the pub_info column to contain authors and document title info:\n",
    "    tmp1 = row['authors'] if row['authors'] == row['authors'] else \"\"\n",
    "    tmp2 = row['pub_info'] if row['pub_info'] == row['pub_info'] else \"\"\n",
    "    tmp = tmp1 + \" \" + tmp2\n",
    "    df_ini.loc[i, 'pub_info'] = tmp\n",
    "    df_ini.loc[i, 'data_source'] = 'ini'\n",
    "    \n",
    "    # add 1 for keep title if not already in the selected titles:\n",
    "    if row['title_lower'] in t_list:\n",
    "        df_ini.loc[i, 'keep_title'] = 0\n",
    "    else:\n",
    "        df_ini.loc[i, 'keep_title'] = 1\n",
    "        \n",
    "        \n",
    "df_ini_keep = df_ini[df_ini['keep_title']==1]\n",
    "df_ini_keep = df_ini_keep.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_ini_keep = pd.concat([df_ini_keep[['title', 'link', 'date', 'pub_info',\n",
    "                        'data_source', 'keep_title']].copy(deep=True), \n",
    "                     pd.DataFrame([2661 + i for i in range(df_ini_keep.shape[0])], columns=['id'])\n",
    "                     ], axis=1)\n",
    "\n",
    "print(\"Number of papers from initial pool we add: \", df_ini_keep.shape[0])\n",
    "df_ini_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb33858",
   "metadata": {},
   "source": [
    "## 4. Prepare dataframe for classification phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f8b7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of selected papers:  158\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([df_selected, df_ini_keep], axis=0, ignore_index=True)\n",
    "df_all = pd.concat([df_all.copy(deep=True), \n",
    "                    pd.DataFrame([\"\"]*df_all.shape[0], columns=['tool_creation']),             # has created the tool or not\n",
    "                    pd.DataFrame([\"\"]*df_all.shape[0], columns=['for_AI']),                    # applied to AI or not\n",
    "                    pd.DataFrame([\"\"]*df_all.shape[0], columns=['type']),                      # type of tool/method: meter,\n",
    "                                                                                               # on-chip, utilization, other\n",
    "                    pd.DataFrame([\"\"]*df_all.shape[0], columns=['from_other_id'])], axis=1)    # if not created, is there an \n",
    "                                                                                               # id of other paper's tool USED\n",
    "print('Final number of selected papers: ', df_all.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d73fd",
   "metadata": {},
   "source": [
    "## 5. Save as an Excel file for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b201b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel(file_name, df_save):\n",
    "\n",
    "    # Apply custom colors to the dataframe\n",
    "    color_mapping = {\n",
    "        'keep': 'green',\n",
    "        'don_t_know': 'orange',\n",
    "        'discard': 'red',\n",
    "        'tool_creation': 'orange',\n",
    "        'for_AI': 'purple',\n",
    "        'type': 'green',\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Create an Excel workbook and worksheet\n",
    "    workbook = xlsxwriter.Workbook(file_name)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    # Write the headers\n",
    "    headers = list(df_save.columns)\n",
    "    for col_num, header in enumerate(headers):\n",
    "        worksheet.write(0, col_num, header)\n",
    "\n",
    "    # Write the data and apply background color\n",
    "    for row_num, row_data in enumerate(df_save.values):\n",
    "        for col_num, cell_data in enumerate(row_data):\n",
    "            cell_data = cell_data if cell_data == cell_data else \"\"\n",
    "            worksheet.write(row_num + 1, col_num, cell_data)\n",
    "            #if df.columns[col_num] == 'City' and cell_data in color_mapping:\n",
    "            #    cell_format = workbook.add_format({'bg_color': color_mapping[cell_data]})\n",
    "            #    worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'keep':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['keep']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'don_t_know':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['don_t_know']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'discard':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['discard']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'tool_creation':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['tool_creation']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'for_AI':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['for_AI']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "            if df_save.columns[col_num] == 'type':\n",
    "                cell_format = workbook.add_format({'bg_color': color_mapping['type']})\n",
    "                worksheet.write(row_num + 1, col_num, cell_data, cell_format)\n",
    "\n",
    "    # Save the Excel file\n",
    "    workbook.close()\n",
    "\n",
    "# Creating the excel file:\n",
    "create_excel('test.xlsx', df_all[['id', 'title', 'link', 'date', 'pub_info', 'data_source', 'keep',\n",
    "       'don_t_know', 'discard', 'comments_first_reviewer', 'assessor',\n",
    "       'keep_don_t_know', 'keep_correction', \n",
    "       'tool_creation', 'for_AI', 'type', 'from_other_id']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_SLR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
