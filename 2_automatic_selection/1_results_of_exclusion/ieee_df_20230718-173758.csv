,original_title,ISBNs,DOI,Publication Title,PDF Link,Abstract,Authors,Author Keywords,Publication Year,title,keep_title
0,Predicting Energy Consumption Using LSTM and CNN Deep Learning Algorithm,979-8-3503-3321-3,10.1109/EFEA56675.2022.10063818,2022 7th International Conference on Environment Friendly Energies and Applications (EFEA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063818,"Innovations in technologies that rely on electricity have led to an uncontrollable rise in power usage. In order to predict future electricity demand and enhance the power distribution system, analysis and forecasting of energy consumption systems are necessary. Several issues with the present energy consumption prediction methods make it difficult to anticipate actual energy usage with any degree of accuracy. In order to master the energy prediction method, this study examines fourteen years' worth of hourly energy usage data from a Kaggle open source dataset. In addition, a Long Short Term Memory (LSTM) and Convolution Neural Network (CNN) based method for estimating energy consumption based on actual datasets is presented in the research. The empirical findings demonstrate which LSTM and CNN architectures can improve energy consumption forecasting accuracy.",A. V. Abraham; P. Sasidharan; S. J. S. Tejas; M. Manohara; R. Muthu; R. C. Naidu,Power consumption;LSTM;CNN;prediction,2022,predicting energy consumption using lstm and cnn deep learning algorithm,1
1,Multi-level Power Consumption and Computation Models and Energy-Efficient Server Selection Algorithms in a Scalable Cluster,978-1-5090-0979-4,10.1109/NBiS.2016.88,2016 19th International Conference on Network-Based Information Systems (NBiS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789760,"It is critical to reduce the electric energy consumed in information systems, especially server clusters. In ourprevious studies, the MLPCM (multi-level power consumption with multiple CPUs) and MLCM (multi-level computation with multiple CPUs) models are proposed with server selection algorithms. In the server selection algorithms, a server is selected to perform a process issued by a client by estimating the electric energy consumption by simulating the execution of every current process. However, it takes time to collect the state of processes performed on each server and estimate the termination time of the processes. In this paper, we propose a simple energy-efficient (PEA) algorithm to select server where only state information on number of processes on each serveris used. We evaluate the PEA algorithm and show not only the total electric energy consumption of the servers but also the average execution time of processes are reduced in the PEA algorithm compared with other algorithms.",H. Kataoka; A. Sawada; D. Duolikun; T. Enokido; M. Takizawa,MLPCM model;MLCM model;Energy-aware server selection algorithm;PEA alogrithm,2016,multi level power consumption and computation models and energy efficient server selection algorithms in a scalable cluster,1
2,A DNN based LSTM Model for Predicting Future Energy Consumption,978-1-6654-9710-7,10.1109/ICAAIC53929.2022.9793147,2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793147,"Due to the progressions of power subordinate hardware, the unnecessary development of energy utilization has expanded dramatically. In this manner, monitoring and prediction of the energy utilization framework will offer the future interest for energy utilization and further develop the power circulation framework. By the virtue of a few difficulties of existing energy utilization, prediction models are restricting to anticipate the genuine energy utilization appropriately. Along these lines, to overcome the energy prediction technique, this paper dissects fourteen years of energy utilization information gathered on an hourly premise, from an open-source dataset from Kaggle. Also, the paper suggests a Long Short-Term Memory (LSTM) based way to deal with predicted energy utilization in light of the genuine dataset. The experimental outcomes show that the proposed LSTM engineering can effectively improve the prediction exactness of energy utilization.",B. E; H. R. M; K. P. N; S. P. S B; J. S,LSTM;DNN;power consumption;Time Series,2022,a dnn based lstm model for predicting future energy consumption,1
3,Integration of Artificial Neural Networks and Genetic Algorithm to Predict Electrical Energy Consumption in Energy Intensive Sector,1-4244-0323-5,10.1109/ICELIE.2006.347212,2006 1ST IEEE International Conference on E-Learning in Industrial Electronics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4152768,"This study presents an integrated genetic algorithm (GA) and artificial neural network (ANN) to estimate and predict electricity demand using stochastic procedures. The considered sector is the energy intensive sector and the economic indicators used in this paper are price, value added, number of customers, price of the substitute fuel and electricity intensity. The chosen models are linear-logarithmic, exponential and quadratic ones. This model can be used to estimate energy demand in the future by optimizing parameter values. The GA applied in this study has been tuned for all its parameters and the best coefficients with minimum error are identified, while all parameter values are tested concurrently. The estimation errors of genetic algorithm models are less than that of estimated by regression method. Neural network is used to forecast each independent variable and then electricity consumption is forecasted up to year 2008 in this sector. It is pointed that neural networks dominate time series approach form the point of yielding less Mean Absolute Percentage Error (MAPE) error. In addition, another unique feature of this study is utilization of ANN instead of time series to obtain better predictions for energy consumption. Electricity consumption in Iranian energy intensive sector from 1981 to 2005 is considered as the case of this study",A. Azadeh; R. T. Moghadam; S. F. Ghaderi; S. Tarverdian; M. Saberi,,2006,integration of artificial neural networks and genetic algorithm to predict electrical energy consumption in energy intensive sector,1
6,Power Consumption and Computation Models of a Server with a Multi-core CPU and Experiments,978-1-4799-1775-4,10.1109/WAINA.2015.127,2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096176,"The power consumption of servers has to be reduced in a cluster to realize eco society. In this paper, we discuss power consumption models of servers. We take a macro level approach to reducing the total power consumption of servers to perform application processes. A server is equipped with a multi-core CPU. Through measuring electric power consumed by types of servers to perform application processes, we newly propose a multi-level power consumption (MLPC) model of a server with a multi-core CPU. Here, the power consumption of a server depends on the number of active cores and active threads where at least one application process is performed. We also discuss a computation model which gives the expected execution time of a process on a server. Based on the MLPC model and the computation model, we discuss an energy-aware (EA) selection algorithm to select a server for each process requested by a client in a cluster so that the total electric energy consumption can be reduced. We evaluate the EA algorithm and show the total energy consumption is reduced in the EA algorithm compared with round-robin and random algorithms.",H. Kataoka; D. Duolikun; T. Enokido; M. Takizawa,Multi-level power consumption (MLPC) model;Computation model;Energy-aware (EA) selection algorithm,2015,power consumption and computation models of a server with a multi core cpu and experiments,1
7,Power Consumption and Computation Models of a Storage Server,978-1-4673-8315-8,10.1109/BWCCA.2015.79,"2015 10th International Conference on Broadband and Wireless Computing, Communication and Applications (BWCCA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424870,"It is now critical to reduce electric energy consumed in a cluster of servers, especially scalable systems including a huge number of servers like cluster computing systems. Types of application processes like computation, storage, and communication processes are performed on servers in clusters. In clusters, most applications use not only CPU resources but also storage drives like database and web applications. In this paper, we consider storage processes which read and write files in storage devices. The SPCS model (simple power consumption model for a storage server) shows how much electric power a server consumes to perform storage and computation processes. In our macro-level approach, we first measure the electric power consumed by a whole server to perform storage and computation processes and the computation time of each process. Then, we define the SPCS model of a server to perform storage and computation processes by abstracting parameters like number of processes which dominate the electric power consumption. We also define a simple computation model for a storage server (SPCS model) to perform storage and computation processes.",A. Sawada; H. Kataoka; D. Duolikun; T. Enokido; M. Takizawa,Eco distributed systems;Storage process;Computation process;Simple power consumption model for a storage server;SCPC model;SCS model,2015,power consumption and computation models of a storage server,1
10,Integration of Artificial Neural Networks and Genetic Algorithm to Predict Electrical Energy consumption,978-1-5090-9155-3,10.1109/IECON.2006.348098,IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4153657,"This study presents an integrated genetic algorithm (GA) and artificial neural network (ANN) to estimate and predict electricity demand using stochastic procedures. The economic indicators used in this paper are price, value added, number of customers and consumption in the previous periods. This model can be used to estimate energy demand in the future by optimizing parameter values. The GA applied in this study has been tuned for all its parameters and the best coefficients with minimum error are identified, while all parameter values are tested concurrently. The estimation errors of genetic algorithm model are less than that of estimated by regression method. Neural network is used to forecast each independent variable and then electricity consumption is forecasted up to year 2008. It is shown that neural networks dominate time series approach form the point of yielding less mean absolute percentage error (MAPE) error. In addition, another unique feature of this study is utilization of ANN instead of time series to obtain better predictions for energy consumption. Electricity consumption in Iranian agriculture sector from 1981 to 2005 is considered as the case of this study",A. Azadeh; S. F. Ghaderi; S. Tarverdian; M. Saberi,,2006,integration of artificial neural networks and genetic algorithm to predict electrical energy consumption,1
12,Non-Intrusive Load Monitoring for High Power Consuming Appliances using Neural Networks,978-1-6654-4966-3,10.1109/ICECIE52348.2021.9664681,"2021 3rd International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9664681,"The topic of Energy Conservation requires urgent attention worldwide to avoid the impending energy crisis and reduce the impact on the environment through emissions. A crucial step in energy conservation is to motivate individual consumers to reduce their consumption. Itemized energy consumption feedback on each appliance helps users to plan their consumption patterns in an optimum way. Non-intrusive load monitoring is a low-cost and low-maintenance method for identifying consumptions of individual devices from the aggregate data of the mains supply. However, high power-consuming devices with power patterns with varying states are generally difficult to identify, despite them making a huge impact on the overall consumption of a household. Research shows that machine learning techniques are a promising approach for this disaggregation process. This paper focuses on developing data preprocessing methods and neural network algorithms to accurately disaggregate four common household appliances including ones with multistate power patterns.",W. A. T. Wickramarachchi; P. H. Panawenna; J. Majuran; V. Logeeshan; S. Kumarawadu,non-intrusive load monitoring;multi-state devices;convolutional neural networks,2021,non intrusive load monitoring for high power consuming appliances using neural networks,1
15,Predicting Power Consumption Anomaly Using Statistical and Supervised Machine Learning Techniques,978-1-6654-3185-9,10.1109/ITOEC53115.2022.9734517,2022 IEEE 6th Information Technology and Mechatronics Engineering Conference (ITOEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9734517,"Power has become an essential element of daily life in the modern world. At the same time, over usage of electricity may lead to excessive power consumption, causing the device to short circuit or be on fire. Therefore, it is crucial to monitor and forecast the anomalies in power consumption to avoid any tragedy. In this paper, the authors proposed a method of predicting anomalies in power consumption. The proposed method uses a statistical approach in labeling; the labeled power consumption data are then used to form the data instances. Later, supervised machine learning classification techniques, namely Support Vector Machine, Decision Tree, and Random Forest, are implemented on the data instances to predict the power consumption anomalies. The experimental results demonstrate that the precision, recall, and F1 score are achieving better results when the training dataset is larger. Besides that, the results show that the techniques used to handle the imbalanced data will affect the performance of models.",Y. -F. Tan; W. -N. Tan; R. El-Hadad; A. Buhari,power consumption anomaly;predicting;statistical method;supervised machine learning;F1 score,2022,predicting power consumption anomaly using statistical and supervised machine learning techniques,1
19,Measuring and visualizing energy consumption within software code,978-1-4799-4035-6,10.1109/VLHCC.2014.6883045,2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6883045,"The authors have begun to witness an exponential growth in the information and communication technologies (ICT) sector. While undoubtedly a milestone, all of this occurs at the expense of high energy costs needed to supply servers, data centers, and any use of computers. Associated with these high energy costs is the emission of greenhouse gases. These two issues have become major problems in society. The ICT sector contributes up to 8% of the overall energy consumption, with 50% of the energy costs of an organization being attributed to the IT departments.The paper discusses a tool which applies the proposed techniques on software code. This tool would guide the developer into programming more energy-aware software by alerting him/her of red smells, and offering green refactorings, all this in a simple visual layout to allow the software developer to become energy-aware. This application will also provide the ability to navigate between less energy efficient areas (packages, classes, modules, functions, methods, blocks and even lines), making its implementation more energy efficient.",T. Carção,,2014,measuring and visualizing energy consumption within software code,1
21,Modeling and Estimation for the Power Consumption of Matrix Computation on Multi-core Platform,978-0-7695-3605-7,10.1109/CSO.2009.451,2009 International Joint Conference on Computational Sciences and Optimization,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5193639,We model and estimate the power consumption of large-scale matrix multiplication by including the most basic power parameters in the parallel algorithm analysis. The matrix multiplication program has been designed based on multi-core frameworks. A Bridging Model (BM) is employed to incorporate the numerical parameters of ultimate physical constraints from power-relevant components and coarse-grained features of the multi-core platform. Consequently the power consumption is predicted by calculating the timing and power factors in the performance analysis equation. The power model and estimation results are validated by measuring the program running on real systems.,D. Q. Ren; R. Suda,,2009,modeling and estimation for the power consumption of matrix computation on multi core platform,1
22,Power consumption estimation using in-memory database computation,978-1-5090-3784-1,10.1109/HONET.2016.7753443,2016 HONET-ICT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753443,"In order to efficiently predict electricity consumption, we need to improve both the speed and the reliability of computational environment. Concerning the speed, we use in-memory database, which is taught to be the best solution that allows manipulating data many times faster than the hard disk.",H. Dağ; M. Alamin,In-Memory Database;Machine Learning;Power Consumption,2016,power consumption estimation using in memory database computation,1
23,Toward using software metrics as indicator to measure power consumption of mobile application: A case study,978-1-4673-8227-4,10.1109/MySEC.2015.7475216,2015 9th Malaysian Software Engineering Conference (MySEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7475216,"Battery capacity of mobile devices is a critical issue for developing green mobile applications. Therefore, energy efficiency has become a major concern nowadays for energyrestricted embedded system such as smartphones and tablets. In industry, it is a challenge for them to develop an energy efficient product while meeting customer expectation. In previous study, there is lack of method that uses software metrics to measure power consumption of mobile applications. In this paper we have identified several software metrics that can be used as indicator to measure mobile application power consumption. The objective of this study is to which identify software metrics is suitable act as indicators to measure power consumption of mobile applications. This can help mobile software designer to measure power used for their mobile applications in the early design phase. In order to prove this concept, we randomly select two open source mobile applications as our case study. The power used of a mobile application is collected by using Trepn Profiler (Power profiling tool for Qualcomm processor CPU). We capture the actual power consumption and estimated power consumption (without calculate Android OS and profiling tool power) with the profiler. There are overall 18 available metrics based on Object-Oriented Metrics. We map the 18 metrics with the power consumption captured by Trepn Profiler. The results shown that McCabe cyclomatic complexity, number of parameters, nested block depth, weighted methods per class, number of overridden method, number of methods, total lines of code and method lines have significant relationship with power consumption of mobile application. Therefore, these eight metrics can be used as the indicator to measure mobile applications' power consumption.",C. Kin Keong; K. Tieng Wei; A. A. Abd. Ghani; K. Y. Sharif,Android Mobile Application;Power Consumption;Metric;Power Measurement,2015,toward using software metrics as indicator to measure power consumption of mobile application a case study,1
25,Energy Consumption Prediction System Based on Deep Learning with Edge Computing,978-1-7281-1618-1,10.1109/ELTECH.2019.8839589,2019 IEEE 2nd International Conference on Electronics Technology (ICET),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839589,"Governments around the world are actively pursuing research on smart cities as an attempt to pursue the city's sophistication and sustainability. In order to create a smart city, it is important to reduce energy and manage it efficiently. With the development of smart city, it is expected that a large number of Internet of Things (IoT) devices will be installed in various buildings in the city, and a lot of energy usage information will be measured. When many IoT devices are connected to the internet, a large amount of data is generated. Therefore, when the existing cloud service is used, data is delayed in analyzing and transmitting data, and it becomes impossible to receive the analysis result quickly. With edge computing, you can process data directly in the edge environment where data is collected and apply the results quickly to the field. It can respond to data much faster than it can deliver data and wait for the results to be analyzed and reduce the load on the data. Therefore, in this paper, we propose a system for predicting energy consumption using a deep learning (DL) algorithm in an edge computing environment. We have applied the proposed system to office environment by building testbed. We used the long short-term memory (LSTM) network which shows high accuracy in time series data analysis and obtained the energy prediction result per day. We check the state of the electronics through the energy consumption prediction data, detect the abnormality and provide the energy consumption pattern analysis service respectively.",S. H. Lee; T. Lee; S. Kim; S. Park,energy;IoT;deep learning;edge computing,2019,energy consumption prediction system based on deep learning with edge computing,1
26,Implementation of an Energy Saving Cloud Infrastructure with Virtual Machine Power Usage Monitoring and Live Migration on OpenStack,978-1-5090-4457-3,10.1109/ICPADS.2016.0101,2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823816,"This work implement a cloud infrastructure that can monitor the status of OpenStack and monitor the real-time status of virtual machine on OpenStack then achieve to energy saving through live migration. The projects of monitoring include the utilization of CPU, load of memory, and power consumption. These data show in real-time, completely monitor the real-time status of physical machines and virtual machines. It also record the utilization and power consumption of physical machines then show on this cloud infrastructure, to provide experimental evidence for the user as a reference. Base on the power consumption we monitoring, we can automatically allocate virtual machines on every physical machines by live migration, to balance the power consumption of every physical machines. Its not only can avoid idle and waste of resources but also can avoid reducing machine life because of the physical machines always keep in high usage, and achieve to power saving.",T. -Y. Wan; C. -I. Chiang; C. -T. Yang; S. -T. Chen; J. -C. Liu,Real-Time Monitoring;Power Saving;Machine;Monitoring;Live Migration;Dynamic Allocation;Cloudfrastructure,2016,implementation of an energy saving cloud infrastructure with virtual machine power usage monitoring and live migration on openstack,1
27,Combined method for monitoring energy consumption of an electric drive of a rocking machine based on an artificial neural network,978-1-7281-9116-4,10.1109/ICOECS50468.2020.9278506,2020 International Conference on Electrotechnical Complexes and Systems (ICOECS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9278506,The article discusses the development of a combined method for controlling the energy consumption of an electric drive (ED) of a rocking machine (RM) of a sucker rod pump unit (SRPU) based on an artificial neural network.,A. O. Timofeev; V. K. Yasoveev,electric drive;rocking machine;sucker rod pumping unit;artificial neural network,2020,combined method for monitoring energy consumption of an electric drive of a rocking machine based on an artificial neural network,1
28,Cloud computing and continuous energy consumption monitoring,978-1-5386-0774-9,10.1109/ICE.2017.8279878,"2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279878,"Measurement of electrical energy consumption has evolved continuously from autonomous measuring devices to continuous measurement networks. The digital era allowed digital networks to be used for continuous and remote measurements. Building of digital measurement networks or sensor networks can be based on different topologies and communication technologies. The Internet of Things and Cloud Computing associated with Deep Learning opens up new opportunities. Increased computing power, lower energy consumption, extended integration into systems on a chip and lower costs becomes a new foundation for expanding and improving sensor networks. This paper presents the impact on the accuracy of measurements using sensor networks with cloud computing technologies from the perspective of continuous running over a period of more than three years.",V. Lupu,sensor network;Internet of things;cloud computing;continuous monitoring;energy consumption,2017,cloud computing and continuous energy consumption monitoring,1
30,Design and implementation of a new power consumption monitoring and analysis system based on intelligent neural network,978-1-6654-6766-7,10.1109/ICCASIT55263.2022.9986683,2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986683,"This paper focuses on the overall design and implementation of the monitoring and analysis system. The evaluation of interference load, the design of Switching virtual circuit compensation capacity and the design of filter is discussed in detail. This system gives full play to the superiority of extra segment over qualitative analysis. The reasoning path is clear. The advantages are ease of interpretation and user engagement. The data processing and self-learning ability of the original power quality monitoring system are improved. The steady state power quality and transient power quality in power system are monitored accurately. Provides a variety of statistical reports. Provide comprehensive, detailed and real-time power quality information. It provides the basis for power quality management.",G. Hongbo; Z. Wen; Y. Bao; C. Yan; G. Shijie; F. Shangying; S. Han; O. Hong; W. Quan; L. Junling,power quality;Online monitoring;system design,2022,design and implementation of a new power consumption monitoring and analysis system based on intelligent neural network,1
31,Remote Monitoring Systems of Unsafe Software Execution using QR Code-based Power Consumption Profile for IoT Edge Devices,978-1-7281-9161-4,10.1109/ICEIC51217.2021.9369725,"2021 International Conference on Electronics, Information, and Communication (ICEIC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9369725,"If an error occurs in a system where several edges are gathered and operated together, the error may be transferred to other edges or the entire system may be down. Therefore, it is important to judge and control the errors of each edge in such a system, which puts a load on the embedded system of small edges. However, it is not easy to judge an error in an embedded system with limitations of performance. In such a system, we try to determine the state of the edge device using power consumption data and determine the error based on it. In this paper, we show that the server can determine errors using the power consumption data, and the data consumption allows the server to read data values through data communication using QR codes. In this architecture, the edge device only transmits power consumption data to reduce the load on the embedded system, and the gateway and server collect the data using QR codes communication. At the same time, the server interprets the received data to determine errors using various algorithms and controls the edge device. In this process, it is important to synchronize the edge device with the gateway and the server. Since the proposed structure uses a separate power meter and communication device, it solves the problem of not sending an appropriate message to the server when a communication error occurs at the previous edge. Also, the proposed model solves the overload problem that occurs when networks are used in various IoT devices using QR code that imaged data and light communication using a camera. After data is extracted and sorted from the QR code obtained by recognizing the camera of the intermediate server, the main server performs error determination through data analysis. The proposed architecture was implemented using `chip-whisperer' to measure edges and data, as well as `raspberry pi' to implement the server. As a result, the proposed architecture server showed successful data transmission and error determination, and it also showed very little additional load at the edge.",M. Kang; D. Park,Robust Execution;Embedded system;Error detection;QRcode;Data transmission,2021,remote monitoring systems of unsafe software execution using qr code based power consumption profile for iot edge devices,1
32,Power Consumption Interval Prediction Based on Quantile Regression Neural Network and Kernel Density Estimation,978-1-5386-8527-3,10.1109/ISCID.2018.10169,2018 11th International Symposium on Computational Intelligence and Design (ISCID),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695577,"Power forecasting is the basis for grid peaking, gird construction planning, and power demand management. Large users are generally special users who have large power consumption. The sampling frequency of the power data is collected once in 15 minutes. The traditional point prediction model take no account into the factors affecting electricity, while interval prediction provides more comprehensive and effective information. Based on the historical electricity data, the quantile regression neural network model (qrnn) and kernel density estimation method are used for power interval prediction. Using the quantile regression to study the relationship between the independent variable and the conditional quantile of the dependent variable, the quantile regression neural network is used to obtain the predicted values of the different quantile points at the same time point. The kernel density estimation method can be based on different points to construct power forecast interval. The interval prediction result at the future time point can be compared with true power consumption whether the power consumption of the large user is abnormal and analyze the future power consumption trend of the large user, and provide decision support for the stable operation of the power grid.",H. Lv; G. Chen; M. Deng; Z. Tan; W. Hu,Interval prediction;Quantile regression neural network;Kernel density estimation,2018,power consumption interval prediction based on quantile regression neural network and kernel density estimation,1
38,Evaluating the Performance and Energy Efficiency of OpenGL and Vulkan on a Graphics Rendering Server,978-1-5386-9223-3,10.1109/ICCNC.2019.8685588,"2019 International Conference on Computing, Networking and Communications (ICNC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8685588,"Open Graphics Library (OpenGL) has been the de facto industry standard of 2D and 3D graphics rendering for decades. As OpenGL continued to evolve, it becomes easier to use and more powerful by accommodating heterogeneous hardware and hiding optimization details from developers. As a side effect, its overhead gradually increases and its performance becomes unpredictable. To address the weaknesses of OpenGL, Vulkan was proposed as a thin graphics API to reduce the overhead and allow developers to gain grainer control over rendering process. This paper conducts a comprehensive evaluation on the performance and energy efficiency of OpenGL and Vulkan on a graphics rendering server. Our experimental results show that 1) OpenGL’s performance is unpredictable; 2) Vulkan can save significant amount of energy while maintaining the same performance; and 3) OpenGL cannot keep up with Vulkan’s performance when an extremely high frame rate is required.",M. Lujan; M. Baum; D. Chen; Z. Zong,performance;energy efficiency;OpenGL;Vulkan,2019,evaluating the performance and energy efficiency of opengl and vulkan on a graphics rendering server,1
40,An Automated Software Package Creation for Energy Consumption Accounting,978-1-6654-6652-3,10.1109/UralCon54942.2022.9906691,2022 International Ural Conference on Electrical Power Engineering (UralCon),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906691,"Modern world market relations put forward rigorous requirements for conditions of information exchange and implementation of automated systems for commercial accounting and sale of thermal and electric energy. Data collection of the amount of energy consumed is often carried out through manual entry of information, that does not exclude probable errors. Besides, errors may occur when data are integrated into internal and external information systems. A software package for household energy consumption metering was worked out. Its architecture is built on a centralized principle; interaction with users is carried out through a web interface. The developed metering software package provides control over the performance, operation mode of main networks and central heating units. It consists of 12 functional blocks; the paper covers the purpose of each of them. The automated software package is designed to obtain thermal energy consumption data, their following processing by means of automatic analysis and automated transfer to the customer billing system.",Y. Zatsarinnaya; G. Kovalev; R. Gainullin,software package;electricity market;modernization;accounting;quality;information technology;energy;warmth,2022,an automated software package creation for energy consumption accounting,1
43,Efficient Computation Offloading with Energy Consumption Constraint for Multi-Cloud System,978-1-6654-8180-9,10.1109/ICACTE55855.2022.9943608,2022 15th International Conference on Advanced Computer Theory and Engineering (ICACTE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943608,"With the increasing functionalities of mobile terminals, computation offloading has become a good way to alleviate the limitation of terminal computing resource and improve terminal performance. In this paper, we propose an efficient computation offloading strategy for multi-cloud system to minimize makespan with terminal energy consumption constraint. The proposed strategy first sorts tasks and establishes paths. Then tasks on each established path are counted as an integrated task and assigned to a worker node with less completion time iteratively. After the initial task assignment, performance optimization is performed to satisfy energy consumption constraint and further decrease makespan. Experimental results show that the proposed approach has better performance compared to genetic algorithm and greedy algorithm.",X. Ge; Q. Zhang,multi-cloud system;computation offloading;task scheduling;makespan;energy consumption,2022,efficient computation offloading with energy consumption constraint for multi cloud system,1
44,Power Consumption and Computation Models of Virtual Machines to Perform Computation Type Application Processes,978-1-4799-8870-9,10.1109/CISIS.2015.18,"2015 Ninth International Conference on Complex, Intelligent, and Software Intensive Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7185176,"Scalable and fault-tolerant information systems like cloud systems are realized in server cluster systems. Server cluster systems are equipped with virtual machines to provide applications with scalable and fault-tolerant services. Scalable and fault-tolerant application services can be provided by balancing processing load among virtual machines to perform application processes. On the other hand, a large amount of electric energy is consumed in a server cluster system since multiple virtual machines are performed on multiple servers which consume electric energy to perform application processes. In order to design and implement an energy-aware server cluster system, the computation model and power consumption model of a server to perform application processes on multiple virtual machines have to be defined. In this paper, we first define the computation model of a virtual machine to perform application processes. We also define the power consumption model of a server to perform application processes on virtual machines.",T. Enokido; M. Takizawa,Virtual machines;Migration;Energy-aware systems;Power consumption models;Green IT,2015,power consumption and computation models of virtual machines to perform computation type application processes,1
45,Prediction Based Energy Efficient Virtual Machine Consolidation in Cloud Computing,978-1-4799-1734-1,10.1109/ICACCE.2015.148,2015 Second International Conference on Advances in Computing and Communication Engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306726,"Cloud computing enables the web hosting of computing resources, applications to be available for consumers on a pay-per-use basis. This has made cloud computing quite popular and the need of today's world. With this, the demand for computational power has increased and this has led to the creation of large-scale cloud data centres. These data centresresult in large electrical power consumption and thus the cost of operation and maintenance, which has become a major issue in the cloud. Therefore we need to find out solutions to minimize this power consumption and thus operating cost. In this paper, a prediction based faster energy efficient virtual machine (VM) consolidation scheme is proposed which results in faster VM consolidation to improve Quality of Service (QoS) and performance while reducing energy consumption.",N. K. Gondhi; P. Kailu,Energy efficiency;Cloud computing;Infrastructure as a Service;Resource management;Virtualization;Heuristics;Consolidation of virtual machines;QoS,2015,prediction based energy efficient virtual machine consolidation in cloud computing,1
46,A method to estimate the energy consumption of deep neural networks,978-1-5386-1823-3,10.1109/ACSSC.2017.8335698,"2017 51st Asilomar Conference on Signals, Systems, and Computers",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335698,"Deep Neural Networks (DNNs) have enabled state-of-the-art accuracy on many challenging artificial intelligence tasks. While most of the computation currently resides in the cloud, it is desirable to embed DNN processing locally near the sensor due to privacy, security, and latency concerns or limitations in communication bandwidth. Accordingly, there has been increasing interest in the research community to design energy-efficient DNNs. However, estimating energy consumption from the DNN model is much more difficult than other metrics such as storage cost (model size) and throughput (number of operations). This is due to the fact that a significant portion of the energy is consumed by data movement, which is difficult to extract directly from the DNN model. This work proposes an energy estimation methodology that can estimate the energy consumption of a DNN based on its architecture, sparsity, and bitwidth. This methodology can be used to evaluate the various DNN architectures and energy-efficient techniques that are currently being proposed in the field and guide the design of energy-efficient DNNs. We have released an online version of the energy estimation tool at energyestimation.mit.edu. We believe that this method will play a critical role in bridging the gap between algorithm and hardware design and provide useful insights for the development of energy-efficient DNNs.",T. -J. Yang; Y. -H. Chen; J. Emer; V. Sze,Deep learning;deep neural network;energy estimation;energy metric;machine learning,2017,a method to estimate the energy consumption of deep neural networks,1
49,Implementation of Machine Learning Algorithm for predicting user behavior and smart energy management,978-1-5090-4083-4,10.1109/ICDMAI.2017.8073480,"2017 International Conference on Data Management, Analytics and Innovation (ICDMAI)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8073480,"A greater interest arises in reducing our energy needs as electrical energy becomes more costly and the environmental effects of fossils become more deceptive. Objectives to find new ways of making our everyday lives more energy efficient have now became an essential part of the tussle to sustain our present quality of living. This project targets domestic usage which has a more direct approach in changing the way we consume energy. In this project we take up House Hold Loads as the application but this project can also be applied for large industrial loads. Smart energy metering and normalized energy data on load usage are one of the major goal setters for the future smart grid and improved energy efficiency in smart homes. Load Monitoring (LM) is essential for energy management and cost fixing. To obtain appliance-specific energy consumption statistics that can further be used to formulate load scheduling strategies for optimal energy utilization, disaggregation of Load is essential. Non-Intrusive Load Monitoring (NILM) is an alternative and best method for Load Disaggregation, as it can distinguish devices from the aggregated data measured at only a centralized location. In this paper we provide an experimental idea of using NILM technology by actually implementing sub-metering system for each load to forecast its futuristic development on the basis of bin packing algorithms and feedback systems controlled by the Machine Learning Algorithm to end up with an energy efficient smart home and smart grids.",R. G. Rajasekaran; S. Manikandaraj; R. Kamaleshwar,Machine Learning;Non-Intrusive Load Monitoring;Load Disaggregation;Bin Packing;Energy Management;Feedback Systems;Power Quality;Graphic User Interface,2017,implementation of machine learning algorithm for predicting user behavior and smart energy management,1
51,Multi-level Computation and Power Consumption Models,978-1-4799-9942-2,10.1109/NBiS.2015.10,2015 18th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350596,"It is critical to reduce the electric power consumed by servers in a cluster in order to realize eco society. In the multi-level power consumption (MLPC) model of a server with a multi-core CPU, the power consumption of the server depends on the number of active cores and active threads where at least one application process is performed. In our previous studies, we discuss the energy-aware (EA) selection algorithm to select a server for each request process. Here, a server which is expected to consume the minimum electric energy is selected in a cluster. A server consumes the basic electric power even if no process is performed. The ratio of the basic energy consumption to the total electric energy consumption is large, e.g. 40 to 50 %. In this paper, we newly propose a globally energy-aware (GEA) algorithm to select a server for each process in a cluster. Here, not only the total electric energy consumption of the servers but also the ratio of basic electric energy consumed by servers to the total energy consumption can be reduced. We evaluate the GEA algorithm and show not only the total energy consumption of the servers but also the average execution time of processes are reduced in the GEA algorithm compared with the EA, round-robin (RR), and random (RD) algorithms.",H. Kataoka; D. Duolikun; T. Enokido; M. Takizawa,Multi-level power consumption (MLPC) model;Multi-level computation (MLC) model;Globally energy-aware (GEA) server selection algorithm;Minimum power consumption,2015,multi level computation and power consumption models,1
52,Novel techniques for bus power consumption reduction in realizations of sum-of-product computation,,10.1109/92.805757,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=805757,"Novel techniques for power-efficient implementation of sum of product computation are presented. The proposed techniques aim at reducing the switching activity required for the successive evaluation of the partial products, in the busses connecting the storage elements where data and coefficients are stored to the functional units. This is achieved through reordering the sequence of evaluation of the partial products. Heuristics based on the traveling salesman problem are proposed to perform the reordering for different categories of algorithms. Information related to both data (dynamic) and coefficients (static) is used to drive the reordering. Experimental results from the application of the proposed techniques on several signal-processing algorithms have proven that significant switching activity savings can be achieved.",K. Masselos; P. Merakos; T. Stouraitis; C. E. Goutis,,1999,novel techniques for bus power consumption reduction in realizations of sum of product computation,1
54,Modeling the power consumption of audio signal processing computations using customized numerical representations,0-7695-1911-3,10.1109/SIMSYM.2003.1192820,"36th Annual Simulation Symposium, 2003.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1192820,"This paper explores the impact that numerical representation has on the power consumption of audio signal processing applications. The motivation is digital hearing aids, for which minimizing the power consumption is a critical design goal. We investigate two aspects of this problem. First, we evaluate the validity of using signal transition counts to model actual power consumption within this problem domain, and second, we compare the relative power consumption of multiply-accumulate operations for several customized numerical representations.",R. Chamberlain; E. Hemmeter; R. Morley; J. White,,2003,modeling the power consumption of audio signal processing computations using customized numerical representations,1
55,An imprecise computation model in reducing power consumption of flash memory for portable devices,0-7695-2209-2,10.1109/CMPSAC.2004.1342677,"Proceedings of the 28th Annual International Computer Software and Applications Conference, 2004. COMPSAC 2004.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1342677,"A methodology is proposed to transform the power consumption problem for flash memory storage of a hard real-time embedded system into an imprecise computation model. Also, based on imprecise computation models, two scheduling algorithms have been developed to minimize the total power consumptions of the online service requests (i.e., tasks) for a flash memory of a hard real-time embedded system. To the best of our knowledge, it is the first idea to solve the power consumption problem of a hard real-time embedded system using imprecise computation models.",Li-Ping Tung; Jia-Ming Chen; Wei-Fen Hsu; Wei-Kuan Shih,,2004,an imprecise computation model in reducing power consumption of flash memory for portable devices,1
56,Limiting CPU power consumption for efficient computation of 3D workloads,978-1-4673-5328-1,10.1109/ICEAC.2012.6471005,2012 International Conference on Energy Aware Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6471005,Rendering 3D workloads using the least power possible is an increasingly important quality of computing platforms. Current platforms do not achieve this goal because they power the Central Processing Units (CPUs) at frequencies above the minimum required for these workloads to operate without performance loss. Higher than necessary frequencies yield greater than necessary power consumption. This paper describes a method for limiting CPU frequency while running 3D workloads to reduce power consumption with minimal performance loss. Using this method on an Intel® 3rd generation CoreTM processor reduces CPU power consumption by an average of 9% with no significant performance impact.,T. Schluessler; J. Romano; S. Gurtovoy; G. Zadicario; J. Fox,efficiency;efficient computing;3D,2012,limiting cpu power consumption for efficient computation of d workloads,1
57,Approaches to minimize power consumption of computation network,978-6-1760-7716-9,10.1109/CADSM.2015.7230795,The Experience of Designing and Application of CAD Systems in Microelectronics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230795,In this paper it was reviewed several existing investigations about minimization power consumption of data centers. It was suggested several approaches of task distribution in computing networks to minimize power consumption and management system for such networks.,L. Globa; O. Stepurin,Virtual machine;live migration of multiple VMs;VM migration costs;VM migration time;energy-efficient computing,2015,approaches to minimize power consumption of computation network,1
58,Evaluating the Energy Efficiency of Software Defined Networking Controllers for Different Topologies,978-1-7281-6770-1,10.1109/icABCD49160.2020.9183851,"2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183851,"The increase in the number of connected devices in network deployments has resulted in network management becoming a tedious process. While the Software Defined Networking (SDN) paradigm was made primarily to deal with the tedious management issue by placing all control functionality on the controllers, this results in the controller being loaded with tasks and ends up consuming a greater amount of energy for managing the network. This leads to an increased cost for managing the network. Many works have tried to compare the performance of SDN controllers, while only few have considered the energy efficiency. However, the energy efficiency of SDN controllers when subjected to different topologies remains an open issue. This paper looked at the energy efficiency of five SDN controllers using different topologies. Mininet is used for topology emulation and Powerstat for the power consumption readings of the controllers. The results of this study show that POX and RYU controllers perform better than Beacon, Floodlight and OpenDaylight controllers in the achieved energy efficiency for all the topologies considered.",S. Ndlovu; P. Mudali; O. A. Oki,Control plane;Energy-efficiency;Network controllers;C-bench;Software defined networks,2020,evaluating the energy efficiency of software defined networking controllers for different topologies,1
59,Mosaic-CNN: A Combined Two-Step Zero Prediction Approach to Trade off Accuracy and Computation Energy in Convolutional Neural Networks,,10.1109/JETCAS.2018.2865006,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434203,"In convolutional neural networks (CNNs), convolutional layers consume dominant portion of computation energy due to large amount of multiply-accumulate operations (MACs). However, those MACs become meaningless (zeroes) after rectified linear unit when the convolution results become negative. In this paper, we present an efficient approach to predict and skip the convolutions generating zero outputs. The proposed two-step zero prediction approach, called mosaic CNN, can be effectively used for trading off classification accuracy for computation energy in CNN. In the mosaic CNN, the outputs of each convolutional layer are computed considering their spatial surroundings in an output feature map. Here, the types of spatial surroundings (mosaic types) can be selected to save computation energy at the expense of accuracy. In order to further save the computations, we also propose a most significant bits (MSBs) only computation scheme, where a constant value representing least significant bits compensates the MSBs only computations. The CNN accelerator supporting the combined two approaches has been implemented using the 65-nm CMOS process. The numerical results show that compared with the state-of-art processor, the proposed reconfigurable accelerator can achieve energy savings ranging from 16.99% to 29.64% for VGG-16 without seriously compromising the classification accuracy.",C. Kim; D. Shin; B. Kim; J. Park,Convolutional neural networks;energy-efficient accelerator,2018,mosaic cnn a combined two step zero prediction approach to trade off accuracy and computation energy in convolutional neural networks,1
60,A Framework for Estimating the Impact of a Distributed Software System's Architectural Style on its Energy Consumption,978-0-7695-3092-5,10.1109/WICSA.2008.28,Seventh Working IEEE/IFIP Conference on Software Architecture (WICSA 2008),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4459169,"The selection of an architectural style for a given software system is an important factor in satisfying its quality requirements. In battery-powered environments, such as mobile and pervasive systems, efficiency with respect to energy consumption has increasingly been recognized as an important quality attribute. In this paper, we present a framework that (1) facilitates early estimation of the energy consumption induced by an architectural style in a distributed software system, and (2) consequently enables an engineer to use energy consumption estimates along with other quality attributes in determining the most appropriate style for a given distributed application. We have applied the framework on five distributed systems styles to date, and have evaluated it for precision and accuracy using a particular middleware platform that supports the implementation of those styles. In a large number of application scenarios, our framework exhibited excellent precision, in that it was consistently able to correctly rank the five styles and estimate the relative differences in their energy consumptions. Moreover, the framework has also proven to be accurate: its estimates were within 7% of the different style implementations ' actually measured energy consumptions.",C. Seo; G. Edwards; S. Malek; N. Medvidovic,Architectural styles;energy estimation;component-based distributed systems,2008,a framework for estimating the impact of a distributed software system s architectural style on its energy consumption,1
61,Reducing power consumed by a PC-based server in an Internet-based data acquisition system using a novel server agent,978-1-4244-5568-3,10.1109/3CA.2010.5533780,"2010 International Symposium on Computer, Communication, Control and Automation (3CA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5533780,"The work attempts to reduce the power consumption of a personal computer (PC)-based server of an Internet-based data acquisition system using a novel server agent. An Internet-based data acquisition system requires at least one PC as the central server. The system needs to be run for a long time. If few data are transferred, the server stays at an almost idle state. However, keeping the server running without doing anything wastes power. Reducing this unnecessary power consumption by a PC-based server and further reducing the power consumption of an entire system are the goals of this work. This work is based on a microcontroller-based device. The novel microcontroller-based device in this work is called a Server Agent. This agent receives data from clients while the original PC-based server is off. After the amount of data transferred exceeds a certain limit, the Server Agent powers on the PC-based server and dumps the data to the PC-based server. The Server Agent will power off the PC-based server again once all data are dumped. The power consumed by the Server Agent is <;1 watt, much lower than that consumed by the PC-based server of 60-110 watts. This process reduces system power consumption.",I. -C. Shen; T. -J. Liu,data acquisition system;power consumption;Internet;server agent;microcontroller,2010,reducing power consumed by a pc based server in an internet based data acquisition system using a novel server agent,1
62,Comparison of artificial intelligence techniques for energy consumption estimation,978-1-5090-1919-9,10.1109/EPEC.2016.7771702,2016 IEEE Electrical Power and Energy Conference (EPEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7771702,"In this article, a comparison study of three artificial intelligence (AI) techniques for energy consumption estimation are presented. The models considered are: multilayer perceptron (MLP); radial basis function (RBF) and support vector machine (SVM). The energy consumption is modeled as a function of activity, structural and intensity changes. The models are applied to Canadian industrial manufacturing data from 1990 to 2000. Comparisons were based on Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Relative Absolute Error (RAE), Root Relative Square Error (RRSE) as well as Simulation Time. The best results were obtained for the Multilayer Perceptron.",O. A. Olanrewaju; C. Mbohwa,Energy consumption;Multilayer perceptron;Radial basis function;Support vector regression,2016,comparison of artificial intelligence techniques for energy consumption estimation,1
65,Estimating Software Energy Consumption with Machine Learning Approach by Software Performance Feature,978-1-5386-7975-3,10.1109/Cybermatics_2018.2018.00106,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726531,"With the growing scale of the application and ability to compute, more and more people pay attention to software energy consumption. There is a huge potential for controlling energy consumption during the application's development phase. Although the energy consumption of software can be obtained by tools or models, the problem of how energy consumption is consumed is still not explained. To solve this problem, a model of energy consumption characterized by performance events is established with using the method of ridge regression machine learning, which can explain the origin of energy consumption, and the error rate is only 6.8%. Our model is based on performance events from perf tool and is independent of the application scenario. Using this model, it does not require programmers to measure and train their own applications, it can also decrypt the causes of energy consumption.",C. Fu; D. Qian; Z. Luan,Software Energy Consumption;Energy-Efficiency;Measurement;Performance,2018,estimating software energy consumption with machine learning approach by software performance feature,1
68,Estimating power consumption of mobile embedded software based on behavioral model,978-1-4244-4314-7,10.1109/ICCE.2010.5418970,2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5418970,"The importance of software that consumes low power in embedded application is revealed again. The existing researches to analyze power consumption of embedded software have been focused on instructions or source-codes level. However, these approaches have shortcomings that the analysis time is long and the power reduction effect is not great. This paper proposes a power consumption analysis technique in more abstract model level than source-code. When our proposed technique compared with the existing source-code analysis, the estimating result of power consumption shows the deviation within average 10% and the analysis time is reduced more than 80%. Our proposed technique can be also applied very usefully to select design decisions that consume low power in the software design phase.",Jong-Phil Kim; Doo-Hwan Kim; Jang-Eui Hong,,2010,estimating power consumption of mobile embedded software based on behavioral model,1
69,A portable platform to estimate power consumption of software modules,978-1-5090-0033-3,10.1109/VLSI-SATA.2016.7593041,"2016 International Conference on VLSI Systems, Architectures, Technology and Applications (VLSI-SATA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7593041,"Researchers perform various hardware and software tests in order to measure power consumption of mobile devices, network modules and embedded system solutions. In this paper, we discuss a portable platform to measure changes in power consumption. We run several tests on this platform to compute CPU utilization by the test programs and the operating system and relate it with execution time and memory utilization. Using the data obtained, we use regression analysis to relate power consumption with CPU utilization.",A. Bhardwaj; S. Saurav,Green-Computing;RaspberryPi;CPU utilization;Ardiuno,2016,a portable platform to estimate power consumption of software modules,1
71,Prediction of Electric Energy Consumption for Demand Response using Deep Learning,978-1-6654-7258-6,10.1109/ICICCSP53532.2022.9862353,2022 International Conference on Intelligent Controller and Computing for Smart Power (ICICCSP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9862353,"This paper emphasizes the capability of Deep Learning (DL) models to conquer the Demand Response (DR) inherent when predicting the Electric Energy Consumption (EEC) of an office building. The prediction of EEC plays a key role in DR programs in a smart grid environment. In this study, historical energy consumption and ambient temperature data of three different climatic days (summer, winter, and cloudy days) of an office building located in Portugal at 10 seconds intervals are taken. A DL technique-based Deep Neural Network model is proposed for the prediction of future EEC. In this paper predictability of EEC of the whole office building has been analyzed. This study describes an evince DL application for commercial energy consumption prediction at 10 seconds intervals and performed precursory success. Moreover, two conventional Machine Learning (ML) models i.e., Support Vector Regressor (SVR) and Random Forest (RF) are developed and analyzed. Furthermore, the proposed DL model is compared with SVR and RF in terms of performance evaluation parameters such as Mean Absolute Error (MAE), Mean Square Error (MSE), and Root Mean Square Error (RMSE). All the models are developed and executed on TensorFlow deep learning platform. The proposed model defeats SVR by 91.65%and RF by 87.38% on a summer day, similarly defeats SVR by 93.85% and RF by 91.68% on a winter day and defeats SVR by 95.63% and RF by 92.67% on a cloudy day in terms of MSE.",R. Panigrahi; N. R. Patne; S. Pemmada; A. D. Manchalwar,Deep Neural Network;Deep Learning;Machine Learning;Neural Network,2022,prediction of electric energy consumption for demand response using deep learning,1
72,Sampling Strategy Analysis of Machine Learning Models for Energy Consumption Prediction,978-1-6654-4094-3,10.1109/SEGE52446.2021.9534987,2021 IEEE 9th International Conference on Smart Energy Grid Engineering (SEGE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534987,"With the development of the Internet of things (IoT), energy consumption of smart buildings has been widely concerned. The prediction of building energy consumption is of great significance for energy conservation and environmental protection as well as the construction of smart city. With the development of artificial intelligence, machine learning technology has been introduced to energy consumption prediction. In this study, multiple learning algorithms including Support Vector Regression (SVR), Artificial Neural Network (ANN), Random Forest (RF) are developed to perform energy consumption prediction. The most appropriate machine learning algorithm for energy consumption prediction has been investigated and found to be the random forest algorithm. Based on the developed machine learning models, studies on the sampling strategy for energy consumption prediction have been conducted. It is found that the variance of data has a significant effect on the prediction accuracy, and a better prediction result can be achieved by increasing the sampling density over the data with high variance. This result can be used to optimize the machine learning algorithm for building energy consumption prediction and improve the computational efficiency.",Z. Wu; W. Chu,energy consumption;machine learning;random forest;sampling strategy,2021,sampling strategy analysis of machine learning models for energy consumption prediction,1
73,Machine Learning Approach for Energy Consumption Prediction in Datacenters,978-1-7281-2580-0,10.1109/ICMIT47780.2020.9046987,2020 2nd International Conference on Mathematics and Information Technology (ICMIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9046987,"Cloud Computing represents the ideal solution for end-users either small medium enterprises or simple clients. This solution is given as a for clients to go from classic service concept to oriented service concept. Moreover, this paradigm collects a set of operations which made them a complex task to the managers. Since the coming of the Cloud Computing encourages service providers to deploy their services. These enormous services need some infrastructure services that are located in datacenters in order to execute them. Due to this use, Cloud infrastructure owners are concerned by the huge energy consumed during this execution. This problematic will affect the use of costs for the services providers. To tackle this problem, in this work, we present several models presented in machine learning methods in order to predict the energy to be consumed for the next use. These forecasts could help the infrastructure providers to propose a plan and some analytics to eliminate the waste of used resources during the execution of services. The implementation of this model has been provided in order to evaluate our system. The obtained results demonstrate the effectiveness of our proposed system.",A. Merizig; T. Bendahmane; S. Merzoug; O. Kazar,Cloud Computing;Energy Consumption;Datacenter Energy Prediction;Support Vector Regression;SVR;Artificial Neural Networks;Time Series;Machine Learning;Cloud Services,2020,machine learning approach for energy consumption prediction in datacenters,1
76,Prediction model for energy consumption and generation based on artificial neural networks,978-989-54659-0-3,10.23919/CISTI49556.2020.9140864,2020 15th Iberian Conference on Information Systems and Technologies (CISTI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140864,"The availability of electric energy is one of the clearest indicators of economic development in the world. It is used as a sign of economic growth in times when the world demand for electricity is growing at a dizzying pace. Due to the high price of energy and knowing that the environmental problems are becoming increasingly serious, energy consumption is one of the most critical problems that are being addressed globally under different approaches, both academics and from the industry. The following article presents a basis concept for the definition of a prediction model for consumption and power generation using artificial neural networks. In order to implement the model, the data of the daily energy demand of the country Colombia were used from the first of January of the year 2000 until the 30 of December of the year 2017. The obtained model is characterized by having 13 inputs and a hidden layer with 26 neurons, the training algorithm used is Bayesian Regularization. Finally, the results obtained, as well as the conclusions and future work are presented.",J. D. Collazos; E. E. Gaona-García; P. A. Gaona-García; M. Carlos Enrique Montenegro; A. Gómez-Acosta,energy consumption;energy generation;neural networks;artificial intelligence;data analysis,2020,prediction model for energy consumption and generation based on artificial neural networks,1
77,Prediction of energy consumption time series using Neural Networks combined with exogenous series,978-1-4673-7679-2,10.1109/ICNC.2015.7377962,2015 11th International Conference on Natural Computation (ICNC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377962,"Artificial Neural Networks (ANNs) are widely used in various practical problems about time series. In this paper, a methodology based on exogenous series is used in combination with a Back Propagation (BP) neural network to predict time series. Exogenous series is chosen by correlation theory with endogenous series. In this way, the prediction output is obtained by not only the historical data but also the information external to historical data. Communication base station energy consumption is one important part of the total social energy consumption. So its energy consumption time series (ECTS) is used as the research data. We compare the prediction performance with the normal time delay neural network (TDNN), and the experiments show that the new method has a more precise and stable performance.",Bin Wu; Yu Cui; Ding Xiao; Cunyong Zhang,exogenous series;correlation theory;energy consumption time series;TDNN,2015,prediction of energy consumption time series using neural networks combined with exogenous series,1
78,Energy Consumption and Scalability Evaluation for Software Transactional Memory on a Real Computing Environment,978-1-4673-8621-0,10.1109/SBAC-PADW.2015.11,2015 International Symposium on Computer Architecture and High Performance Computing Workshop (SBAC-PADW),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423173,"Transactional Memory is a concurrent programming abstraction that overcomes several of the limitations found in traditional synchronization mechanisms. As it is a more recent abstraction, little is known about energy consumption of Software Transactional Memories (STM). In this context, this work presents an analysis and characterization of energy consumption and performance of four Transactional Memory libraries: TL2, Tiny STM, Swiss TM, and Adapt STM, using the STAMP benchmarks. Although most works in the state-of-the-art chose to evaluate Transactional Memories through simulation, in this work the benchmarks are run in actual computers, avoiding the known issues with modeling power consumption in simulators. Our results show that Swiss TM is the most efficient library of the four in terms of energy consumption and performance for the default configurations, followed by Adapt STM, Tiny STM, and TL2, for most of the execution scenarios and 8 threads at most. STM's scalability is directly tied to the strategies for detection and resolution of conflicts. In this perspective, Adapt STM is the best STM for applications with short transactions, Swiss TM presents the best results for medium transactions, and long transactions with medium/high contention are best handled by TL2. On the other hand, Tiny STM shows the worst scalability for most scenarios, but with good results for applications with very small abort rates.",T. M. Rico; M. L. Pilla; A. R. Du Bois; R. M. Duarte,Software transactional memory;transactional memory;green computing,2015,energy consumption and scalability evaluation for software transactional memory on a real computing environment,1
81,Design of artificial neural network models for the prediction of the Hellenic energy consumption,978-1-4244-8820-9,10.1109/NEUREL.2010.5644049,10th Symposium on Neural Network Applications in Electrical Engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644049,"Energy consumption predictions are essential and are required in the studies of capacity expansion, energy supply strategy, capital investment, revenue analysis and market research management. In the recent years artificial neural networks (ANN) have attracted much attention and many interesting ANN applications have been reported in power system areas, due to their computational speed, their ability to handle complex non-linear functions, robustness and great efficiency, even in cases where full information for the studied problem is absent. In this paper, several ANN models were addressed to identify the future energy consumption. Each model has been constructed using different structures, learning algorithms and transfer functions in order the best generalizing ability to be achieved. Actual input and output data were used in the training, validation and testing process. A comparison among the developed neural network models was performed in order the most suitable model to be selected. Finally the selected ANN model has been used for the prediction of the Hellenic energy consumption in the years ahead.",P. Karampelas; V. Vita; C. Pavlatos; V. Mladenov; L. Ekonomou,Artificial neural networks;energy consumption;installed capacity;prediction,2010,design of artificial neural network models for the prediction of the hellenic energy consumption,1
82,Adaptive neural network prediction model for energy consumption,978-1-61284-840-2,10.1109/ICCRD.2011.5763864,2011 3rd International Conference on Computer Research and Development,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763864,"This paper discusses on the adaptive neural network model for predicting the energy consumption at a metering station. The function of the metering system is to calculate the energy consumption of the outgoing gas flow. To ensure the robustness of the developed model, it is suggested to make the model an adaptive model that will periodically update the weights. This will ensure the reliability of the model. A dynamic prediction model that can adapt itself to changes in the energy consumption pattern is desirable especially for short-term energy prediction. It is also important for an on-line running of the metering system. Two methods of weights update are proposed and tested, namely the accumulative training and sliding window training. The developed adaptive neural network model is then compared with the static neural network. Adaptive neural network for energy consumption has shown better result and recommended for implementation in the metering station.",M. J. Ismail; R. Ibrahim; I. Ismail,accumulative training method;adaptive neural network;metering system;sliding window training method,2011,adaptive neural network prediction model for energy consumption,1
83,Analysis and Prediction of Hourly Energy Consumption Based on Long Short-Term Memory Neural Network,978-1-7281-9101-0,10.1109/ICOIN50884.2021.9333968,2021 International Conference on Information Networking (ICOIN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9333968,"Due to the advancements of electricity dependent machinery, the excessive growth of power consumption has increased exponentially. Therefore, analysis and prediction of the energy consumption system will offer the future demand for electricity consumption and improve the power distribution system. On account of several challenges of existing energy consumption prediction models that are limiting to predict the actual energy consumption properly. Thus, to conquer the energy prediction method, this paper analyzes fourteen years of energy consumption data collected on an hourly basis, an open source dataset from kaggle. Moreover, the paper initiates a Long Short Term Memory (LSTM) based approach to predict the energy consumption based on the actual dataset. The empirical results demonstrate that the proposed LSTM architecture can efficiently enhance the prediction accuracy of energy consumption.",R. Akter; J. -M. Lee; D. -S. Kim,Energy consumption;LSTM neural network;prediction analysis,2021,analysis and prediction of hourly energy consumption based on long short term memory neural network,1
84,Prediction of energy consumption based on LSTM Artificial Neural Network,978-1-6654-7108-4,10.1109/SSD54932.2022.9955883,"2022 19th International Multi-Conference on Systems, Signals & Devices (SSD)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955883,"Short term power consumption forecasting has recently gained increasing attention due to the increasing development of smart grids and the advent of advanced measuring infrastructure. In fact, prediction of future power loads turns out to be a key issue to avoid energy wastage and to build effective power management strategies. Energy consumption information can be considered as historical time se-ries data that are required to extract all meaningful knowledge and then forecast the future consumption. This paper proposes a novel approach based on Long Short-Term Memory (LSTM) network for predicting the periodic energy consumption. The LSTM network has been favored in this work to predict future load consumption and prevent consumption peaks. This network is constructed to model and forecast sequential data. To provide a comprehensive evaluation of this method, we have performed several experiments using real measurement data power consumption in a French city. The experimental results on various time horizons demonstrate that the proposed method has a higher prediction performance compared to several traditional forecasting methods, such as the autoregressive moving average model (ARMA), Therefore, these predictions allow us to make decisions in advance and trigger load shedding in cases where consumption exceeds the authorized threshold in order to protect the electricity network.",S. Mahjoub; L. Chrifi-Alaoui; B. Marhic; L. Delahoche; J. -B. Masson; N. Derbel,Neural networks;Long Short-Term Memory (LSTM);Energy consumption prediction,2022,prediction of energy consumption based on lstm artificial neural network,1
85,ss5:A Neural Network-based Energy Consumption Prediction Model for Feature Selection and Paremeter Optimization of Winders,978-1-7281-6855-5,10.1109/ICNSC48988.2020.9238073,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238073,"Textile industry has become the third largest energy consuming industry after engineering and chemical sectors. In order to reduce the energy consumption in the textile industry, a neural network is used to establish the energy consumption prediction model of the winder. In this research, the model is specially designed as the objective function to optimize the energy consumption of the winders. Firstly, the neural network error back propagation is analyzed and the absolute values of the weight coefficient matrix product are used to approximate the influence of input parameters on the model output. The values are also used to select the core parameters to optimize the model. Secondly, the single-dimensional search method is applied for a set of parameter values within a reasonable interval of the whole input parameters to reduce the energy consumption. Experimental results indicate that a set of core parameters can be determined to remodel after the training of the neural network model. In addition, a set of parameter values obtained by single-dimensional search can also be used to effectively reduce the energy consumption of the winders. The proposed method effectively solves the problem and is efficient and straightforward. The feasibility of the proposed approach is validated through the comparative analysis.",B. Wang; X. Zheng; J. Bao; J. Li,Winders;energy consumption prediction;neural network;feature selection;single-dimensional search;parameter optimization,2020,ss a neural network based energy consumption prediction model for feature selection and paremeter optimization of winders,1
87,Prediction and Optimization on Energy Consumption of Data Center Based on Multi-layer Feedforward Neural Network,978-1-7281-1722-5,10.1109/APAP47170.2019.9224637,2019 IEEE 8th International Conference on Advanced Power System Automation and Protection (APAP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224637,"There will be the characteristics of large amounts of equipments, high parameter coupling, non-linear calculation and complex modeling for the conventional energy consumption calculation. Multi-layer feedforward neural network model is used to establish relations between the parameters of air conditioning system, computer equipments, power supply system and the energy consumption values. The error back-propagation algorithm based on gradient descent strategy is used to adjust connection weight and threshold of the neurons in hidden layers. The genetic algorithm is used on the initial weights and thresholds optimization and the search for minimum energy consumption. Through the prediction of energy consumption with the variation of uncontrollable parameters, the adjustment of controllable parameters such as the temperature target value of air conditioner, the control mode of fresh air exchangers and humidifiers can obtain the target of energy consumption minimization.",S. Zhang; X. Ye; Y. Ren,Air conditioning system;Energy Consumption Optimization;Error Back-Propagation;Genetic Algorithm;Multi-layer Feedforward Neural Network,2019,prediction and optimization on energy consumption of data center based on multi layer feedforward neural network,1
89,Measuring Application Software Energy Efficiency,,10.1109/MITP.2012.39,IT Professional,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171963,"Researchers have studied the energy efficiency of hardware, but what about application software? Using an experimental approach, the authors show how applications affect total energy consumption and discuss design factors that could influence software energy efficiency.",E. Capra; C. Francalanci; S. A. Slaughter,green IT;software energy efficiency;software design;application development environment;information technology,2012,measuring application software energy efficiency,1
90,Measuring energy footprint of software features,978-1-5090-1428-6,10.1109/ICPC.2016.7503726,2016 IEEE 24th International Conference on Program Comprehension (ICPC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7503726,"With the proliferation of Software systems and the rise of paradigms such the Internet of Things, Cyber-Physical Systems and Smart Cities to name a few, the energy consumed by software applications is emerging as a major concern. Hence, it has become vital that software engineers have a better understanding of the energy consumed by the code they write. At software level, work so far has focused on measuring the energy consumption at function and application level. In this paper, we propose a novel approach to measure energy consumption at a feature level, cross-cutting multiple functions, classes and systems. We argue the importance of such measurement and the new insight it provides to non-traditional stakeholders such as service providers. We then demonstrate, using an experiment, how the measurement can be done with a combination of tools, namely our program slicing tool (PORBS) and energy measurement tool (Jolinar).",S. Islam; A. Noureddine; R. Bashroush,,2016,measuring energy footprint of software features,1
93,The estimation of monthly electrical energy consumption with feed forward neural networks,978-1-7281-1624-2,10.1109/ECAI46879.2019.9042121,"2019 11th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042121,"In this paper we present a method for the estimation of the monthly electric energy consumption, in a house, using a feed forward neural network. The network is trained with the backpropagation algorithm and the patterns used for training are the previous months' consumption. The network was trained using real consumptions from a house, from the previous three years. We used for the network three input neurons, and on these three inputs will be placed the consumptions for the previous three months, and the network will estimate on its output the consumption for the current month.",A. Ene; C. Stirbu,feed forward neural network;electric energy consumption;non-linear function approximation,2019,the estimation of monthly electrical energy consumption with feed forward neural networks,1
94,Pixel Similarity Based Computation and Power Reduction Technique for H.264 Intra Prediction,978-1-4244-7843-9,10.1109/FPL.2010.41,2010 International Conference on Field Programmable Logic and Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694241,"H.264 intra prediction algorithm has a high computational complexity. This paper proposes a pixel similarity based technique for reducing the amount of computations performed by H.264 intra prediction algorithm and therefore reducing the power consumption of H.264 intra prediction hardware. The proposed technique performs a small number of comparisons among neighboring pixels of the current block before the intra prediction process. If the neighboring pixels of the current block are similar, the prediction equations of H.264 intra prediction modes are simplified for this block. The proposed technique reduces the amount of computations performed by 4×4 luminance prediction modes up to 68% with a small comparison overhead. This technique increases the PSNR slightly for some videos and it decreases the PSNR slightly for some videos. We also implemented an efficient 4×4 intra prediction hardware including the proposed technique using Verilog HDL. The proposed technique reduced the power consumption of this hardware up to 57%.",Y. Adibelli; M. Parlak; I. Hamzaoğlu,H.264;Intra Prediction;Computation Reduction;Low Power;Hardware Implementation;FPGA,2010,pixel similarity based computation and power reduction technique for h intra prediction,1
95,A Computation and Power Reduction Technique for H.264 Intra Prediction,978-1-4244-7839-2,10.1109/DSD.2010.115,"2010 13th Euromicro Conference on Digital System Design: Architectures, Methods and Tools",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5615438,"H.264 intra prediction algorithm has a very high computational complexity. This paper proposes a technique for reducing the amount of computations performed by H.264 intra prediction algorithm. For each intra prediction equation, the proposed technique compares the pixels used in this prediction equation. If the pixels used in a prediction equation are equal, this prediction equation is simplified significantly. By exploiting the equality of the pixels used in prediction equations, the proposed technique reduces the amount of computations performed by 4x4 luminance prediction modes up to 78% with a small comparison overhead. The proposed technique does not affect the PSNR and bit rate. We also implemented an efficient 4x4 intra prediction hardware including the proposed technique using Verilog HDL. We quantified the impact of the proposed technique on the power consumption of this hardware on a Xilinx Virtex II FPGA using Xilinx XPower, and it reduced the power consumption of this hardware up to 13.7%.",Y. Adibelli; M. Parlak; I. Hamzaoglu,H. 264;Intra Prediction;Computation Reduction;Low Power;Hardware Implementation;FPGA,2010,a computation and power reduction technique for h intra prediction,1
97,Power Consumption Prediction of Digital Circuits using Machine Learning,978-1-6654-4290-9,10.1109/AISP53593.2022.9760542,2022 2nd International Conference on Artificial Intelligence and Signal Processing (AISP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760542,"The demand for Integrated Circuits (ICs) is increasing exponentially, leading to the challenges of a more reliable and effective Electronic Design Tool (EDA) for the circuit design flow. To overcome such limitations Machine Learning (ML) is used, which can learn from the previous design data and can apply it to the unknown design given to it. In this context, the paper proposes the use of the regression technique of ML to estimate the power consumption of the MOSFET-based digital circuits. For this purpose, to train the ML-based regressor model, a dataset is created from the PMOS based Resistive Load Inverter (RLI), NMOS based RLI, and CMOS-based NAND gate layout. For the formation of the dataset, a 90nm MOS technology node is used and it inculcates the features like capacitance, resistance, number of MOSFET, their respective width and length, and the average power consumption of the respective layout. The regressor model used to predict the power consumption in this work is linear regressor, polynomial regressor, random forest regressor, decision tree regressor, and the extra tree regressor. At last, from the experimental results, it is observed that the extra tree regressor performs better for the RLI circuits with the MSE value of $4.02\times 10^{-10}$ and $\mathrm{R}^{2}$ value of 0.61, and for the NAND gate, the polynomial linear regressor excels with the MSE value of $7.27\times 10^{-10}$ and $\mathrm{R}^{2}$ value of 0.65.",M. D. Bhavesh; N. A. Anilkumar; M. I. Patel; R. Gajjar; D. Panchal,Machine Learning;VLSI;Power Consumption;Design Automation;EDA,2022,power consumption prediction of digital circuits using machine learning,1
100,Evaluating Network-Based DoS Attacks under the Energy Consumption Perspective: New Security Issues in the Coming Green ICT Area,978-1-4577-1455-9,10.1109/BWCCA.2011.66,"2011 International Conference on Broadband and Wireless Computing, Communication and Applications",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103061,"In the green Information and Communication Society (ICS), new form of Denial of Service (DoS) attacks may be put in place: exploiting the computational and storage resources of datacenters with the aim of consuming as much energy as possible, causing detrimental effects, from high costs in the energy bill, to penalization for exceeding the agreed quantity of CO2 emissions, up to complete denial of service due to power outages. To the best of our knowledge, this is the first paper which investigates the impacts of network-based DoS attacks under the energy consumption perspective. We analyzed different types of such attacks with their impacts on the energy consumption, and showed that current energy-aware technologies may provide attackers with great opportunities for raising the target facility energy consumption and consequently its green house gases (GHG) emissions and costs.",F. Palmieri; S. Ricciardi; U. Fiore,denial of services DoS;energy consumption;networking;datacenters;green house gasses emissions GHG,2011,evaluating network based dos attacks under the energy consumption perspective new security issues in the coming green ict area,1
101,Fast and accurate workload-level neural network based IC energy consumption estimation,978-1-5090-5052-9,10.1109/SMACD.2017.7981598,"2017 14th International Conference on Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design (SMACD)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981598,"A fast, yet accurate nanoscale IC energy estimation is a design-time desideratum for area-delay-power-reliability optimized circuits and architectures. This paper introduces an IC energy estimation approach, which instead of sequentially propagating workload vectors throughout the circuit, relies on an one time propagation of the workload statistics. To this end, the basic gates need be SPICE pre-characterized with respect to (w.r.t.) static and dynamic energy consumption per input transition type and Neural Network based gate models constructed and trained in order to estimate gate output statistics and consumed energy based on gate input statistics, i.e., the `0' → `0', `0' → `1', `1' → `0', and `1' → `1' transition probabilities. Both pre-characterization and training are done once per technology node and do not contribute to the actual evaluation time. In this way, regardless of n, the number of workload input vectors, by propagating signal statistics instead of logic values the overall circuit energy consumption is evaluated in one instead of n circuit traversals. Moreover, as opposed to the constant and equal gate delay assumption utilized in state of the art energy estimation methods, the proposed approach takes into account the real gate propagation delays, which yields estimates that are closer to the actual energy figures. We evaluated with the proposed method the static and dynamic energy consumption for a set of ISCAS'85 circuits and a 10, 508-gate hashing circuit, using TSMC 40nm CMOS technology, and 50, 000-vector workloads. The experiments indicate that our method provides an estimation error below 2.6% and 1.5% for dynamic and static energy, respectively, when compared to the accurate SPICE measurements, while providing an estimation speedup in the order of 50, 000x.",N. C. Laurenciu; S. D. Cotofana,Energy Estimation;Neural Networks,2017,fast and accurate workload level neural network based ic energy consumption estimation,1
102,Microcontroller energy consumption estimation based on software analysis for embedded systems,978-1-4673-6576-5,10.1109/NORCHIP.2015.7364397,2015 Nordic Circuits and Systems Conference (NORCAS): NORCHIP & International Symposium on System-on-Chip (SoC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364397,"In this paper, we present a energy consumption estimation method for microcontrollers. Vast amount of work in this topic has been done based on measuring the energy per instruction in low level programming languages like assembler. However, in our approach we use solely C programs and instructions without any regard to lower level languages. The method is based on measuring energy per each C instruction in the benchmark program and using the result to estimate the total energy consumed by the program. As a test case we use simple image processing algorithm including Gaussian blur and edge detection on PIC PIC32MX460F512L microcontroller. We show that the method is scalable on different microcontroller voltages and clock frequencies with only one set of measurements to reduce the amount of preparation work for estimation. We show that the estimation results give us credibility with less than 7% error.",P. Ruberg; K. Lass; P. Ellervee,,2015,microcontroller energy consumption estimation based on software analysis for embedded systems,1
103,Energy Consumption Estimation of Software Components Based on Program Flowcharts,978-1-4799-6123-8,10.1109/HPCC.2014.102,"2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056795,"This paper presents and evaluates a new approach of energy estimation for single software components based on program flowcharts. This estimation is designed to be applicable early in the design process, which enables system designer to evaluate different design variants with respect to the energy consumption of the later system. The energy estimation model is based on individual flowchart elements and execution probabilities for branches and iterations. The used flowchart elements are for arithmetical calculations, flow control and reads/writes, which are a selection of possible elements used to show the feasibility of the approach. The estimation model is verified in a first step by using three commercially available benchmarks. The flowcharts of these are utilized to estimate the energy consumption by using the presented model. The comparison between estimated and measured energy consumption of an exemplary embedded system results in an estimation error bandwidth between -11.9 % and +6.9 %. The main benefit of the presented approach is the applicability within the development phase ""System Design"" [1], i.e. Previous to any software implementation. This is realized by using only available information of that development phase and generic elements to estimate the energy consumption.",P. Heinrich; H. Bergler; D. Eilers,energy estimation;energy-efficiency;embedded;adaptive systems;automotive electronics,2014,energy consumption estimation of software components based on program flowcharts,1
104,Software Energy Consumption Estimation at Architecture-Level,978-1-5090-3727-8,10.1109/ICESS.2016.35,2016 13th International Conference on Embedded Software and Systems (ICESS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074433,"The architecture of software systems can be naturally modeled as complex networks, where entities of software are nodes and interactions between entities are edges. These edges represent data-flows, instruction-flows and control-flows of the software, and these flows driving hardware circuit is the internal cause of the energy consumption of the software. In this research, we model software systems as complex networks, assuming that there is a nonlinear function relation between network characteristics of software and its energy consumption. Based on this assumption, we propose a software energy consumption estimation model at architecture-level. First we measure five network characteristics of software, and then use extreme learning machine (ELM) to fit the relation between network characteristics of software and its energy consumption. Finally we evaluate our energy model on Linux platform and the results show that our model can achieve a 7.9% error rate compared to pTop model, which indicates our assumption is reasonable and our software energy model is effective.",D. Li; B. Guo; Y. Shen; J. Li; J. Wang; Y. Huang; Q. Li,energy consumption estimation;architecture-level;complex networks;software energy model,2016,software energy consumption estimation at architecture level,1
105,Power Efficient Motion Estimation using Multiple Imprecise Metric Computations,1-4244-1016-9,10.1109/ICME.2007.4285083,2007 IEEE International Conference on Multimedia and Expo,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4285083,"In this paper, we propose power efficient motion estimation (ME) using multiple imprecise sum of absolute difference (SAD) metric computations. We extend the recent work of Varatkar et al (2006) by providing analytical solutions based on modelling of computation errors due to voltage overscaling (VOS) and sub-sampling (SS). Results show that our solutions provide significantly better performance in the sense of rate increase for fixed QP, e.g., less than 5% increase, while in Varatkar et al (2006) the rate increase could be as high as 20%. It allows us to apply lower voltage which leads to additional power saving. Our analysis also allows us to compare different ME algorithms (e.g., full search vs. a fast algorithm) and SAD computation architectures (parallel vs. serial) in terms of their robustness to imprecise metric computations and their power efficiency. Finally, we demonstrate that additional power savings can be achieved by removing redundancy between the various computations.",I. S. Chong; A. Ortega,voltage overscaling (VOS);error tolerance (ET);matching metric computation (MMC);imprecise computation,2007,power efficient motion estimation using multiple imprecise metric computations,1
106,Prediction method about power consumption by using utilization rate of resource in cloud computing environment,978-1-4673-8796-5,10.1109/BIGCOMP.2016.7425924,2016 International Conference on Big Data and Smart Computing (BigComp),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425924,"Cloud computing technologies are suited for reducing costs of maintaining IT infrastructure and initial investment. As cloud computing is developed, problems of power consumption for maintaining the cloud computing environment are occurred. So, several studies for reducing power consumption have been performed. However study for predicting power consumption in cloud computing environment is insufficient. Thus, we propose a prediction method about power consumption by using utilization rate of CPU, Memory, and Hard disk. Also, to prove accuracy of our prediction method, we perform CPU test to compare and analyze predictive power consumption and actual power consumption. As a result, average error rate between the predictive power consumption and actual power consumption value is about 4.22% in the CPU test.",S. Park; Youngsong Mun,Cloud computing;power measurement;power consumption;data center;prediction method,2016,prediction method about power consumption by using utilization rate of resource in cloud computing environment,1
107,An early design estimation approach to synthesize the low-power pre-computation-based content addressable memory,978-1-61284-931-7,10.1109/ICOS.2011.6079244,2011 IEEE Conference on Open Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079244,"Content addressable memory (CAM) is often used in many applications which require searching in high speed such as network router, translation look-aside buffer (TLB), Huffman decoding, discrete cosine transform or the applications having quick lookup table operation. Due to its operational characteristic of parallel data searching, the power consumption is also exacerbated. In this paper, we propose a methodology for synthesizing a low power pre-computation-based content addressable memory (PB-CAM) effectively. The concept of discrete uniform distribution is adopted in pre-computation block so as to verify the outcomes of power reduction when the adaptive parameter extractors are synthesized in a different manner. With our proposed approach, we are able to estimate the tendency towards power consumption efficiently and determine which type of parameter extractor is superior in power reduction for the specific data. Experiment shows the power consumption of our approach is better by at least 29% compared with original parameter extractors.",R. Shen; C. Peng; F. Lai,CAM;PB-CAM;parameter extractor;one's count;Block-XOR;Gate Block Selection;DAI(Discard and Interlace),2011,an early design estimation approach to synthesize the low power pre computation based content addressable memory,1
108,Approximated Prediction Strategy for Reducing Power Consumption of Convolutional Neural Network Processor,978-1-5090-1437-8,10.1109/CVPRW.2016.113,2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789603,"Convolutional neural network (CNN) is becoming popular because of its great ability for accurate image recognition. However, the computational cost is extremely high, which increases power consumption of embedded CV systems. This paper proposes an efficient computing method, LazyConvPool (LCP), and its hardware architecture to reduce power consumption of CNN-based image recognition. The LCP exploits redundancy of operations in CNN and only executes essential convolutions by an approximated prediction technique. We also propose Sign Connect, which is a low computational-cost approximated prediction without any multiplications. The experimental evaluation using image classification dataset shows that the proposed method reduces the power consumption by 17.8%-20.2% and energy consumption by 11.4%-14.1% while retaining recognition performance.",T. Ujiie; M. Hiromoto; T. Sato,,2016,approximated prediction strategy for reducing power consumption of convolutional neural network processor,1
110,Neural network methods for fast and portable prediction of CPU power consumption,978-1-5090-0172-9,10.1109/IGCC.2015.7393702,2015 Sixth International Green and Sustainable Computing Conference (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393702,"The need for energy efficient computing has established performance-per-watt as a first-class metric for evaluating HPC applications. Consequently, optimizations that target HPC systems and data centers are required to dynamically monitor system power consumption in order to be effective. Although newer architectures are making power sensors available on the chip, the general state of power measurement tools across different architectures remains deficient. This paper describes a neural-network based model for fine-grain, accurate and low-cost power estimation. The main novelty of the proposed approach is its portability. The methodology can be adopted to predict power consumption not only on a range of current processors but future architectures as well. This portability is achieved by taking advantage of performance monitoring units (PMU) available on current systems and applying a carefully constructed sequence of feature selection techniques. We evaluate our models along several dimensions on multiple platforms. The experimental results show that the constructed models are able to predict power consumption with high accuracy at a low overhead. The results also provide key insight as to the number of features necessary to achieve reasonable prediction accuracy.",M. Gutierrez; S. Rahman; D. Tamir; A. Qasem,,2015,neural network methods for fast and portable prediction of cpu power consumption,1
111,Neural network prediction methods of power consumption for GSHP system with bilateral variable flow,978-988-15639-3-4,10.23919/ChiCC.2017.8027651,2017 36th Chinese Control Conference (CCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8027651,In order to realize the optimal control of variable frequency circulating pumps for ground source heat pump (GSHP) system it is necessary to build the prediction model of the total power consumption of GSHP system based on running data. Firstly the power consumption analysis of GSHP system with bilateral variable flow is presented. Then a Hyberball Cerebellar Model Articulation Controller (HCMAC) prediction model of power consumption for GSHP system is established. The inputs of model include circulating pump frequency at user-side circulating pump frequency at ground-source side and current air conditioning load. Finally according to the characteristics of the learning data of the GSHP system a differential parallel HCMAC learning method is proposed to improve the learning accuracy. The simulation experiments are performed according to the learning data provided by TRNSYS simulation platform. The experimental results show that the accuracy of differential parallel CMAC prediction model is better than that of the general HCMAC prediction model.,L. Hui; D. Peiyong; W. Lin; Y. Yu,GSHP;variable frequency;HCMAC neural network;prediction model;power consumption,2017,neural network prediction methods of power consumption for gshp system with bilateral variable flow,1
112,Machine learning for energy efficiency: Automatic detection of electric loads from power consumption,978-8-8872-3737-5,10.23919/AEIT.2017.8240544,2017 AEIT International Annual Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240544,"This work deals with the problem of energy efficiency and saving: we present a method to automatically extract behavioral rules from consumption data, so that these rules can be applied or fed to an automatic control system. To extract behavioral rules we shall be able to both (i) define power plants similarity techniques and (ii) analyze and gather rules from data, making the correct assumptions.",C. Tomazzoli; S. Scannapieco,energy saving;energy efficiency;machine learning;automatic reasoning,2017,machine learning for energy efficiency automatic detection of electric loads from power consumption,1
114,Current variations measurements for the estimation of software-related power consumption,0-7803-7218-2,10.1109/IMTC.2002.1007205,IMTC/2002. Proceedings of the 19th IEEE Instrumentation and Measurement Technology Conference (IEEE Cat. No.00CH37276),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1007205,"A current measurement configuration for the estimation of the power consumption of low-power processing systems is presented in this work. The problem addressed is to measure the current variations of digital circuits (and especially of embedded processing circuits) and try to identify from these measurements the energy consumption variations associated with certain tasks performed by the system software. Accurate monitoring of the instantaneous variations of the power supply current may provide the appropriate information for the estimation of the power consumption at different operating situations of the processor (core) and of the overall processing system as well (consumption of peripheral units). The proposed instantaneous current measuring approach, along with the execution of special test programs for analysis of inter-instruction effects, is expected to provide clear information of the power behavior of single-chip processing systems.",T. Laopoulos; P. Neofotistos; C. Kosmatopoulos; S. Nikolaidis,,2002,current variations measurements for the estimation of software related power consumption,1
115,Estimation of power consumption of each application based on software dependency in android,978-1-5090-4045-2,10.1109/GCCE.2017.8229436,2017 IEEE 6th Global Conference on Consumer Electronics (GCCE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8229436,"Several reports showed that the most important issue in smartphones was its power consumption. For saving power consumption, estimating power is important. The power consumption of each application depends on other applications installed in the device. In this paper, we propose a method for estimating power consumption of each application considering this software dependency. We then evaluate the method with intermittently invoked applications and show that the method can estimate power consumption accurately.",S. Kurihara; S. Fukuda; S. Yamaguchi; M. Oguchi,Android;Battery-draining application;GPS,2017,estimation of power consumption of each application based on software dependency in android,1
116,Estimation of Power Consumption of Each Application Caused by Device Lock Considering Software Dependency in Smartphones,978-1-5386-2087-8,10.1109/CANDAR.2017.56,2017 Fifth International Symposium on Computing and Networking (CANDAR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345491,"Several reports showed that the most important problem in smartphones was its power consumption. Detection of battery draining applications based on estimating power consumption of each application is essential for saving power consumption. However, estimating is difficult because the power consumption of an application depends on its device. We think there are dependencies on hardware and software. The software dependency means that the increased and decreased power consumption by installing and uninstalling a certain application depend on the other applications installed in the device. In this paper, we focus on software dependency of power consumption of each application caused by a device lock, called WakeLock, and discuss its estimation. We propose a method for estimating power consumption considering software dependency of WakeLock based on an existing method. We then present an evaluation of the proposed method using practical smartphone applications and demonstrate that the method can estimate the power consumption more accurately than the standard method which does not consider the dependency.",S. Kurihara; S. Fukuda; M. Oguchi; S. Yamaguch,smartphone;Android;WakeLock;software dependency;battery draining application,2017,estimation of power consumption of each application caused by device lock considering software dependency in smartphones,1
117,Energy consumption powered by graphics processing units (GPU) in response to the number of operating computing unit,978-1-5090-1322-7,10.1109/ICIEAM.2016.7910995,"2016 2nd International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7910995,"The article presents a method of measuring energy consumption with the NVIDIA graphics processing unit and energy consumption in response to the number of operating units. The architecture of graphics processing unit has been considered as well as the method of energy consumption of GPU. The experiment is based on multiplication of matrices. Brief results and dependency of counting time from number of computing elements are also demonstrated. A simple way to understand the difference between a CPU and GPU is to compare how they process tasks. The CPU consists of a few cores optimized for sequential serial processing while the GPU has a massively parallel architecture consisting of thousands of smaller, more efficient cores designed for handling multiple tasks simultaneously.",I. K. Huzmiev; Z. A. Chipirov,microcontroller;energy;efficiency;parallel programming;graphics processing unit (GPU);computing unit;energy consumption,2016,energy consumption powered by graphics processing units gpu in response to the number of operating computing unit,1
119,Electric power consumption forecast of life energy sources based on fuzzy neural network,978-1-61284-704-7,10.1109/ITiME.2011.6130840,2011 IEEE International Symposium on IT in Medicine and Education,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6130840,"A fuzzy neural network(FNN) with five layers is proposed in this article. Aim at the structure optimization of network, a new node selection method and corresponding back propagation learning algorithm are presented. We use real history data to train the network model at the same time and to forecast the result after the train finished. Test results illustrate its good practicability to power consumption forecast of life energy sources.",Shao Xiufeng; Zhang Jian,fuzzy neural network;fuzzy integrated judge;electric power consumption forecast of life energy sources,2011,electric power consumption forecast of life energy sources based on fuzzy neural network,1
120,A light-weight hardware/software co-design for pairing-based cryptography with low power and energy consumption,978-1-5386-2656-6,10.1109/FPT.2017.8280149,2017 International Conference on Field Programmable Technology (ICFPT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280149,"Embedded electronic devices and sensors such as smartphones, smart watches, medical implants, and Wireless Sensor Nodes (WSN) are making the “Internet of Things” (IoT) a reality. Such devices often require cryptographic services such as authentication, integrity and non-repudiation, which are provided by Public-Key Cryptography (PKC). As these devices are severely resource-constrained, choosing a suitable cryptographic system is challenging. Pairing Based Cryptography (PBC) is among the best candidates to implement PKC in lightweight devices. In this research, we present a fast and energy efficient implementation of PBC based on Barreto-Naehrig (BN) curves and optimal Ate pairing using hardware/software co-design. Our solution consists of a hardware-based Montgomery multiplier, and pairing software running on an ARM Cortex A9 processor in a Zynq-7020 System-on-Chip (SoC). The multiplier is protected against simple power analysis (SPA) and differential power analysis (DPA), and can be instantiated with a variable number of processing elements (PE). Our solution improves performance (in terms of latency) over an open-source software PBC implementation by factors of 2.34 and 2.02, for 256- and 160-bit field sizes, respectively, as measured in the Zynq-7020 SoC.",A. Salman; W. Diehl; J. -P. Kaps,ECC;pairing-based cryptography;Montgomery multiplier;hardware-software co-design;system-on-chip;embedded,2017,a light weight hardware software co design for pairing based cryptography with low power and energy consumption,1
121,Energy consumption analysis of software polar decoders on low power processors,978-0-9928-6265-7,10.1109/EUSIPCO.2016.7760327,2016 24th European Signal Processing Conference (EUSIPCO),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7760327,"This paper presents a new dynamic and fully generic implementation of a Successive Cancellation (SC) decoder (multi-precision support and intra-/inter-frame strategy support). This fully generic SC decoder is used to perform comparisons of the different configurations in terms of throughput, latency and energy consumption. A special emphasis is given on the energy consumption on low power embedded processors for software defined radio (SDR) systems. A N=4096 code length, rate 1/2 software SC decoder consumes only 14 nJ per bit on an ARM Cortex-A57 core, while achieving 65 Mbps. Some design guidelines are given in order to adapt the configuration to the application context.",A. Cassagne; O. Aumage; C. Leroux; D. Barthou; B. Le Gal,,2016,energy consumption analysis of software polar decoders on low power processors,1
124,A Convolutional neural network and sequence-to- sequence model based energy disaggregation algorithm for non-intrusive load monitoring,978-1-83953-605-2,10.1049/icp.2022.0242,22nd International Symposium on High Voltage Engineering (ISH 2021),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800622,"With the achievement of the sensing technology and communication network, the smart monitoring and computing equipment becomes more and more common, which generates the massive data of different types and sampling frequency. The detailed information in the collected electricity usage data shows the load features and residents' electricity utilizing style, and the achievement of artificial intelligence and machine learning algorithms provide better ways for process and analysis. The appliance-level energy consumption information obtained by non-intrusive load monitoring is a great benefit for energy saving by scientific management. For this purpose, this paper adopted an energy disaggregation algorithm based on CNN and Seq2Seq model to analyse the appliances' energy consumption information. We use the local attention mechanism in decoding to process the information in the long source sequence, expected to reduce the information compression and computational complexity. The proposed method for non-intrusive load monitoring succeeds in disaggregation from the total power profiles to target appliance power profiles very close and provides more effective performance than the traditional CNN and LSTM method.",W. Lian; T. Wu; Y. He; Z. Shan; G. Si,,2021,a convolutional neural network and sequence to sequence model based energy disaggregation algorithm for non intrusive load monitoring,1
125,Edge Computing Technique for a 87% Energy Saving for IoT Device Dedicated to Environmental Monitoring,978-1-7281-7670-3,10.1109/LASCAS51355.2021.9459177,2021 IEEE 12th Latin America Symposium on Circuits and System (LASCAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459177,"In this paper, we propose a method based on polynomial regression to perform data compression at the edge in order to reduce the energy consumption of connected objects. Our study is based on the trade-off between data compression at the edge and minimizing the error on data reconstruction on the server. A polynomial regression was experienced on a two-year database of temperature measurements. The error percentage between our data compression and the real temperature evolution have been assessed to determine the most relevant polynomial regression. A digital implementation of the data compression on an Arduino was carried out with a set of data collected over three weeks of experiments. The analyzis of the results concluded about the efficiency of our method with a reduction of 87% energy with an acceptable accuracy of 0.2° C for temperature data collection.",F. Rivet; L. Foucaud; G. Ferré,Data Aggregation;Polynomial Regression;IoT;Power Consumption,2021,edge computing technique for a energy saving for iot device dedicated to environmental monitoring,1
129,Forecasting Energy Efficiency and Energy Consumption in Bulgaria by Examining the Energy Intensity Indicator Using Neural Networks,978-1-7281-4346-0,10.1109/SIELA49118.2020.9167069,2020 21st International Symposium on Electrical Apparatus & Technologies (SIELA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9167069,"The energy policy of a country is crucial to the prosperity of its economy. There are many factors to consider - dependence on imports, diversification of energy sources, increasing global energy demand, energy efficiency, climate impact, etc. Effective energy planning is based on the estimated energy consumption and the energy efficiency of the economy. The article presents the results of researches conducted for these two indicators, the subject of the study being the energy system of the Republic of Bulgaria. Mathematical models are presented for forecasting the energy intensity of the economy by studying the trend model with time series and through artificial neural networks. A neural network model for predicting the final energy consumption has also been developed, based on data on the gross domestic product and the energy intensity of the economy.",K. Yotov; E. Hadzikolev; S. Hadzikoleva,forecasting energy efficiency;energy consumption,2020,forecasting energy efficiency and energy consumption in bulgaria by examining the energy intensity indicator using neural networks,1
130,A study on server Sleep state transition to reduce power consumption in a virtualized server cluster environment,978-1-4673-0298-2,10.1109/COMSNETS.2012.6151371,2012 Fourth International Conference on Communication Systems and Networks (COMSNETS 2012),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6151371,"Growth of Cloud computing has fueled the demand for large infrastructures called data centers. While the objective of the cloud computing ecosystem is to move computation and processing away towards a centralized environment, the fallout lies in the power and energy consumption of these infrastructures. Reducing power consumption is an essential requirement for Cloud resource providers to decrease operating costs. One of the options to reduce power consumption is to reduce the number of servers in IDLE (unused) state— as these IDLE servers consume as much as 60% of peak power. Number of servers in IDLE state can be reduced by turning off IDLE servers or transitioning these IDLE servers to low power SLEEP state. With virtualization being the backbone to provision cloud computing services, we use simulation to study and report the impact of using SLEEP state on the server with its virtual machines (VM) servicing application workload requests. We look at two parameters: a) power consumption of the cloud computing environment, b) average response time per request. Our simulation results show that using SLEEP state at server level, and the server with its VMs' servicing application workload requests, we can achieve a 2% savings in average power usage and around 27% savings in average response time per request.",V. K. Mohan Raj; R. Shriram,Power Aware Computing;Server power states;Virtualized environment,2012,a study on server sleep state transition to reduce power consumption in a virtualized server cluster environment,1
131,"Reducing Total ICT Power Consumption with Collaboration Among End Systems, Communication Network and Power Network",978-1-61284-313-1,10.1109/AINA.2011.22,2011 IEEE International Conference on Advanced Information Networking and Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763497,"The widespread use of ICT equipment is expected to increase the power consumed by ICT rapidly and it is recognized that the energy consumption of ICT equipment themselves (Green of ICT) should be one of key issues. This paper first identifies the need of the collaboration among end systems, the communication network and the power network, in order to reduce the total power consumption by the entire ICT systems. Next, this paper proposes the fundamental policies for the collaboration. One of them is to take any action to keep or put end systems or network devices in the sleep mode as much as possible when all areas have enough amount of available electric power, and to aggregate end systems and network devices in the area which has a largest amount of electric power capacity when multiple areas don't have enough amount of available electric power. Then, it is proposed to estimate the energy consumption of end systems by measuring and analyzing packets transferred in the network, in order to eliminate the processing load for information exchanges required for the collaboration among end systems and the network.",S. -i. Kuribayashi; Y. Osana,Reducing energy consumption;green of ICT;collaboration,2011,reducing total ict power consumption with collaboration among end systems communication network and power network,1
132,A 141.4 mW Low-Power Online Deep Neural Network Training Processor for Real-time Object Tracking in Mobile Devices,978-1-5386-4881-0,10.1109/ISCAS.2018.8351398,2018 IEEE International Symposium on Circuits and Systems (ISCAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8351398,"A low-power online deep neural network (DNN) training processor is proposed for a real-time object tracking in mobile devices. For a real-time object tracking, a homogeneous core architecture is proposed to achieve 1.33× higher throughput than previous DNN training processor. To reduce the external memory access (EMA), a binary feedback alignment (BFA) algorithm and an integral run-length compression (iRLC) decoder are proposed. While the BFA reduces the EMA by 11.4% compared to the conventional back-propagation approach, the iRLC decoder achieves 29.7% EMA reduction without throughput degradation. Finally, a dropout controller is proposed and achieves 43.9% power reduction through clock-gating. Implemented with 65 nm CMOS technology, the 4.4 mm2 DNN training processor achieves 141.1 mW power consumption at 30.4 frames-per-second (fps) real-time object tracking in mobile devices.",D. Han; J. Lee; J. Lee; S. Choi; H. -J. Yoo,deep neural network;training;object tracking;feedback alignment;low-power accelerators;external memory access,2018,a mw low power online deep neural network training processor for real time object tracking in mobile devices,1
135,PowerJoular and JoularJX: Multi-Platform Software Power Monitoring Tools,978-1-6654-6934-0,10.1109/IE54923.2022.9826760,2022 18th International Conference on Intelligent Environments (IE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826760,"Monitoring the power consumption of applications and source code is an important step in writing green software. In this paper, we propose PowerJoular and JoularJX, our software power monitoring tools. We aim to help software developers in understanding and analyzing the power consumption of their programs, and help system administrators and automated tools in monitoring the power consumption of large numbers of heterogeneous devices.",A. Noureddine,Power Monitoring;Measurement;Power Consumption;Energy Analysis,2022,powerjoular and joularjx multi platform software power monitoring tools,1
138,Energy consumption of virtual machine migration within varied DCN architectures,978-1-5386-7747-6,10.1109/IWCMC.2019.8766542,2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766542,"Virtual machine (VM) migration mechanism in data centers significantly improves the utilization of the server resource. While the recent work focuses on how to use VM migration to stability physical machine (PM) utilization or improve energy consumption, little attention has been agreed to network performance issues, such as architecture, link, load and inter-traffic between VMs in the data centers network (DCN) architectures. Network-aware Virtual Machine (NVM) placement and migration is developing as a very favorable technique for the optimization of compute network resource utilization, energy consumption, and network traffic minimization. Thus, NVM operation guarantees a fair share allocation of network resources, leading to a seamless VM mobility though decreasing degradation of network performance.The focus of this paper is to present the impact of several network architectures and virtualisation on how to reduce the energy consumed by virtual machine migration. We introduce a simulation setting for energy aware employing Green-Cloud simulator. The simulator is designed to detect the details of the consumed energy by datacenter components such us VMs, PMs, servers, switches, and links. The simulation results gotten for three-tier, Debug and High speed architectures show the value of each system in employing power management schema through DNS and DVFS by applying voltage scaling and dynamic shutdown technics.",N. KORTAS; H. YOUSSEF,Virtual machine;datacenter;cloud computing;Energy efficiency;GreenCloud;networks architectures,2019,energy consumption of virtual machine migration within varied dcn architectures,1
139,A Systematic Review of Energy Consumption and SLA Violation Conscious Adaptive Threshold based Virtual Machine Migration,978-1-6654-4415-6,10.1109/ICSCCC51823.2021.9478089,2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478089,"The upsurge in request of computational power with rapid progress in the Cloud, Fog and edge-technologies has escalated the need of electrical vitality with expanded outflow of harmful gases like CO2.Dynamic integration of cloud technology, the relocation of hubs and hosts amid run-time and the increase in asset availability has increased the issue. To tackle this issue, there are numerous strategies and proposed models which trim down the energy exploitation, vitality consumption, service level agreement (SLA) infringement and restrict the count of virtual machines migration etc. In this paper, considering the need of the hour, algorithms sentient about the energy consumption and SLA violations in conjunction with minimum migration time policy are considered. A state-of-art-analysis of few proposed algorithm and changes done to the adaptive threshold based VM migration techniques is conducted. It is observed that on the basis of CPU utilization threshold value and migration parameters, the hosts and nodes to be migrated are determined. Few algorithms also considered RAM available with the hosts and network Bandwidth for enhanced performance and load stabilizing. In addition, a comparative analysis of the existing algorithms is demonstrated to elucidate the best fit algorithm based on energy consumed per migration and percentage SLA violation.",A. Patel; N. Chaurasia,Virtual Machine Migration(VMM);Adaptive Threshold Algorithm based VMM(AT-VMM);SLA Violation;Energy Consumption,2021,a systematic review of energy consumption and sla violation conscious adaptive threshold based virtual machine migration,1
140,Energy Consumption Analysis of Various Dynamic Virtual Machine Consolidation Techniques in Cloud Data Center,978-1-6654-7439-9,10.1109/ICACCM56405.2022.10009565,"2022 International Conference on Advances in Computing, Communication and Materials (ICACCM)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009565,"Data centers in the cloud computing industry need tremendous energy to keep up with the rising demand for cloud resources. The two primary subsystems that make up a data center's energy usage are computing and cooling. The approach known as Dynamic Virtual Machine Consolidation (DVMC) is frequently used to lower the energy use of computer systems. Dynamic consolidation of virtual machines manages the data center in terms of energy consumption and quality of services. Energy consumption, active and overloaded Physical Machines (PMs), and VM migration counts are the key parameters to assess the performance of various VM consolidation algorithms. In this article, we have conducted simulation-based experiments and collected the energy consumption, active and overloaded hosts, and VM migration counts in each time interval of simulation duration. We plotted the results, and a comparative study was conducted to analyse the outcomes of different consolidation algorithms in terms of energy consumption and service quality. Our main goal is to figure out how the performance of the algorithm can be enhanced.",S. S. Panwar; M. M. S. Rauthan; V. Barthwal,Cloud Data Center;Energy Consumption;Dynamic Virtual Machine Consolidation;Performance Metrics;Cloud Computing,2022,energy consumption analysis of various dynamic virtual machine consolidation techniques in cloud data center,1
141,Research on a Virtual Machine Mode Transfer Method Supporting Energy Consumption Optimization,979-11-88428-08-3,10.23919/ICACT53585.2022.9728798,2022 24th International Conference on Advanced Communication Technology (ICACT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9728798,"In traditional cloud resource optimization scheduling, excessive pursuit of service performance and system reliability has resulted in low utilization of system resources and severe energy dissipation. In this paper, transfer target of virtual machines was taken into account with respect to the above problem, including virtual machine mode transfer method, hot mode sleep selection method and cold mode wake-up selection method that support energy protection. In other words, the operating mode and hot mode virtual machines are converged in a cluster of physical machines of minimum amount to reduce energy consumption by shutting down idle physical machines; the cold mode virtual machines are converged in another cluster of physical machines of as few physical machines as possible to reduce energy consumption through collective sleep. The experimental results show that the energy optimization resource adjustment strategy in this paper reduces the energy consumption of the system while ensuring the required system performance and reliability.",J. Guo; Y. Li; C. Liu; Z. Zhao; B. Zhang,Virtual machine mode transfer;Hot mode sleep method;Cold mode wake-up method;Energy consumption optimization,2022,research on a virtual machine mode transfer method supporting energy consumption optimization,1
142,Research on a Virtual Machine Mode Transfer Method Supporting Energy Consumption Optimization,979-11-88428-06-9,10.23919/ICACT51234.2021.9370393,2021 23rd International Conference on Advanced Communication Technology (ICACT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9370393,"In traditional cloud resource optimization scheduling, excessive pursuit of service performance and system reliability has resulted in low utilization of system resources and severe energy dissipation. In this paper, transfer target of virtual machines was taken into account with respect to the above problem, including virtual machine mode transfer method, hot mode sleep selection method and cold mode wake-up selection method that support energy protection. In other words, the operating mode and hot mode virtual machines are converged in a cluster of physical machines of minimum amount to reduce energy consumption by shutting down idle physical machines; the cold mode virtual machines are converged in another cluster of physical machines of as few physical machines as possible to reduce energy consumption through collective sleep. The experimental results show that the energy optimization resource adjustment strategy in this paper reduces the energy consumption of the system while ensuring the required system performance and reliability.",J. Guo; Y. Li; C. Liu; Z. Zhao; B. Zhang,Virtual machine mode transfer;Hot mode sleep method;Cold mode wake-up method;Energy consumption optimization,2021,research on a virtual machine mode transfer method supporting energy consumption optimization,1
144,Exploring RRAM Variability as Synapses on Inception Simulation Framework to Characterize the Prediction Accuracy and Power Estimation per Bit for Convolution Neural Network,978-1-7281-6169-3,10.1109/IPFA49335.2020.9260780,2020 IEEE International Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260780,"Resistive random access memory (RRAM) is one of the most preferred candidates for implementation of hardware-based neural networks for future edge computing applications given its analog conductance behavior (depending on the material stack), ease of integration with the Si CMOS process, relatively lower power consumption (compared to traditional bulk phase change RAM devices) and high integration density. The matrix convolution operation is an inevitable process in a convolutional neural network (CNN) due to its robust approximation to learn and classify the non-linear relationship between the input and output data sets. Today, most of the popular CNNs are stacked with more and more convolution layers (referred to as deep learning) to improve performance, but in many instances, this approach tends to over fit the data, resulting in prediction accuracy loss. The Inception network was an essential milestone in the development of CNN classifiers. The Inception layer is constructed with parallel pipelines of convolution operators, which resulted in improved performance. While several studies have focused on the quantification of the impact of RRAM degradation on the prediction accuracy for pattern classification / image recognition in a simple arbitrary neural network with one or two hidden layers, the impact of these hardware variations on a full-fledged convolutional neural network (CNN) that is commercially used is not well explored. In this study, we extract the GPU trained weights of the CNN platform for visual recognition and replace the GPU weights with the RRAM resistance data in the floating-point format for the Inception network layers alone to quantify the impact of “partial” hardware-based CNN prediction accuracy.",N. L. Prabhu; N. Raghavan,Convolution Neural Network (CNN);Resistive Switching Memory;Graphical Processing Unit (GPU);CNN Trained Weights,2020,exploring rram variability as synapses on inception simulation framework to characterize the prediction accuracy and power estimation per bit for convolution neural network,1
145,"Exploiting computation skip to reduce energy consumption by approximate computing, an HEVC encoder case study",978-3-9815370-8-6,10.23919/DATE.2017.7927039,"Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927039,"Approximate computing paradigm provides methods to optimize algorithms with considering both computational accuracy and complexity. This paradigm can be exploited at different levels of abstraction, from technological to application levels. Approximate computing at algorithm level aims at reducing computational complexity by approximating or skipping block functions of the computation. Numerous applications in the signal and image processing domain integrate algorithms based on discrete optimization techniques. These techniques minimize a cost function by exploring the search space. In this paper, a new approach is proposed to exploit the computation-skipping approximate computing concept by using the Smart Search Space Reduction (Sssr) technique. Sssr enables early selection of the best candidate configurations to reduce the search space. An efficient SSSR technique adjusts configuration selectivity to reduce execution complexity while selecting the most suitable functions to skip. The High Efficiency Video Coding (HEVC) encoder in All Intra (AI) profile is used as a case study to illustrate the benefits of SSSR. In this application, two functions use discrete optimization to explore different solutions and select the one leading to the minimal cost in terms of bitrate/quality and computational energy: coding-tree partitioning and intra-mode prediction. By applying SSSR to this use case, energy reductions from 20% to 70% are explored through Pareto in Rate-Energy space.",A. Mercat; J. Bonnot; M. Pelcat; W. Hamidouche; D. Menard,,2017,exploiting computation skip to reduce energy consumption by approximate computing an hevc encoder case study,1
147,Energy consumption of ICT infrastructures: An operator's viewpoint,978-1-55752-950-3,10.1364/ECEOC.2012.We.1.G.4,2012 38th European Conference and Exhibition on Optical Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6706255,"The digital revolution has resulted up to now in the need for increasingly powerful and energy-hungry infrastructures. This paper provides an operator's viewpoint on how to face this challenge, including some intermediate results of France Telecom Orange energy action plan and some expected technological and architectural evolutions of ICT infrastructures.",S. Gosselin; F. Saliou; F. Bourgart; E. Le Rouzic; S. Le Masson; A. Gati,,2012,energy consumption of ict infrastructures an operator s viewpoint,1
148,Reducing energy consumption in ICT by implementing dynamic bus voltage architecture,978-3-8396-0439-7,,2012 Electronics Goes Green 2012+,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360549,"Early in 2000, the telecoms & datacomms industry introduced a board-level power architecture based on a master DC/DC converter that powers a number of point-of-load regulators. Termed `intermediate bus architecture', the scheme is easy to implement but it is not specifically designed to minimize energy consumption. With its core commitment to saving energy, Ericsson AB has developed a methodology that allows system designers to monitor each load's energy consumption and actively manage the power supply to optimize the system's energy usage. Dynamic Bus Voltage technology is based on a digitally-controlled Advanced Bus Converter, and is foreseen as one of the most significant technological breakthroughs for the ICT industry - because saving a single Watt at board level results in an average 3 Watt saving at system level, the benefits are obvious. This paper explores the technology's background, its prerequisites, and a Dynamic Bus Voltage case study for a datacomms application.",P. Le Fèvre,,2012,reducing energy consumption in ict by implementing dynamic bus voltage architecture,1
151,Power Consumption of Virtual Machine Live Migration in Clouds,978-1-61284-312-4,10.1109/CMC.2011.62,2011 Third International Conference on Communications and Mobile Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5931175,"Virtualization Technology has been employed increasingly widely in modern data centers in order to improve its energy efficiency. In particular, the capability of virtual machine(VM) migration brings multiple benefits for such as resources(CPU, memory, et al.) distribution, energy aware consolidation. However, the migration of virtual machines itself brings extra power consumption. For this reason, a better understanding of its effect on system power consumption is highly desirable. In this paper, we present a power consumption evaluation on the effects of live migration of VMs. Results show that the power overhead of migration is much less in the scenario of employing the strategy of consolidation than the regular deployment without using consolidation. Our results are based on the typical physical server, the power of which is linear model of CPU utilization percentage.",Q. Huang; F. Gao; R. Wang; Z. Qi,data center;power consumption;live migration,2011,power consumption of virtual machine live migration in clouds,1
152,Virtual Machine Migration Methods for Heterogeneous Power Consumption,978-1-4799-7646-1,10.1109/UIC-ATC-ScalCom.2014.26,2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307006,"Virtualization is widely used as a basis for cloud computing. For this technique, if self-management of virtual machines (VMs) can be developed, operational costs will be greatly reduced. To develop self-managed virtualization, it is necessary to develop an algorithm that optimally places VMs on physical machines (PMs) and executes VM migrations among PMs in response to changes in demand. The algorithm must satisfy various requirements, i.e., Minimum power consumption, sufficiently good performance, relatively few migrations, and quick computation. This study proposes three different algorithms for executing VM migrations in order to save electrical power. The proposed methods are based on a greedy algorithm and employ different ways of searching for PMs and VMs involved in migrations. The methods employ an efficiency metric defined in terms of resource usage and electric power for an environment in which power consumption is heterogeneous among PMs. The proposed methods are evaluated via computer simulations. Among these methods, we find there is a trade off between power consumption and the number of migrations. We also find that the most power conserving method achieves power consumption that is close to the strict minimum power.",S. Ohta; A. Sakai,virtualization;cloud computing;heuristic;greedy algorithm;server management,2014,virtual machine migration methods for heterogeneous power consumption,1
154,Towards Energy Consumption and Carbon Footprint Testing for AI-driven IoT Services,978-1-6654-9115-0,10.1109/IC2E55432.2022.00011,2022 IEEE International Conference on Cloud Engineering (IC2E),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9946240,"Energy consumption and carbon emissions are expected to be crucial factors for Internet of Things (IoT) applications. Both the scale and the geo-distribution keep increasing, while Artificial Intelligence (AI) further penetrates the “edge” in order to satisfy the need for highly-responsive and intelligent services. To date, several edge/fog emulators are catering for IoT testing by supporting the deployment and execution of AI-driven IoT services in consolidated test environments. These tools enable the configuration of infrastructures so that they closely resemble edge devices and IoT networks. However, energy consumption and carbon emissions estimations during the testing of AI services are still missing from the current state of IoT testing suites. This study highlights important questions that developers of AI-driven IoT services are in need of answers, along with a set of observations and challenges, aiming to help researchers designing IoT testing and benchmarking suites to cater to user needs.",D. Trihinas; L. Thamsen; J. Beilharz; M. Symeonides,Internet of Things;Edge Computing;Software Testing;Energy Modeling;Machine Learning,2022,towards energy consumption and carbon footprint testing for ai driven iot services,1
155,ICT for automated forecasting of electrical power consumption: A case study in Maputo,978-1-905824-26-7,,2011 IST-Africa Conference Proceedings,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107372,"Accurate short term load forecasting is crucial for efficient operations planning of electrical power systems. We present a model for automatic forecasting of the short term (24 hours) electrical power consumption in Maputo, Mozambique. The proposed model is based on analysis of historical records of power consumption combined with information about additional factors that influence the consumption. The data is clustered into segments with the objective of identifying similar consumption patterns. These consumption patterns are then correlated with weather conditions and used to construct an automated prediction model for load forecasting. Today these forecasts are made manually by experts at Electricidade de Moçambique (the local power company) using conventional methods. The automated prediction model that was developed in this project presents an accurate and consistent complement to manual prediction and is currently being evaluated for the possibility of augmenting the manual forecasts with additional information.",C. Sotomane; L. Asker; V. Massingue,Electrical forecasting;clustering;decision tree;regression;data mining,2011,ict for automated forecasting of electrical power consumption a case study in maputo,1
156,A Power Management Approach to Reduce Energy Consumption for Edge Computing Servers,978-1-7281-1796-6,10.1109/FMEC.2019.8795328,2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795328,"With the rapid development of edge computing and its applications, requests to edge servers is expected to grow, resulting in higher edge network energy consumption. This in essence would also result in higher operational costs for running edge applications. Furthermore, service providers try to manage their resources efficiently to provide appropriate quality of services to their customers while reducing service costs. To appropriately manage resources, it is necessary to apply useful models to measure energy consumption in the edge network. The linear relationship between energy consumption and CPU utilization is one powerful modeling method used to compute the energy consumption of edge network servers. The method calculates the power consumption of a server based on its CPU utilization during run-time. In this paper, we propose a linear power model for the EdgeCloudSim simulator to measure the energy consumption of edge network servers. Moreover, we introduce a simple dynamic power management model used to minimize power consumption in the edge network by switching the edge servers on and off based on provisioned application needs. The experimental and simulation results show a notable reduction in the total energy consumption when applying the proposed simple model on two different orchestration policies to manage the edge network servers.",M. Daraghmeh; I. Al Ridhawi; M. Aloqaily; Y. Jararweh; A. Agarwal,Power management;Linear power model;Energy efficiency;Edge computing networks,2019,a power management approach to reduce energy consumption for edge computing servers,1
157,GreenOracle: Estimating Software Energy Consumption with Energy Measurement Corpora,978-1-4503-4186-8,,2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832886,"Software energy consumption is a relatively new concern for mobile application developers. Poor energy performance can harm adoption and sales of applications. Unfortunately for the developers, the measurement of software energy con-sumption is expensive in terms of hardware and difficult in terms of expertise. Many prior models of software energy consumption assume that developers can use hardware instrumentation and thus cannot evaluate software runningwithin emulators or virtual machines. Some prior modelsrequire actual energy measurements from the previous versions of applications in order to model the energy consumption of later versions of the same application.In this paper, we take a big-data approach to software energy consumption and present a model that can estimate software energy consumption mostly within 10% error (in joules) and does not require the developer to train on energy measurements of their own applications. This model leverages a big-data approach whereby a collection of prior applications' energy measurements allows us to train, trans-mit, and apply the model to estimate any foreign application's energy consumption for a test run. Our model is based on the dynamic traces of system calls and CPU utilization.",S. A. Chowdhury; A. Hindle,Software energy;GreenMining;Modeling energy consumption;Android applications;Mining software repositories;improving energy consumption,2016,greenoracle estimating software energy consumption with energy measurement corpora,1
158,A new approach to model energy consumption of servers in data centers,978-1-4673-0342-2,10.1109/ICIT.2012.6209940,2012 IEEE International Conference on Industrial Technology,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6209940,"Electricity consumption of data centers increases continuously. Beside of the IT industry which tries to reduce this consumption by improving efficiency of components in data centers, there are research solutions based on an optimized energy management of data centers by acting on the IT load placement, then on cooling, start-up and shut down. In this context, this paper focus on energetic modeling of servers in data centers. In the state of art, the IT load is usually presented as a whole unit by means of the percentage CPU, while in this work, the percentage CPU is separated in two parts. The first one is the percentage CPU due to server self applications (for example a virtual machine manager), while the second part is due to services turning on the server. This classification led to a new linear model which shows that electricity consumption of data centers can be modeled as accumulated layers depending on what kind of software is running on the servers. The model is developed and then validated with experimental measurements on actual server conduct with the help of industrial partners. This modeling presents the first step of further works aim to optimize the energy consumption of data centers by knowing the IT load that is held on its servers.",G. Warkozek; E. Drayer; V. Debusschere; S. Bacha,modeling;data center;energy consumption;virtual machine;CPU usage;energy efficiency;…,2012,a new approach to model energy consumption of servers in data centers,1
159,Task and Server Assignment for Reduction of Energy Consumption in Datacenters,978-1-4673-2214-0,10.1109/NCA.2012.42,2012 IEEE 11th International Symposium on Network Computing and Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299091,Energy consumption of cloud data centers accounts for a major operational cost. This paper presents an optimization model for task scheduling to minimize task processing time and energy consumption in data centers for cloud computing. We formulate an integer programming optimization problem to minimize the expected energy consumption of homogenous tasks in a data center with a large number of servers and propose the most-efficient-server first greedy task scheduling algorithm to minimize energy expenditure. We show that the proposed task scheduling can minimize the energy expenditure while bounding the average task waiting time. We present a simulation of the proposed task scheduling scheme to show an optimum number of servers to achieve small task processing times and to minimize energy consumption.,N. Liu; Z. Dong; R. Rojas-Cessa,Cloud computing;Energy;Green Cloud;Task Scheduling,2012,task and server assignment for reduction of energy consumption in datacenters,1
160,A Comparative Study of HDD and SSD RAIDs’ Impact on Server Energy Consumption,978-1-5386-2326-8,10.1109/CLUSTER.2017.103,2017 IEEE International Conference on Cluster Computing (CLUSTER),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048983,"In the US alone, data centers consumed around $20 billion (200 TWh) yearly electricity in 2016, and this amount doubles itself every five years. Data storage alone is estimated to be responsible for about 25% to 35% of data-center power consumption. Servers in data centers generally include multiple HDDs or SSDs, commonly arranged in a RAID level for better performance, reliability, and availability. In this study, we evaluate HDD and SSD based Linux (md) software RAIDs' impact on the energy consumption of popular servers. We used the Filebench workload generator to emulate three common server workloads: web, file, and mail, and measured the energy consumption of the system using the HOBO power meter. We observed some similarities and some differences in energy consumption characteristics of HDD and SSD RAIDs, and provided our insights for better energy-efficiency. We hope that our observations will shed light on new energy-efficient RAID designs tailored for HDD and SSD RAIDs' specific energy consumption characteristics.",E. Tomes; N. Altiparmak,storage systems;energy-efficiency;RAID,2017,a comparative study of hdd and ssd raids impact on server energy consumption,1
161,Data center energy consumption simulator from the servers to their cooling system,978-1-4673-5669-5,10.1109/PTC.2013.6652466,2013 IEEE Grenoble Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6652466,"Efficient energy use has become a worldwide issue for designing and managing the datacenters. Behavioral modeling is a massive task and essential for researching and building our datacenter energy management system (part of a project called Energetic-FUI, France). This paper presents a general expression in the development of our Datacenter Workload Energy Simulation tool (DCWES) using Matlab/Simulink. All modules of the DCWES tool have been converted to Modelica and Java formats to integrate into the Energetic-FUI software.",V. G. Tran; V. Debusschere; S. Bacha,Datacenter simulation;DCWES;energy efficiency;EnergeTIC;workload power,2013,data center energy consumption simulator from the servers to their cooling system,1
162,An approach for a reduced response time and Energy consumption in mixed task set using a Priority Exchange Server,978-1-4799-3080-7,10.1109/ICACCI.2014.6968620,"2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968620,"An important factor that affects the performance of battery operated real-time and embedded systems is Energy. Various techniques have been employed to limit the energy dissipation. Dynamic voltage and frequency scaling (DVFS) is one of the most popular techniques for energy conservation in such systems and is a well researched area. This paper presents an energy conscious real-time scheduling algorithm - DVFSPES, DVFS with Priority Exchange Server for mixed task set comprising of periodic and aperiodic tasks. It uses Earliest Deadline First (EDF) based Priority Exchange Server. The results of DVFSPES are compared with EEDVFS, Energy Efficient DVFS algorithm, that uses an EDF based Deferrable Server on various performance metrics. Depending on the task set used DVFSPES can provide upto 50% improvement in response time of aperiodic tasks without compromising on the deadlines of the periodic task.",S. Mehariya; D. Songara; V. Mitra; M. C. Govil,Dynamic Voltage and Frequency Scaling;Real Time Scheduling;Earliest Deadline First;Priority Exchange Server;Mixed task set,2014,an approach for a reduced response time and energy consumption in mixed task set using a priority exchange server,1
164,A Data-Driven Based Energy Consumption Modeling for Heterogeneous Servers in Data Centers,978-1-6654-3425-6,10.1109/EI252483.2021.9713131,2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713131,"The server is recognized as one of the main energy consumption equipment in data center, of which accurate energy consumption modeling is the key of improving the data center's energy efficiency. This paper proposes a data-driven based energy consumption modeling for the heterogeneous servers popularized in the modern data center, i.e. it constructs a polynomial based energy consumption model by using the real-time server performance data published in the SPECpower_ssj 2008. The results illustrate that the server can have different energy consumption characteristics even with the same CPU and it also shows the superiority of the proposed model. Lastly, this paper takes the data center with 1000 servers as an example, a comprehensive comparison analysis between the proposed model and the existing server energy consumption models is conduced, and the results show the accuracy of the proposed model and the effectiveness to track the actual energy consumption profile.",X. Ma; C. Zhang; S. Li; X. Yang,data center;server energy consumption modeling;SPECpower_ssj2008,2021,a data driven based energy consumption modeling for heterogeneous servers in data centers,1
165,On Minimizing RTOS Aperiodic Tasks Server Energy Consumption,978-1-4244-2276-0,10.1109/DDECS.2008.4538772,2008 11th IEEE Workshop on Design and Diagnostics of Electronic Circuits and Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538772,This paper describes method for minimizing energy consumption of aperiodic tasks server in the RTOS environment. The presented method is based on Dynamic Voltage Scaling and is applicable for microcontrollers equipped with software controlled main clock generation circuits.,K. Dudacek,power requirements;RTOS;aperiodic events server,2008,on minimizing rtos aperiodic tasks server energy consumption,1
167,Design and Implementation of Energy Consumption Simulation Software for Energy-Using Systems,978-1-4799-7005-6,10.1109/ISCID.2014.28,2014 Seventh International Symposium on Computational Intelligence and Design,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064136,"As lacking clear understanding of energy-using characteristics for devices, it is difficult to reasonably assess their consumption levels of energy. In order to solve this problem, chart-module integration theory is applied to energy consumption simulation field to design a software system that supports dynamic energy consumption simulation in this article. Firstly, the overall architecture of the software mainly composed by drawing core engine is described. Then, the realization processes and methods of the graph component library and drawing core engine are illustrated in detail. Finally, the process of modeling and simulation of energy consumption based on the designed software is given. The software users can use graphs to represent energy consumption modules, and give them energy consumption related properties. Applications show that the software provides a unified graphical, integrated, visual environment for energy-using systems, which effectively enhances flexibility and maneuverability of energy simulation analysis.",Y. Xie; L. Zhang; Y. Ren; F. Wang,energy-using system;graphic primitive;energy consumption simulation;modeling and simulation,2014,design and implementation of energy consumption simulation software for energy using systems,1
168,Performance modelling power consumption and carbon emissions for Server Virtualization of Service Oriented Architectures (SOAs),978-1-4244-5563-8,10.1109/EDOCW.2009.5332010,2009 13th Enterprise Distributed Object Computing Conference Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332010,"Server virtualization is driven by the goal of reducing the total number of physical servers in an organisation by consolidating multiple applications on shared servers. Expected benefits include more efficient server utilisation, and a decrease in green house gas emissions. However, service oriented architectures combined with server virtualization may significantly increase risks such as saturation and service level agreement (SLA) violations.",P. Brebner; L. O'Brien; J. Gray,Performance Modelling;Service Oriented Architecture;SOA;Server Virtualization;Cloud Computing;Power Consumption;Carbon Emissions;Green ICT,2009,performance modelling power consumption and carbon emissions for server virtualization of service oriented architectures soas,1
169,Data analytics to increase efficiency of the AI based energy consumption predictor,978-1-7281-7274-3,10.1109/CISPSSE49931.2020.9212200,2020 International Conference on Computational Intelligence for Smart Power System and Sustainable Energy (CISPSSE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212200,"These days most of the developed countries have been focusing on energy consumption forecasting. The smart management of energy became the key note for many researchers in aspects of better understanding of the complex pattern of energy production, distribution and utility line. The AI based smart predictor mainly depends on the huge historical data analytics along with a set of modelling algorithms to specify each logical part. In this paper we have discussed about the core data analytics and the manual evaluation to capture the exact patterns from a real time versatile building energy consumption dataset which could be utilized in the implementation of an AI based smart predictor. With high dimensional data visualization and data analytics we were able to attain relatively lower mean absolute error i.e. a reduction of error up to 40.22% in the data pre-processing phase. We have mainly focused on the handling of the real time energy consumption data set and to trace out the energy supply or consumption breakdown conditions. From a publicly available data set, various data pre-processing criteria have taken and prepared the data-frame for the multivariate prediction model. After data pre-processing linear regression has been used to predict the energy consumption per carpet area and the prediction efficiency has been compared for each cases. With the manual evaluation and the tracing of energy breakdown or any other unusual condition, the prediction performance increased up to 31.03%.",S. Das; T. K. Choudhury; S. K. Mohapatra,Data analytics;Artificial Intelligence;Energy consumption predictor;prediction efficiency;building energy consumption,2020,data analytics to increase efficiency of the ai based energy consumption predictor,1
173,Forecasting of Energy Consumption : Artificial Intelligence Methods,978-9-8933-3436-2,10.23919/CISTI54924.2022.9820078,2022 17th Iberian Conference on Information Systems and Technologies (CISTI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820078,"Currently, energy consumption is one of the most important research areas in the world. The growing need to increase energy efficiency and improve the use of energy sources brings the need for better energy management and forecasting models. Therefore, forecasting energy consumption has become crucial for estimating energy consumption, as it provides both environmental and especially economic benefits. Forecasting is an integral part of business decision-making processes. The growing needs for greater energy efficiency and better use of energy sources bring out the need for better energy management and forecasting models. This article seeks to find the most suitable energy consumption prediction model through a review of studies that have developed data-based building energy consumption prediction models, with a particular focus on the machine learning algorithms used for prediction and some performance measures used for evaluation.",T. C. Brito; M. A. Brito,energy consumption;energy forecasting;Artificial Intelligence;Machine Learning,2022,forecasting of energy consumption artificial intelligence methods,1
175,Energy Consumption Saving in 5G Network Based on Artificial Intelligence,978-1-6654-7517-4,10.1109/ICONAT57137.2023.10080476,2023 International Conference for Advancement in Technology (ICONAT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10080476,"Fifth generation (5G) technology is tasked with tackling the challenge of energy efficiency. As a result, the problem of selecting the optimal set of cells to be turned OFF is nondeterministic polynomial time hard. 5G is more than just a generational step; it opens a new world of possibilities. There are several ways to develop a nation, and Information and Communication Technology will be the best enabler toward realizing this challenge. The exponential increase in network traffic and the number of connected devices make energy efficiency an increasingly important concern for the entire technological ecosystem. With that in mind, we shall discuss some of the proven works related to the topic, such as the Genetic Algorithm (GA), Particle Swarm Optimization (PSO) algorithms, controlling PDCCH channel skipping in sectors of IIoT (3GPP of 5G), and many other related solutions to the most vital element of concern.",D. Ghosh; S. H. Bharathi,5G;IIoT;3GPP;Energy Savings;PDCCH;Artificial Intelligence;Genetic Algorithm;Particle Swarm Optimization (PSO),2023,energy consumption saving in g network based on artificial intelligence,1
177,Energy Consumption Forecasting using a Deep Learning Energy-Level Based Prediction,978-1-6654-0137-1,10.1109/IPRECON52453.2021.9640748,2021 IEEE International Power and Renewable Energy Conference (IPRECON),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640748,"Smart grids benefit the consumers via enabling informed participation. As a result, customers have more choices, which drives a range of buying trends and actions. One such important application is accurate forecasts of energy demands (loads) at individual sites, but load forecasting is still a challenge. Most load forecasting research has used traditional numerical value estimation, which is a regression style prediction; however, energy consumers will not know if the forecasted load is low or high. Level prediction can be performed by performing regression first and then classifying the values into energy levels, or by using a classification model to predict the levels directly. The Random Forest (RF) classification algorithm is shown to have outperformed other machine learning algorithms for level predictions. This paper provides a deep learning-based classification approach. The results of this deep learning-based classification were compared to those of the RF classification algorithm, it was observed that the deep learning method outperformed the RF method, particularly for high numbers of energy levels.",R. Rane; M. Desai; A. Pandey; F. Kazi,Convolutional Neural Networks (CNN);Deep Neural Networks (DNN);Energy consumption prediction;Energy level classification;Load forecasting;Machine learning;Ordinal binning;Pattern recognition;Random Forest (RF);Smart grid;Smart meter,2021,energy consumption forecasting using a deep learning energy level based prediction,1
178,Real-Time Power Consumption Monitoring and Forecasting Using Regression Techniques and Machine Learning Algorithms,978-1-7281-2516-9,10.1109/IoTaIS47347.2019.8980380,2019 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8980380,"The demand for electricity in the Philippines has been steadily increasing with about one-third of the share going to the residential sector. Thus, there is a need to introduce energy management tools for residences to allow households to take control of their electricity consumption. This work presents a system which provides information on the power consumption of a residence through energy monitoring and forecasting. The system was deployed in a residential unit with a solar PV array and the electricity consumption was monitored for 28 days using an online cloud-server database. Moreover, different regression techniques and machine learning algorithms, such as linear and polynomial regression, support vector regression (SVR) and Random Forest, were trained and implemented to identify the model that gives the best accuracy in predicting the total electricity consumption of the residence at the end of the month. Results show that the linear and polynomial regressions produced large errors due to the nonlinear trend of the consumption data, which is attributed to the generated energy of the solar PV array. The support vector regression algorithm generated models with low percent errors in predicting the end of the month electricity consumption. Moreover, the random forest regression accurately predicted the next-day electricity consumption at 0.58 % error. However, the models generated using Random Forest are not suitable for long-term prediction.",J. M. M. Arce; E. Q. B. Macabebe,Electricity Consumption;Energy Monitoring System;Forecasting;Machine Learning,2019,real time power consumption monitoring and forecasting using regression techniques and machine learning algorithms,1
179,Detection of abnormal power consumption patterns of power users based on machine learning,978-1-6654-7968-4,10.1109/IMCEC55388.2022.10019957,"2022 IEEE 5th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10019957,"With the development of China's power industry, the data of power consumption is increasing, and the illegal stealing of electricity by high-tech means is increasing. How to effectively detect abnormal power consumption behavior has become an important problem that power companies need to solve. Firstly, the principal component analysis (PCA) is used to reduce the dimension of the user's electricity consumption behavior to improve the efficiency of model detection; The abnormal detection of residential power consumption is realized by double algorithm judgment. Aiming at the problem that it is difficult to determine the abnormal proportion of LOF, DBSCAN is used to determine the abnormal value proportion, realize the optimization of LOF algorithm, and obtain the detection results of abnormal power consumption of residents; Then the Isolated Forest model is used to detect the abnormal electricity consumption of residents, and the users of abnormal electricity are selected; Finally, an example is given to verify the feasibility of the anomaly detection model, which improves the accuracy of abnormal power consumption detection.",J. Luo; D. Wang,abnormal power consumption detection;Isolated Forest;DBSCAN_LOF algorithm,2022,detection of abnormal power consumption patterns of power users based on machine learning,1
180,Power Consumption-Based Server Selection Algorithms for Communication-Based Systems,978-1-4244-8053-1,10.1109/NBiS.2010.80,2010 13th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635557,"We have to reduce the total electrical power consumption in information systems. In this paper, we consider communication based applications where a server transmits a large volume of data to a client like file transfer protocol (FTP). We discuss a power consumption model for communication-based applications, where the total power consumption of a server depends on the total transmission rate and number of clients where the server concurrently transmits files. A client has to select a server in a set of possible servers, each of which holds a file, so that the power consumption of the server is reduced. We evaluate a pair of PCB (power consumption-based) and TRB (transmission rate-based) algorithms to select a server. In the evaluation, we show the total power consumption can be reduced by the PCB and TRB algorithms compared with the traditional round-robin (RR) algorithm and PCB is more practical than TRB.",T. Enokido; A. Aikebaier; M. Takizawa; S. M. Deen,Green IT;Power consumption;Communication-based Systems;Power Consumption-Based (PCB) algorithm;Transmission Rate-Based (TRB) algorithm,2010,power consumption based server selection algorithms for communication based systems,1
181,Power Consumption Models for Migrating Processes in a Server Cluster,978-1-4799-4224-4,10.1109/NBiS.2014.41,2014 17th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023929,"Application processes have to be efficiently performed on servers in a cluster with respect to not only performance but also energy consumption. In this paper, we consider a process migration (MG) approach to energy-efficiently performing an application process on servers in a cluster. In this paper, we propose a model to estimate the energy consumption of a server to perform processes. First, a process is initiated on a server named home server in a cluster. A process performed on a current server is migrated to another server if the server is expected to consume a smaller amount of electric energy to perform the process than the current server in the estimation model. A process takes checkpoints and sends the checkpoints to the home server. If a process is faulty, the home server recreates the process on an operational server and the process is restarted on a state saved at a checkpoint most recently taken on the home server. In the evaluation, the total energy consumption of servers is shown to can be smaller in the MG algorithm than the other algorithms.",D. Duolikun; A. Aikebaier; T. Enokido; M. Takizawa,Energy-aware cluster;Power consumption model;Computation model;Process migration,2014,power consumption models for migrating processes in a server cluster,1
182,Minimizing Power Consumption with Performance Efficiency Constraint in Web Server Clusters,978-1-4244-4746-6,10.1109/NBiS.2009.101,2009 International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5350201,"Energy efficiency has become a very important issue to reduce the consumption of resources on the Earth. We have to consider how to save the energy consumption anywhere and anytime, including a large set of servers, for example, servers in the Google company. Hence, power and energy consumption has recently become key concerns, especially huge number of servers are deployed in large cluster configurations as in data centers and Web hosting facilities. Even though we emphasize power saving as much as possible, the performance of servers should be ensured. So far, there have been some discussions about enhancing power conservation. However, with the best of our knowledge, a mathematical model about consumed power and server's performance has not been discussed. Therefore, in this paper, we attempted to minimize the energy consumption with performance constraint of web servers. We know, the response time is the focus of the performance in web servers. Therefore, we first find the trade off value of load for each server based on optimized methods. With the trade off load, the performance of users can be satisfied at the same time the power consumption is minimized. Then, using the trade off load value, we propose a novel load allocation method and then discuss the effectiveness of our load allocation method by comparing with other two methods: random load allocation method and average load allocation method.",Y. Yang; N. Xiong; A. Aikebaier; T. Enokido; M. Takizawa,Power consumption;web server;performance,2009,minimizing power consumption with performance efficiency constraint in web server clusters,1
183,A Power Consumption Model of a Storage Server,978-1-4577-0789-6,10.1109/NBiS.2011.64,2011 14th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041943,"In order to realize digital ecosystems, the total electric power consumption of servers to perform application processes has to be reduced in information systems. Applications are classified into three types, computation, communication, and storage based types. In the computation and communication types of applications, CPU and communication resources of computers are mainly consumed, respectively. In this paper, we measure how much electric power of a whole computer is consumed to perform application processes. In the storage types of applications, the electric power is consumed to read and write files in to storage drives like hard disk drive (HDD). Then, we discuss a power consumption model of a computer to perform storage application processes by abstracting most factors dominating the power consumption from the experimental results. Here, the power consumption rate of a computer is maximum if at least one process is performed. Otherwise, the power consumption rate is minimum. This is a simple power consumption model.",T. Inoue; A. Aikebaier; T. Enokido; M. Takizawa,Power consumption;Storage-based Applications;Power consumption model;Digital ecosystem,2011,a power consumption model of a storage server,1
184,Multi-server federated edge learning for low power consumption wireless resource allocation based on user QoE,,10.23919/JCN.2021.000040,Journal of Communications and Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684774,"Federated edge learning (FEL) deploys a machine learning algorithm by using devices distributed on the edge of a network, trains massive local data, uploads the local model to update the parameters after training, and performs alternate updating with global model parameters to reduce the pressure for uplink data transmission, prevent systematic time delay and ensure data security. This paper proposes that an optimal balance between time delay and energy consumption be achieved by optimizing the transmission power and bandwidth allocation based on user quality of experience (QoE) in a multi-server intelligent edge network. Given the limited computing capability of devices involved in FEL local training, the transmission power is modeled as a quasi-convex uplink power allocation (UPA) problem, and a lower energy consumption bandwidth allocation algorithm is proposed for solution-seeking. The proposed algorithm allocates appropriate power to the device by adapting the computing power and channel state of the device, thereby reducing energy consumption. As the theoretical deduction result suggests that additional bandwidth should be allocated to those devices with weak computing capabilities and poor channel conditions to realize minimal energy consumption within the restraint time. The simulation result indicates that, the maximum gain of the proposed algorithm can be optimized by 31% compared with the baseline.",T. Zhou; X. Li; C. Pan; M. Zhou; Y. Yao,Bandwidth optimization;federated edge learning;QoE;uplink power allocation,2021,multi server federated edge learning for low power consumption wireless resource allocation based on user qoe,1
185,Using a hybrid LDO regulator and a switching regulator circuit to reduce the power consumption in the light load operation of a server motherboard,978-1-4799-5829-0,10.1109/CCECE.2015.7129334,2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129334,"In this paper we propose a hybrid LDO regulator and switching regulator circuit design that uses an LDO regulator instead of a switching regulator to operate in light load. By means of this method our design reduces the power consumption of a switching regulator in light load at the input terminal, and then reduces the power consumption of the server motherboard during the operation. This design includes a microcontroller Unit (MCU) which is able to initialize, detect, judge and control both regulator operations. In addition, the MCU controls both the LDO regulator and the switching regulator in order to transition between light load and heavy load.",Y. -W. Bai; C. -H. Lin,,2015,using a hybrid ldo regulator and a switching regulator circuit to reduce the power consumption in the light load operation of a server motherboard,1
186,A self-managing strategy for balancing response time and power consumption in heterogeneous server clusters,978-1-4244-7681-7,10.1109/ICEIE.2010.5559691,2010 International Conference on Electronics and Information Engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559691,"Today, scalable servers are key elements of most information systems. Their operational requirements, like good response time, low power consumption or high availability, are more and more strict. To fulfill these requirements continuously a proper management policy must be used. But the complexity of these servers prevents the application of manual policies and the own servers must manage themselves as much as possible. Therefore, there is a growing need of self-managing techniques and systems for this type of complex servers. This paper presents a self-managing technique for balancing response time and power consumption that can be integrated and configured in any server cluster very easily.",D. F. Garcia; J. Entrialgo; J. García; M. García,server clusters;self-managing;power management;performance management,2010,a self managing strategy for balancing response time and power consumption in heterogeneous server clusters,1
187,Power consumption minimization in hybrid cooled server by fan reduction,978-1-5090-2994-5,10.1109/ITHERM.2017.7992574,2017 16th IEEE Intersociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems (ITherm),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7992574,"The energy consumption in a typical data center is rising day by day to meet the increasing demand of high compute servers resulting in high energy costs. In typical data centers, almost half of the IT energy is dedicated to cooling of the IT server racks. Hybrid cooling technology as an approach to minimize the power consumption uses of water or water based fluid to cool a high heat generating component whereas the rest of the components is cooled by air using internal fans. In this paper, our objective is to optimize the flow rate of air cooling loop of such hybrid cooled server to make data center cooling more cost effective and energy efficient. The volume of air supplied is controlled by varying the air flow rate through the internal fans. Also, the number of fans is reduced from five to three to minimize the power consumption. This finding helped us realize the 40% decrease in Fan power for each server. The pressure difference between the cold and hot aisle is created to avoid the backflow of cold air. Parameters like CPU and memory utilization were varied and temperature of different components such as processors, Dual-In-Line-Memory Module (DIMMs) & Platform Controller Hub (PCH) was monitored. When the server is running with 3 fans (approx. 10 CFM) maximum temperatures are found below the critical temperature. Further studies are also carried out through CFD analysis to observe changes in a model in 6SigmaET to increase the cooling efficiency. The study gives an idea of power savings by fan consolidation for energy efficient hybrid servers.",M. M. Islam; U. Chowdhury; N. Inamdar; D. Agonafer,Fan consolidation;Hybrid cooled servers;warm water cooling,2017,power consumption minimization in hybrid cooled server by fan reduction,1
188,Performance and Power Consumption Measurement of Java Application Servers,978-1-4673-2453-3,10.1109/MASCOTS.2012.68,"2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298217,"In this paper, we present our in-progress project of modeling performance and power consumption of Java application servers using SPECjEnterprise2010. We run the workload on two application server using two different CPUs, AMD Phenom II and Intel Atom, and investigate performance and power consumption behaviors against the increasing system sizes. We have observed that: (1) CPU utilization draws non-linear functions of the system size and their shapes are different on Phenom and Atom. However, power consumption on both servers increase proportionally. (2) Browse transaction is the source of non-linearly in the CPU utilization. (3) Estimation of the CPU utilization from that of each transaction measured separately incurs large errors (up to 65%), while the errors in the estimation of the power consumption are relatively small (up to 4%).",H. Oi; S. Niboshi,Workload Analysis;Performance Evaluation;Power Consumption;Measurement;SPECjEnterprise2010,2012,performance and power consumption measurement of java application servers,1
189,Reducing the Power Consumption of Servers with Bandwidth Consideration,978-1-4799-5390-5,10.1109/IIH-MSP.2014.168,2014 Tenth International Conference on Intelligent Information Hiding and Multimedia Signal Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6998413,"In recent years, cloud computing systems become more and more mature and cloud computing system applications are becoming more widespread. Microsoft, Google, IBM, Amazon has developed applications for the cloud computing environment. The cloud computing environment like a large pool of resources, MapReduce distribute resources in this resource pool to achieve cloud computing. Hadoop MapReduce is a distributing cloud computing system, more and many user this cloud computing system. Green Mater[1] is a resource manager in a cloud computing system which is based on Hadoop MapReduce, Green Master[1] distribute jobs out to the virtual machines with higher computing performance rather than that with lower computing performance. Green Master[2] select virtual machines which have higher performance and assign tasks and reducing virtual machines achieves power-saving effect. This paper focuses on adding network bandwidth in Green Master, we consider the transmission speed of network bandwidth into Green Master and filter out three appropriate virtual machines, and those virtual machines have better performance than Green Master select.",Y. C. Lin; W. T. Lee; J. Y. Qiu,Hadoop;MapReduce;Benchmark;Cloud Netwrok;Bandwidth,2014,reducing the power consumption of servers with bandwidth consideration,1
190,Conceptualization of Effective Algorithm for Minimizing Power Consumption in Cloud Servers,978-1-6654-8734-4,10.1109/SMART55829.2022.10046762,2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10046762,"There is no adequate way to describe the vastness of today's Internet data. This shows that we are now in the midst of the shift to the age of data-intensive applications. Consequently, the cloud has become essential in the current condition of affairs where we find ourselves in order to deal with this unexpected increase in data. It's common knowledge that worldwide, cloud data centres account for less than 0.01% of all power use. Companies must entirely embrace renewable sources of energy as a source of electricity to stop environmental deterioration caused by the usage of large quantities of brown energy (energy from traditional fossil fuels, such as oil or coal), to power these server factories (i.e. data centres). In this piece, we detail an algorithm for planning out cloud data centre operations such that they are both profitable and environmentally friendly. With this approach, we want to find the optimal balance between a workload's energy needs and the renewable resources available in a cloud data centre.",R. G. Tiwari; A. K. Agarwal; N. Gupta; A. Anand; N. Verma,Energy Optimization;Cloud Workload Scheduling;Cloud data centers;Job Scheduling,2022,conceptualization of effective algorithm for minimizing power consumption in cloud servers,1
193,Reduced power consumption Current-mode ADC using SAR logic for AI application,978-1-7281-8331-2,10.1109/ISOCC50952.2020.9332945,2020 International SoC Design Conference (ISOCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332945,"This paper introduces a new SAR logic that does not need to refer to the upper digital bits to overcome the limitation that the speed can be limited by the conversion time of the comparator by using conventional SAR logic. This proposed logic can be applied to a current-mode flash type ADC and it can be realized with a system consisting of current comparators, encoders and an input generator made up of current rectifiers. The proposed circuit has been implemented using 0.18-um CMOS technology. This circuit operates at a supply voltage of 3.3-V and its input current range is 0-100 μA. The active layout area of the 6-bit current-mode ADC is 341-μm×158 μm, The power consumption is estimated to be 2.4-mW when the input frequency is 100 kHz.",S. Park; H. Kim; D. J. Lee; T. Nho; S. Kim; D. Shim,ADC;current-mode;SAR logic,2020,reduced power consumption current mode adc using sar logic for ai application,1
194,Power-aware game for cloud computing: A distributed mechanism based on Game Theory for minmizing power consumption in cloud scale datacenter,978-1-4673-2073-3,10.1109/ISTEL.2012.6483058,6th International Symposium on Telecommunications (IST),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483058,"The power consumption of datacenters has increased dramatically in recent years. Cloud computing accelerates this increase. The reduction of power consumption has become a challenge for cloud providers in large scale datacenters. They consolidate servers by virtualization technology as an effective remedy for huge power consumption. The management of consolidation often has been performed centrally in datacenters. We devised a distributed self-organized mechanism based on Game Theory for this purpose. In the worst case, our results are only twice as great as the theoretical minimum power consumption. In addition our mechanism could enhance the current centralized ones in two ways. Firstly, it can make decisions with less delay in response to dynamic behavior of usage patterns in cloud computing. Secondly, it can better scale up in pace with the future datacenters.",H. Khani; N. Yazdani; S. Mohammadi,Game Theory;Power Consumption;Cloud Computing;Datacenter,2012,power aware game for cloud computing a distributed mechanism based on game theory for minmizing power consumption in cloud scale datacenter,1
195,Construction and Implementation of Power Consumption Information System in Power Supply Station Area Based on Edge Computing,978-1-6654-7197-8,10.1109/AUTEEE56487.2022.9994319,"2022 IEEE 5th International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994319,"This paper innovatively designs a user power analysis system embedded with edge computing technology in the power Internet of Things system. The system processes massive amounts of smart electricity consumption data nearby to avoid blockage of communication channels caused by massive data transmission. The system extracts the characteristics of power distribution data flow from multiple angles. Then, the K-means clustering method is improved to meet the needs of power distribution data flow identification. By calculating the relationship between abnormal monitoring indicators and setting standard features, the abnormal power consumption monitoring results are obtained. The simulation results show that the highest accuracy rate is 95.5%, and the monitoring area is not less than 90% of the study area. Therefore, this paper believes that the proposed technology can not only provide a safe and fast control method, but also enable the system to have stronger power consumption information big data collection capabilities.",B. Dai; Y. Shi; X. Zhao; F. Mo; R. Li; D. Yang,edge computing;deep learning;K-means clustering algorithm;abnormal electricity consumption;electricity consumption monitoring;information system,2022,construction and implementation of power consumption information system in power supply station area based on edge computing,1
197,Federated Learning based Energy Demand Prediction with Clustered Aggregation,978-1-7281-8924-6,10.1109/BigComp51126.2021.00039,2021 IEEE International Conference on Big Data and Smart Computing (BigComp),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373194,"To reduce negative environmental impacts, power stations and energy grids need to optimize the resources required for power production. Thus, predicting the energy consumption of clients is becoming an important part of every energy management system. Energy usage information collected by the clients' smart homes can be used to train a deep neural network to predict the future energy demand. Collecting data from a large number of distributed clients for centralized model training is expensive in terms of communication resources. To take advantage of distributed data in edge systems, centralized training can be replaced by federated learning where each client only needs to upload model updates produced by training on its local data. These model updates are aggregated into a single global model by the server. But since different clients can have different attributes, model updates can have diverse weights and as a result, it can take a long time for the aggregated global model to converge. To speed up the convergence process, we can apply clustering to group clients based on their properties and aggregate model updates from the same cluster together to produce a cluster specific global model. In this paper, we propose a recurrent neural network based energy demand predictor, trained with federated learning on clustered clients to take advantage of distributed data and speed up the convergence process.",Y. L. Tun; K. Thar; C. M. Thwal; C. S. Hong,energy;federated learning;recurrent neural network;clustering;long short-term memory,2021,federated learning based energy demand prediction with clustered aggregation,1
198,Down-clocking Scheme using Deep Learning for Minimizing Energy Consumption in Wireless Networks,978-1-7281-4985-1,10.1109/ICAIIC48513.2020.9065016,2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065016,"Wi-Fi interface is known to consume a lot of energy in mobile devices, and Idle Listening (IL) dominates clients' energy consumption in Wi-Fi. In this paper, we propose IL down-clocking schemes using deep learning model to reduce the energy consumption in IL time. We exploit the orthogonal frequency-division multiplexing (OFDM) subcarrier addressing for the preamble design. To minimize preamble length for energy efficiency, we use a deep learning model with the recurrent neural network (RNN). Our experimental evaluation using OPNET network simulator and USRP/GNU Radio implementation shows that our scheme outperforms the state-of-the-art down-clocking scheme in both energy consumption and network throughput.",J. -H. Park; S. H. Jeong; Y. -J. Suh,Wireless Communications;Energy Efficiency;Idle Listening Adapting Clock Rate;OFDM Subcarrier;Deep Learning,2020,down clocking scheme using deep learning for minimizing energy consumption in wireless networks,1
203,Initial Data Corruption Impact on Machine Learning Models' Performance in Energy Consumption Forecast,978-1-6654-3316-7,10.1109/USSEC53120.2021.9655724,2021 Ural-Siberian Smart Energy Conference (USSEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9655724,"The paper discusses the problem of operational risks from the application of models based on machine learning in the power industry as in the case of the power consumption forecasting problem. Currently, studies on the machine learning application in the power industry are primarily aimed at improving the accuracy, adaptive capabilities of models, selecting and preprocessing of features. At the same time, the risks at the stage of trained models' application are not given due attention, although the incorrect use of the trained models can lead to a critical deterioration in accuracy and the appearance of errors unacceptable for the models' operation. The paper considers an example of constructing XGBoost and Random Forest models for power consumption short-term forecasting of a mining enterprise, taking into account meteorological factors. Various scenarios of corruption of the initial data used by the model to form a forecast are considered. It is shown how losses and gaps in the initial data increase the power consumption forecast error, causing the risk of significant financial losses when operating on the electricity market.",A. Khalyasmaa; P. Matrenin,machine learning risks;short-term load forecasting;data preprocessing;software testing,2021,initial data corruption impact on machine learning models performance in energy consumption forecast,1
205,Machine Learning-based Analysis of correlation between Energy Consumption data of the Company and its Sales,978-1-7281-6758-9,10.1109/ICTC49870.2020.9289575,2020 International Conference on Information and Communication Technology Convergence (ICTC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289575,"This paper has researched about the correlation between company data, and its annual sales data. Using the identified correlation, we propose a new method of predicting the company's annual sales data with energy consumption data. For this work, gradient boosting was applied to the predictive learning model for effective and better performance of prediction. To implement this method, district address-based energy consumption data is merged into company survey data with pre-processing. Then to predict the sales of each company, the gradient boosting based machine learning model has applied. Our approach to utilizing the energy consumption data can contribute to a new method of predicting the status of companies.",J. Lee; N. Kim; H. Lee; S. Park; B. Lee,Regression;Data pre-processing;Predictive-learning;Gradient Boosting;Machine Learning;Energy data,2020,machine learning based analysis of correlation between energy consumption data of the company and its sales,1
206,[1] Energy consumption clustering using machine learning: K-means approach,978-1-6654-1995-6,10.1109/ACIT53391.2021.9677130,2021 22nd International Arab Conference on Information Technology (ACIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677130,"Nowadays, the accurate analysis of energy consumption has become vital for the development of efficient energy projects as well as, for demonstrating the consumptive behavior of the energy consumers in the system. The importance of this analysis comes from many reasons, one of them is that it leads to a better understanding of the system components. This paper presents a clustering algorithm for residential energy consumption using the K-Means algorithm in two different approaches. The dataset utilized in this article contains energy consumption features selected from 25 houses over a period of two years. Firstly, data cleaning has been used to remove and eliminate the inconsistent data, secondly the Elbow method has been applied to determine the optimal number of clusters before using the K-means approach for the purpose of clustering. In K-means, the data have been clustered into two different approaches. The first one is clustering the daily mean consumption in each season in each year. The second one is clustering the monthly mean consumption over the two years. Finally, data visualization has been applied in order to present the result of our proposed method. The paper finds that the households have different consumption behaviors in different seasons, days, and months and that it is due to the change of the average temperature in each season as well as the different appliances and consumptive patters of each house. The results are representative and match the aim of the paper. Further, they are significant for the further development of the energy system and efficient for tracking the consumption of the houses. Finally, the results of this paper are going to be used after running the algorithm again with a different number of clusters to compare the results and find new insights in the data that might affect the decision.",A. Al Skaif; M. Ayache; H. Kanaan,Energy Consumption;Clustering;Elbow Method;K-Means,2021,energy consumption clustering using machine learning k means approach,1
208,Profiling Energy Consumption of Deep Neural Networks on NVIDIA Jetson Nano,978-1-6654-1552-1,10.1109/IGSC51522.2020.9290876,2020 11th International Green and Sustainable Computing Workshops (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290876,"Improving the capabilities of embedded devices and accelerators for Deep Neural Networks (DNN) leads to a shift from cloud to edge computing. Especially for battery-powered systems, intelligent energy management is critical. In this work, we provide a measurement base for power estimation on NVIDIA Jetson devices. We analyze the effects of different CPU and GPU settings on power consumption, latency, and energy for complete DNNs as well as for individual layers. Furthermore, we provide optimal settings for minimal power and energy consumption for an NVIDIA Jetson Nano.",S. Holly; A. Wendt; M. Lechner,power;energy;latency;NVIDIA;Jetson;deep neural network;profiling,2020,profiling energy consumption of deep neural networks on nvidia jetson nano,1
209,Learning and Predictive Energy Consumption Model based on LSTM recursive neural networks,978-1-7281-8084-7,10.1109/ICDS50568.2020.9268733,2020 Fourth International Conference On Intelligent Computing in Data Sciences (ICDS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268733,"This paper presents a new model for learning and predicting energy consumption based on recurrent neural networks. Specifically, the Long Short Time Memory (LSTM) networks. In this model, we first calculate the moving average of the energy consumption according to a window, well-chosen in accordance with the nature of the data, in order to build an approximate output of the model. Then we use a deep neural network model that combines a multitude of different types of layers to learn how to predict energy consumption in any context. To implement this model, we used the TensorFlowJS Framework in web, mobile or embedded application context. By comparing the prediction results with those obtained by the moving average, we conclude that our model has learned perfectly well how to make good predictions and we can trust it in a different context.",M. Rafik; A. Fentis; T. Khalili; M. Youssfi; O. Bouattane,Deep Learning;Energy consumption;Recurrent neural networks;LSTM,2020,learning and predictive energy consumption model based on lstm recursive neural networks,1
210,"Keynote Speaker 1: Random Neural Networks Optimise QoS, Security and Energy Consumption",978-1-6654-5465-0,10.1109/SIN56466.2022.9970552,2022 15th International Conference on Security of Information and Networks (SIN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9970552,"Random Neural Networks (RNNs) are recurrent network models with strong machine learning capabilities that have been exploited in many applications. We will first recall their theoretical properties, including the product form solution, their capability as approximations for continuous and bounded functions and their efficient deep learning algorithms. Then we will focus on the Cognitive Packet Network (CPN) which uses RNNs to introduce AI into network algorithms to route traffic intelligently with the objective of optimizing Quality of Service (QoS), reducing energy consumption and mitigating security threats and attacks. Then we will provide experimental results showing that CPN can be implemented in various ways: through additional software resident in conventional routers, also through Software Defined Networks (SDN), or also as overlay networks.",E. GELENBE,,2022,keynote speaker random neural networks optimise qos security and energy consumption,1
213,Quantifying the Energy Efficiency Challenges of Achieving Exascale Computing,978-1-4799-8006-2,10.1109/CCGrid.2015.130,"2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152580,"Power and performance are two potentially opposing objectives in the design of a supercomputer, where increases in performance often come at the cost of increased power consumption and vice versa. The task of simultaneously maximising both objectives is becoming an increasingly prominent challenge in the development of future exascale supercomputers. To gain some perspective on the scale of the challenge, we analyse the power and performance trends for the Top500 and Green500 supercomputer lists. We then present the PαPW metric, which we use to evaluate the scalability of power efficiency, projecting the development of an exascale system. From this analysis, we found that when both power and performance are considered, the projected date of achieving an exascale system falls far beyond the current target of 2020.",J. Mair; Z. Huang; D. Eyers; Y. Chen,,2015,quantifying the energy efficiency challenges of achieving exascale computing,1
214,Estimating the Power Consumption of an Idle Virtual Machine,978-0-7695-5046-6,10.1109/GreenCom-iThings-CPSCom.2013.63,"2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682077,"Power management has become one of the main challenges for data center infrastructures. Currently, the cost of powering a server is approaching the cost of the server hardware itself, and, in a near future, the former will continue to increase, while the latter will go down. In this context, virtualization is used to decrease the number of servers, and increase the efficiency of the remaining ones. If virtualization can be used to positively impact on the data center energy consumption, this new abstraction layer disconnects user services (hosted on a virtual machine) from their operating cost. In this paper, we propose an approach and a model to estimate the total power consumption of a virtual machine, by taking into account its static (e.g. memory) and dynamic (e.g. CPU) consumption of resources. This model permits to reconnect each VM to its corresponding operating cost, and provides more information to virtual infrastructure providers and users to optimize their infrastructure/applications. It can be observed from results of experiments that the proposed method outperforms the methods found in the literature that only consider the dynamic consumption of resources.",F. Quesnel; H. K. Mehta; J. -M. Menaud,Cloud Computing;Data Center;Energy Metering;Power Modeling and Prediction;Virtualization;Scheduling,2013,estimating the power consumption of an idle virtual machine,1
216,Energy consumption forecasting using ARIMA and neural network models,978-1-5386-2059-5,10.1109/ISEEE.2017.8170657,2017 5th International Symposium on Electrical and Electronics Engineering (ISEEE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170657,Energy forecast is essential for a good planning of the electricity consumption as well as for the implementation of decision support systems which can lead the decision making process of energy system. Energy consumption time series prediction problems represent a difficult type of predictive modelling problem due to the existence of complex linear and non-linear patterns. This paper presents two approaches for energy consumption forecast: an autoregressive integrated moving average (ARIMA) model and a non-linear autoregressive neural network (NAR) model. The two models are deeply described and finally compared in order to evaluate their performance.,C. Nichiforov; I. Stamatescu; I. Făgărăşan; G. Stamatescu,forecasting;energy consumption;artificial neural networks;arima;time series,2017,energy consumption forecasting using arima and neural network models,1
217,Energy consumption minimization on LoRaWAN sensor network by using an Artificial Neural Network based application,978-1-5386-7713-1,10.1109/SAS.2019.8705992,2019 IEEE Sensors Applications Symposium (SAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705992,"In this paper we use an application approach to minimize the energy consumption and increase the lifetime of a LoRaWAN sensor network. In this sensor network the nodes transmission cycles are controlled by an Artificial Neural Network (ANN) based algorithm. The algorithm predicts the data of nodes and by this method the nodes can avoid data transmission and stay more in Idle mode. For implementing this algorithm and for controlling the network we use the middleware MQTT, which is compatible with The Things Network public LoRaWAN server. With this control, the nodes can, for the best case, save up to 58.91% transmissions and extend their lifetime.",R. Kromes; A. Russo; B. Miramond; F. Verdier,,2019,energy consumption minimization on lorawan sensor network by using an artificial neural network based application,1
219,Green algorithm to reduce the energy consumption in cloud computing data centres,978-1-4673-8460-5,10.1109/SAI.2016.7556035,2016 SAI Computing Conference (SAI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556035,"Datacentres consume incredible amounts of energy for data processing, storage and communication, which negatively impacts the environment through carbon emissions. This paper proposes a novel scheduling algorithm aimed at reducing energy consumption in cloud computing datacentres, with the objective to save the environment. It optimises Virtual Machines' (VMs') allocation and consolidation so as to improve resource utilisation of running servers and the shutdown of idle servers. The proposed algorithm was evaluated and compared with two benchmarks DVFS (Dynamic Voltage Frequency Scaling) and ESWCT (Energy-aware Scheduling algorithm using Workload-aware Consolidation Technique). The results showed a significant improvement in reducing the energy and improvement in resource utilisation.",S. M. AlIsmail; H. A. Kurdi,Cloud computing;Green computing;Energy efficiency;Power management;Virtualisation,2016,green algorithm to reduce the energy consumption in cloud computing data centres,1
220,Energy Consumption Minimization of Smart Devices for Delay-Constrained Task Processing with Edge Computing,978-1-7281-5186-1,10.1109/ICCE46568.2020.9043049,2020 IEEE International Conference on Consumer Electronics (ICCE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043049,"As high quality real-time service demands on smart device applications are rapidly increasing, offloading the application task to the edge server to reduce total response time is emerging as a key issue. Meanwhile, smart devices are very sensitive to the energy consumption (to maximize the battery lifetime), where various energy consumption schemes have been attempted to minimize the power profile, especially for computationally heavy tasks. In this paper, an energy consumption minimization scheme that adjusts both the offloading ratio and CPU operating frequency of the device based on a Dynamic Voltage and Frequency Scaling (DVFS) technique under delay constraint is proposed. Simulation results show that the proposed scheme minimizes the energy consumption of the device while satisfying the delay requirement.",W. Yoo; W. Yang; J. -M. Chung,Smart device;energy consumption;partial offloading;edge computing;dynamic voltage and frequency scaling,2020,energy consumption minimization of smart devices for delay constrained task processing with edge computing,1
221,Machining process energy consumption modelling using response surface methodology and neural network,978-1-5090-6199-0,10.1109/CSCWD.2017.8066724,2017 IEEE 21st International Conference on Computer Supported Cooperative Work in Design (CSCWD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066724,"Machining parameters influence the energy consumed during machining processes. A reliable prediction model for energy consumption will enable industry to achieving energy saving by optimizing the machining parameters during process planning stage. This paper presents a two-level optimization artificial neural network modelling method to characterizing the relationship between energy consumption and the machining parameters. On the first level, the input of the artificial neural network is optimized by the regression analysis. On the second level, the parameters of the artificial neural network are optimized by genetic-simulated annealing algorithm. The method has been tested and validated based on experimental data. The experimental results show that this modelling method can lead to a more accurate predicted of energy consumption for the given machining parameters.",X. Li; J. Lu,Energy consumption;sustainable manufacturing;regression analysis;artificial neural network,2017,machining process energy consumption modelling using response surface methodology and neural network,1
223,A study of secure data transmissions in mobile cloud computing from the energy consumption side,978-1-4673-5742-5,10.1109/ICOIN.2013.6496385,The International Conference on Information Networking 2013 (ICOIN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6496385,"For mobile cloud computing, one of the key issues is to minimize energy consumption in data communication. Although many studies have examined energy consumption of data transmissions, they are limited in that they have focused mainly on bitstream transmissions over existing 3G networks or Wi-Fi environments. Thus, the present paper explores energy efficiency of mobile devices when transferring data securely over various communication networks including high-speed 4G networks such as LTE and Wibro.",J. -A. Hong; S. Seo; N. Kim; B. -D. Lee,4G Networks;Energy Efficiency;Mobile Cloud Computing;Security,2013,a study of secure data transmissions in mobile cloud computing from the energy consumption side,1
225,Energy consumption on heterogeneous computing platforms,978-1-4799-7683-6,10.1109/PDGC.2014.7030770,"2014 International Conference on Parallel, Distributed and Grid Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030770,"In the recent past, heterogeneous computing has gained popularity over the traditional homogeneous computing. Moreover, the upcoming processors are typically equipped with dynamic voltage and frequency scaling options to reduce energy consumption as per the application requirements. Scheduling plays a vital role for efficient parallel computing systems, and in this work, the relationship among heterogeneity, make-span and energy consumption has been explored through simulations for heterogeneous processing systems. Heterogeneity is found to adversely affect the total energy consumption in comparison to the extent of makespan improvement.",S. Bansal; K. Bansal; R. K. Bansal,Task Scheduling;Heterogeneity;Make-span;Energy consumption,2014,energy consumption on heterogeneous computing platforms,1
226,A Study of Big Data Computing Platforms: Fairness and Energy Consumption,978-1-5090-3684-4,10.1109/IC2EW.2016.31,2016 IEEE International Conference on Cloud Engineering Workshop (IC2EW),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527848,"Improving the performance is the common sense on those large-scale data processing frameworks and fruitful studies are proposed in this direction. In contrast, the fairness and energy consumption of those frameworks need further exploration and how the performance, fairness and energy consumption interact each other on big data computing frameworks is not well addressed. In our research, we study the fairness and the energy consumption of those big data computing systems. We find that there are tradeoff between these factors. We conduct detailed studies on the factors which impact the tradeoff between different factors. Based on the observations in our study, we propose workload aware, energy-efficient and green-aware optimizations and implement them into Hadoop YARN. Particularly, in this thesis proposal, we propose to explore the following research problems. First, we explore the tradeoff between fairness and performance, and improve the performance of the state-of the-art approach by up to 225% [7]. Second, we consider the energy efficiency, renewable energy supply as well as battery usage and reduce the brown energy consumption of existing systems by more than 25% [8]. Third, we will explore the relationship between fairness and energy consumption, and eventually we will develop multi-objective optimizations for performance, fairness and energy consumption.",Z. Niu; B. He,,2016,a study of big data computing platforms fairness and energy consumption,1
227,A DSL-MCDA Model for Energy Consumption-Aware in Cloud Computing,978-1-7281-5184-7,10.1109/IINTEC48298.2019.9112111,"2019 International Conference on Internet of Things, Embedded Systems and Communications (IINTEC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112111,"Cloud Computing environment provides an infinite number of resources to Cloud users with different utilities such as computing power, storage space, servers and applications. There are various issues in the cloud resource allocation area that still need to be solved. To address some of these issues, we propose in this paper the DSL-MCDA (Deep Supervised Learning - Multi Criteria Decision Analysis) Model for Energy Consumption-Aware in Cloud Computing as a proactive model of energy consumption-aware. The main goal of the proposed model is to reduce the energy consumption since virtual machines (VM) are dynamically consolidated to lesser number of physical machines (PMs) by selecting an optimal resource that satisfies the demands of cloud users, and this based on classification in deep supervised learning and multi-criteria decision analysis (MCDA) methods.",K. Saidi; O. Hioual; A. Siam,Cloud Computing;Resource allocation;Energy Consumption-Aware;Deep Supervised Learning (DSL);Multi-Criteria Decision Analysis (MCDA),2019,a dsl mcda model for energy consumption aware in cloud computing,1
228,"Energy consumption TCP, TCP-Reno and SCTP within cloud computing",978-1-4799-2806-4,10.1109/WSCAR.2014.6916810,2014 World Symposium on Computer Applications & Research (WSCAR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916810,"This paper presents the performance evaluation and the energy consumption, SCTP, TCP and TCP-Reno within a Cloud service. We present a simulation setting for energy aware using Green-Cloud simulator. The simulator is designed to capture the details of the consumed energy by data center components such us servers, switches, and links. The simulation results gotten for TCP, TCP-Reno and SCTP show the value of each protocol in employing power management schema, such as voltage scaling and dynamic shutdown with different architectures (three-tier and threetier high speed).",N. Kortas; W. Kammoun,Cloud computing;Energy efficiency;Data centers;TCP;TCP-RENO;SCTP;Green-Cloud,2014,energy consumption tcp tcp reno and sctp within cloud computing,1
230,Evaluation of Artificial Neural Network Inference Speed and Energy Consumption on Embedded Systems,978-1-7281-8229-2,10.1109/INFOTEH51037.2021.9400658,2021 20th International Symposium INFOTEH-JAHORINA (INFOTEH),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400658,"Digitalization and automation have been the driving force of the fourth industrial revolution and with them comes a vast amount of data that is collected and needs to be processed. Because of the high costs involved with operating data centers, the task of processing this data has been moved onto edge devices, which process the data on the spot and can act independently. In this paper, an accelerator for artificial neural network inference on edge devices, namely the Intel Neural Compute Stick (NCS), will be evaluated in terms of speed, energy consumption, and performance/cost ratio after which it will be compared to other similar solutions. It has been concluded that the inference speed is significantly better by using the Intel NCS than without it. This solution can be used in private projects and prototyping because of its low cost and low power consumption.",A. Arnautović; E. Teskeredžić,Cyber-physical Systems;Edge Computing;Embedded Intelligence;Embedded AI,2021,evaluation of artificial neural network inference speed and energy consumption on embedded systems,1
232,Joint optimization of latency and energy consumption for mobile edge computing based proximity detection in road networks,,10.23919/JCC.2022.04.020,China Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762679,"In recent years, artificial intelligence and automotive industry have developed rapidly, and autonomous driving has gradually become the focus of the industry. In road networks, the problem of proximity detection refers to detecting whether two moving objects are close to each other or not in real time. However, the battery life and computing capability of mobile devices are limited in the actual scene, which results in high latency and energy consumption. Therefore, it is a tough problem to determine the proximity relationship between mobile users with low latency and energy consumption. In this article, we aim at finding a tradeoff between latency and energy consumption. We formalize the computation offloading problem base on mobile edge computing (MEC) into a constrained multiobjective optimization problem (CMOP) and utilize NSGA-II to solve it. The simulation results demonstrate that NSGA-II can find the Pareto set, which reduces the latency and energy consumption effectively. In addition, a large number of solutions provided by the Pareto set give us more choices of the offloading decision according to the actual situation.",T. Zhao; Y. Liu; G. Shou; X. Yao,proximity detection;mobile edge computing;road networks;constrained multiobjective optimization,2022,joint optimization of latency and energy consumption for mobile edge computing based proximity detection in road networks,1
235,Energy Consumption Forecasting Based on Long Short-term Memory Neural Network with Realistic Smart Meter Data,978-1-6654-8768-9,10.1109/SSCI51031.2022.10022120,2022 IEEE Symposium Series on Computational Intelligence (SSCI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10022120,"Energy consumption forecasting has been more and more important in saving energy and mitigating the hazard-ous environmental impact, which plays a vital role in facilitating decision-making and planning in smart grids. This paper advocates the long short-term memory (LSTM) neural network for time series energy consumption forecasting based on realistic smart meter data. The proposed approach is validated using the open-source, public smart meters data in the United Kingdom under extensive case studies. The results demonstrate that the proposed approach based on LSTM achieves high accuracy in predicting energy consumption due to the capability of modeling long temporal sequences. The impact of different weather conditions on forecasting performance is also analyzed.",Y. Liang; P. K. Saha,Energy consumption forecasting;long short-term memory;machine learning;smart grid;time series data,2022,energy consumption forecasting based on long short term memory neural network with realistic smart meter data,1
236,An Efficient Computing Task Offloading Strategy Based on Energy Consumption and Load Balancing Degree,979-8-3503-2000-8,10.1109/IAECST57965.2022.10062173,2022 4th International Academic Exchange Conference on Science and Technology Innovation (IAECST),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062173,"Computing tasks offload of the edge computing has a significant impact on edge devices energy consumption and load balancing. To reduce the total cost, an offloading strategy that combines energy consumption and load balancing degree is proposed. A task partitioning model is given to perform fine-grained division of computing tasks. Furthermore, the energy consumption model of computing task offloading is obtained through the time delay model, and then the cost function of computing task offloading is constructed in combination with the load balancing degree and energy consumption. With the task offloading strategy, the minimum cost of task offloading is obtained under the multiple constraints, and the path of computing task offloading is determined. The simulation results demonstrate that the strategy can significantly improve the load balancing of the edge server and the overall performance of the edge server.",N. Hu; M. Xiang; C. Huang; L. Qin; B. Yang; R. Wang; Z. Luo,Edge computing;Task offloading;Time delay;Energy consumption;Load balancing degree,2022,an efficient computing task offloading strategy based on energy consumption and load balancing degree,1
238,Research on the Computing Network Topology Distribution Based on Energy Consumption for Cooperative Communication System,978-1-4799-7005-6,10.1109/ISCID.2014.147,2014 Seventh International Symposium on Computational Intelligence and Design,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081975,"Cooperative communication technology has drawn more attention for its unique advantages. It can be applied to many networks and form the computing cooperative communication system network. However, some existing evolving model is not suitable for cooperative communication system entirely. To describe this kind system, this paper established the evolving algorithm based on the features of cooperative communication and improved the preference attachment scheme, introduced the energy consumption factor, which could enhance the network performance effectively. By forming the dynamic equation, the theoretical analysis and simulation results show that the cooperative communication system network is scale-free. Comparing the network that without energy consumption factor, the introduced scheme can make the network topology distributed more uniform and the network lifetime much longer, which means the stability and robustness performance of network are improved effectively.",W. Xie; B. Zhou; E. Liu; T. Zhou,cooeprative cmmunication;degree distribution;energy consumption;network lifetime,2014,research on the computing network topology distribution based on energy consumption for cooperative communication system,1
239,A Deep Reinforcement Learning based policy gradient for Energy Consumption in Edge Computing,979-8-3503-9784-0,10.1109/ICCPC55978.2022.10072146,"2022 International Conference on Computer, Power and Communications (ICCPC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10072146,"IoT devices gain much attention in today's world, including various applications like natural language processing, face recognition and augmented reality etc. The above applications need huge resources which will ruin the energy of the device. Based upon the increase of the device usage, the task of computation is a critical process. A pioneer solution to solve the problem is Edge computing, which will bring the computation closer to the IoT device. The computation can be done both in the device and in the remote edge, it is based on the need and resource availability of the IoT application. The offloading can be achieved by using the Deep Reinforcement learning algorithm (DRL) to acquire the concept of Nash Equilibrium. The offloading decisions can be taken based on Policy Gradient algorithm to overcome the problem of Markov Decision Process. The various algorithms of policy gradient are compared with the standard algorithm used for offloading.",G. Saranya; E. Sasikala,IoT (Internet of Things);DRL(Deep Reinforcement learning);Nash equilibrium;Policy gradient algorithm;Markov decision process,2022,a deep reinforcement learning based policy gradient for energy consumption in edge computing,1
243,Determining Energy Consumption in Heterogenous Cloud Computing by Usage of RMRECFS Workflow with Cost Confinement,978-1-6654-9707-7,10.1109/ICIRCA54612.2022.9985689,2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985689,"For large-scale workflow applications, the cloud is a promising platform. The pay-per-use model is used. In cloud data centers, reducing the energy utilization of priority-limited cost-cutting workflows limits became a hot topic. The majority of existing scheduling algorithms focus on the completion time as well as cost of a particular workflow application while working within cost limitations; These algorithms, however, fail to account for energy savings. The critical task remapping and frequency scaling RMRECFS (Re-Mapping based Reducing Energy Consumption with Frequency Scaling) method is used in this work to provide an approach for reducing energy consumption. Energy utilization reduction and key task remap are two steps of this technique. The cost budget, critical work path, and expandable budget factor are all included to determine the adjustable cost budget and additional costs in the first stage. To execute a preliminary task and task mapping virtual machines when adhering to configurable budget restrictions, most workflow tasks are then distributed to VMs that spend some least amount of power. By reallocating key jobs and applying frequency scaling to virtual machines based on spare costs, the second phase minimizes power consumption owing to task relocation. Experiment with two different types of workflow applications at various ranges show that the provided RMRECFS algorithm efficiently saves energy usage while staying within budget limitations when compared to the conventional RMREC algorithm",N. P. S. Kumar; S. Arjun; B. Dhivya; S. K. S. Sri,Heterogeneous Cloud Computing;Re-Mapping based Reducing Energy Consumption with Frequency Scaling Algorithm;Energy Consumption;Cost Confinement;Virtual Machines,2022,determining energy consumption in heterogenous cloud computing by usage of rmrecfs workflow with cost confinement,1
248,A New Model for Energy Consumption Optimization under Cloud Computing and its Genetic Algorithm,978-1-4799-7434-4,10.1109/CIS.2014.171,2014 Tenth International Conference on Computational Intelligence and Security,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016842,"How to reduce energy consumption under the restraints of satisfying customer service level by effective resource allocation and scheduling has become a key issue in cloud computing. In this paper, we propose a new resources-allocation and scheduling architecture for energy consumption optimization. Based on this architecture, a new energy consumption optimization model is designed to meet the real-time Service Level Agreement (SLA). The proposed model optimizes energy consumption both on system level and component level. On system level, a new virtual machine deployment algorithm based on grouping genetic algorithm is proposed to minimize systems' idle energy consumption, which abstracts the mapping between virtual machines and servers into a multidimensional variable packing problem. On component level, dynamic voltage power adjustment technology is used to reduce energy consumption on execution. Therefore, energy consumption can be reduced on both levels with premise of meeting users' requirements. Experimental results show that compared with other algorithms, the proposed one can greatly reduce the total energy consumption of cloud computing systems under the same conditions.",H. Zhu; X. Wang; H. Wang,cloud computing;real-time task;energy consumption optimization;virtual machine deployment,2014,a new model for energy consumption optimization under cloud computing and its genetic algorithm,1
249,Assessing the possible potential in the global energy consumption: Integrated artificial neural network and data envelopment analysis,978-1-5386-0948-4,10.1109/IEEM.2017.8290152,2017 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290152,"Energy is fundamental to attaining various objectives globally. Its conservation and optimal use will help achieve the numerous objectives. Energy use has been well analyzed and assessed for different purposes using Artificial Neural Network (ANN) and Data Envelopment Analysis (DEA). This study has looked at the various benefits that can be acquired using these methods leading to the significance of developing an integrated model. To determine how much energy could be conserved globally, the integrated model was developed. The model applied to the global energy consumption from 1995 to 2009 discovered a possible saving of 1.62% that could have been conserved.",O. A. Olanrewaju; C. Mbohwa,Artificial Neural Network;Data Envelopment Analysis;Global energy consumption;Integrated model,2017,assessing the possible potential in the global energy consumption integrated artificial neural network and data envelopment analysis,1
250,What Do Programmers Know about Software Energy Consumption?,,10.1109/MS.2015.83,IEEE Software,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155416,"Traditionally, programmers received a range of training on programming languages and methodologies, but they rarely receive training on software energy consumption. Yet, the popularity of mobile devices and cloud computing requires increased awareness of software energy consumption. On mobile devices, battery life often limits computation. Under the demands of cloud computing, datacenters struggle to reduce energy consumption through virtualization and datacenter-infrastructure-management systems. Efficient software energy consumption is increasingly becoming an important nonfunctional requirement for programmers. However, are programmers knowledgeable enough about software energy consumption? Do they base their implementation decision on popular beliefs? Researchers surveyed more than 100 programmers regarding their knowledge of software energy consumption. They found that the programmers had limited knowledge of energy efficiency, lacked knowledge of the best practices to reduce software energy consumption, and were often unsure about how software consumes energy. These results highlight the need for better training and education on energy consumption and efficiency.",C. Pang; A. Hindle; B. Adams; A. E. Hassan,software energy consumption;energy efficiency;software power consumption;power usage,2016,what do programmers know about software energy consumption,1
252,Creating the Educational and Research Software for Integrated Assessment of Energy Consumption and Sustainable Development of Regions,978-1-7281-2569-5,10.1109/MEES.2019.8896654,2019 IEEE International Conference on Modern Electrical and Energy Systems (MEES),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896654,"A new approach which determines the level of sustainable development of the country and its individual regions taking into account the development of the energy sector and energy security of the country is proposed. The authors present their own research and development of software that comprehensively takes into account social, environmental, economic and energy indicators for assessing the sustainable development of the country. The algorithm of base indicators calculation for a comprehensive assessment of energy consumption and sustainable economic development and their correlation is developed. The results of the study can be used in the educational process and in the professional activity of future specialists in the field of electrical engineering to systematize information on the level of energy consumption of the country and calculate its sustainable development.",I. Shvedchykova; I. Soloshych; S. Pochtovyuk,socio-ecological-economic condition;educational and research software;energy consumption,2019,creating the educational and research software for integrated assessment of energy consumption and sustainable development of regions,1
253,Analysis and Optimization of Embedded Software Energy Consumption on the Source Code and Algorithm Level,978-1-4244-4995-8,10.1109/EM-COM.2009.5402965,2009 Fourth International Conference on Embedded and Multimedia Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5402965,"The energy consumption optimization of embedded systems can be undertaken in multiple levels of hardware and software. In this paper, based on the energy consumption measurement of embedded software, the generating reasons and influencing factors of embedded software energy consumption on the micro-structure and circuit level of hardware were analyzed firstly. Then, to reduce the energy consumption of embedded software, some measures were adopted to improve the software-related characteristics on the source code and algorithm level. Finally, a C program of typical ""Eight Queens"" puzzle was optimized with three methods of source code level, algorithm level and a mix of source code and algorithm level, the highest energy savings of embedded systems could achieve up to 93.1%, and experimental results demonstrated that the energy consumption optimization methods of embedded software were feasible and effective to minimize the energy consumption of embedded systems.",G. Luo; B. Guo; Y. Shen; H. Liao; L. Ren,,2009,analysis and optimization of embedded software energy consumption on the source code and algorithm level,1
254,Development of energy consumption model for virtual commissioning software,978-1-4673-9752-0,10.1109/RTUCON.2015.7343139,2015 56th International Scientific Conference on Power and Electrical Engineering of Riga Technical University (RTUCON),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7343139,Two different industrial robot electrical energy consumption modeling applications with various modeling approach are discussed. Application programming interface between MATLAB and external C++ or VB.NET application is introduced for energy consumption data at virtual commissioning software. Validation of the developed model is performed. The main identified problem is speed of the application programming interface (API). Future development and application suggestions are discussed.,O. Bormanis,Virtual manufacturing;multi-robot systems;prediction models,2015,development of energy consumption model for virtual commissioning software,1
255,The dependence of microprocessor system energy consumption on software optimization,978-1-5386-1701-4,10.1109/ELNANO.2017.7939795,2017 IEEE 37th International Conference on Electronics and Nanotechnology (ELNANO),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939795,Energy efficiency and computational time become the key usability factors of the low power computational systems. In this sense optimization of the source code is a great challenge to make low power computational system competitive relative to other and adorable for the customers. The paper describes several experiments with a modern low power system that shows the influence of the program loop optimization on microprocessor system power consumption. Conclusions about positive effect of the automatic software optimization are presented.,S. Sushko; A. Chemeris,low power;software optimization;tiling;parallelization;polyhedral model,2017,the dependence of microprocessor system energy consumption on software optimization,1
256,Software Defined networking for reducing energy consumption and carbon emission,978-1-5090-2246-5,10.1109/SECON.2016.7506640,SoutheastCon 2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506640,"With the exponential growth of the internet use, many organizations use vast amount of energy/power to operate and cool their network infrastructures and thus produce significant amount of carbon waste. The main focus of this research is to design OpenFlow based networks that will result in high speed computer networks and dramatic reductions of energy consumption and carbon emission. Note that optimizing a physical network requires tedious time spent manually debugging hardware, by manipulating a virtual network one may add and remove hosts with the click of a mouse. Mininet virtualization software allows the user to carry out what would normally be tedious processes in the matter of minutes. We also present steps toward converting a typical network set-up into an OpenFlow controlled Software Defined Network (SDN); to reduce the power consumption used by the network. Mininet is useful in visually representing a physical network to optimize power consumption using Software Defined Network.",D. B. Rawat; C. Bajracharya,Software Defined Networks;OpenFlow;Mininet;OpenDaylight;Georgia Southern University,2016,software defined networking for reducing energy consumption and carbon emission,1
257,Balancing Energy Consumption Algorithm Based-on Controller Handover for Software-Defined Wireless Sensor Network,978-1-5386-8339-2,10.1109/CompComm.2018.8780885,2018 IEEE 4th International Conference on Computer and Communications (ICCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780885,"In recent years, SDWSNs has been gaining more and more attention in the wireless sensor networks (WSNs) space. This phenomenon is mainly attributed to that both data collection and definable control can be more clearly achieved. However, simultaneously, there are some defects in energy balance and energy efficiency in SDWSNs, especially in the case of all nodes with limited energy. Large amounts of data reception will cause the rapid energy consumption in the aspect of energy of the controller, which will quickly lead to network failure. In this paper, to balance energy consumption of network in which energy of all nodes are limited and prolong lifetime of the network, we propose a novel balancing energy consumption algorithm based-on controller handover. In proposed algorithm, BP neural network is applied to support the mechanism of handover. Simulation results show that this algorithm can effectively balance energy consumption and extend lifetime of the network compared with the traditional energy saving algorithms in SDWSNs.",C. Lei; W. Muqing; Z. Min,SDWSN;energy consumption;controller handover;BP neural network,2018,balancing energy consumption algorithm based on controller handover for software defined wireless sensor network,1
259,A hardware and software Web-based environment for Energy Consumption analysis in mobile devices,978-1-5090-3216-7,10.1109/NCA.2016.7778625,2016 IEEE 15th International Symposium on Network Computing and Applications (NCA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778625,"In recent times, the number of mobile Android devices has been growing exponentially not only in the expanding popularity of low-cost mobile devices but also for the great number of functionalities and applications. This new range of features has highlighted the need for greater capacity in mobile batteries to provide an extended time of use. Several studies have been done to minimize the impact on the uncontrolled growth of applications, as well as analyze the suitable hardware configuration for a range of applications. In this sense, the objective of this work is to provide a Web-based environment which helps the designer to characterize mobile devices through automated testing and multiple devices simultaneously. The Web environment allows the designer to make assessments on the mobile device, remotely, without the need for measurement environment available. The use of multiple devices allows the designer to perform in different parallel measurements simultaneously. As the case study, an analysis involving video streaming, CPU processor load, and CPU fixed-frequency algorithms versus dynamic frequency scaling techniques were performed for two types of Android smartphones.",S. A. L. Carvalho; R. N. Lima; D. C. Cunha; A. G. Silva-Filho,,2016,a hardware and software web based environment for energy consumption analysis in mobile devices,1
261,Characterizing energy consumption in software HEVC encoders: HM vs x265,978-1-5090-5859-4,10.1109/LASCAS.2017.7948097,2017 IEEE 8th Latin American Symposium on Circuits & Systems (LASCAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7948097,"Nowadays, digital video processing has become an important challenge when developing digital systems, mainly in terms of energy consumption. The High Efficiency Video Coding (HEVC) is the state-of-the-art video coding standard and the energy profiling of different HEVC encoder implementations is of key importance. HEVC encoder has different implementations developed for different goals. This work presents a comparison between the commercial encoder x265 and the reference software HM (HEVC Test Model). The Running Average Power Limit (RAPL) tool was utilized to measure the energy consumption of HM and x265 encoders for different configurations. Both results were compared to estimate the performance differences between such encoders. Based on the obtained results it can be seen that x265 achieves a higher coding efficiency for all studied configurations, reaching on the best case a gain of 9% on the coding efficiency, whereas consuming the same amount of energy than HM. The results also demonstrate that x265 has the characteristics of high consumption, small coding efficiency loss, and high adaptability, which are desirable to perform energy control on the encoder, and that some of its tools can reduce the energy consumption around 25% with small performance losses.",I. Machado; W. Penny; M. Porto; L. Agostini; B. Zatt,HEVC;x265;Video Coding;Energy Consumption;RAPL,2017,characterizing energy consumption in software hevc encoders hm vs x,1
262,A Preliminary Study of the Impact of Code Coverage on Software Energy Consumption,978-1-6654-3583-3,10.1109/ASEW52652.2021.00057,2021 36th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679828,"Software testing plays an important role in building quality software and improving maintainability. However, there are no research studies to analyze its impact on energy efficiency. In this paper, we our hypothesis and research questions on the impact of software tests (in particular through coverage metrics) on the energy consumption of software. We also present our experimental methodology and our initial results.",A. Noureddine; M. Martinez; H. Kanso,Software Energy;Software Testing;Power Consumption;Code Coverage,2021,a preliminary study of the impact of code coverage on software energy consumption,1
264,Evaluating Energy and Performance for Server-Class Hardware Configurations,978-0-7695-4509-7,10.1109/NAS.2011.23,"2011 IEEE Sixth International Conference on Networking, Architecture, and Storage",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005458,"The improvement for energy efficiency has been increasingly becoming a major consideration in server and data center design, especially for the power-hungry ones. Numerous studies have provided various new methods or proposals for the building of ""green"" server and data center, but this paper concentrates on how different configuration schemes in a server effect practical performance and power consumption for specific applications. It is completely necessary to obtain thin provisioning for the particular applications to meet performance requirements with minimal energy consumption. This paper evaluates the different hardware configurations' impact on energy consumption and performance for typical applications, hoping for offering evidences or clues to subsequent researches. The File Bench is used to generate four sever workloads and ZH-101 is employed to collect relevant real-time power consumptions. Our result shows that different workloads need different hardware configurations at the demands of both energy-efficiency and performance. And running multiple workloads on a reduced hardware configuration is a wise choice.",C. Liu; J. Huang; Q. Cao; S. Wan; C. Xie,Storage System;Energy Consumption;Performance Metric,2011,evaluating energy and performance for server class hardware configurations,1
265,Reducing Power Consumption of Datacenter Networks with 60GHz Wireless Server-to-Server Links,978-1-5090-5019-2,10.1109/GLOCOM.2017.8254209,GLOBECOM 2017 - 2017 IEEE Global Communications Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254209,"Datacenters have become the digital backbone of the modern society and consume enormous amounts of power. Significant portion of the power consumption is due to the power hungry switching fabric necessary for communication in the datacenter. Additionally, the complex cabling in traditional datacenters pose design and maintenance challenges and increase the energy cost of the cooling infrastructure by obstructing the flow of chilled air. In this work we address these problems of traditional datacenters by designing a server-to-server wireless datacenter network (DCN). We propose design methodologies for the use of 60GHz unlicensed millimeter-wave bands to establish direct communication links between servers in a DCN without the need for a conventional fabric. This will reduce the power consumption of the DCN significantly. We first demonstrate that such a power-efficient wireless DCN can sustain the traffic requirements encountered in small to mid-size real datacenters and provide data rates that are comparable to traditional DCNs. Having established the feasibility of a server-to-server wireless DCN in terms of performance, we estimate that its power consumption is lower by four to six times in comparison to a conventional DCN fabric.",S. G. Umamaheswaran; S. A. Mamun; A. Ganguly; M. Kwon; A. Kwasinski,,2017,reducing power consumption of datacenter networks with ghz wireless server to server links,1
267,Framework for Load Power Consumption in HANs Using Machine Learning and IoT Assistance,,10.1109/MDAT.2020.3021029,IEEE Design & Test,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183897,"Editor's notes: In home area networks, many appliances share a power distribution network and all are potentially the cause and victims of sudden current, voltage, and power spikes. This article proposes a monitoring framework to protect the devices and the network against damage and to optimize power consumption. The authors study and evaluate two machine learning algorithms, support vector machine and k-means clustering, for identifying anomalies and misbehavior, and find that support vector machines seem to be better suited for this application. -Axel Jantsch, Royal Institute of Technology.",A. Manimuthu; V. Dharshini,Embedded systems;Energy;Gateway;Machine Learning;IoT;Smart grid,2021,framework for load power consumption in hans using machine learning and iot assistance,1
268,Optimizing Chiller Switch-on Time Interval for Chiller Power Consumption Saving Via Big Data Analytics and Machine Learning Framework,978-986-91715-5-7,10.23919/eMDC/ISSM48219.2019.9052110,2019 Joint International Symposium on e-Manufacturing & Design Collaboration(eMDC) & Semiconductor Manufacturing (ISSM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052110,"In semiconductor manufacturing, the chiller water system requires huge energy consumption, especially in the countries which have high temperature and humidity climate such as Taiwan. In order to minimize chiller power consumption without affecting the environment of wafer production, optimizing chiller system operations become a crucial issue. Conventionally, chiller operations greatly depend on engineers' practical experiences. However, various uncertainties, including changeable weather and complicated chiller combinations, lead to inconsistent decisions of switching chiller machines as well as energy waste. To improve the operational performance of the system for energy saving, researchers have proposed many different types of solutions, but those technologies are not easy to widely adopted in practical applications due to the complicated and limited operations and models.",Y. -C. Tsai; C. -F. Chien; Y. -J. Chen; M. -K. Hsieh,Big Data Analytics;Machine Learning;Chiller Optimization;Energy Saving;Time-of-use Pricing,2019,optimizing chiller switch on time interval for chiller power consumption saving via big data analytics and machine learning framework,1
269,Cooperative Local Distributed Machine Learning Considering Communication Latency and Power Consumption,978-1-6654-9734-3,10.1109/CCNC51644.2023.10060678,2023 IEEE 20th Consumer Communications & Networking Conference (CCNC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060678,"Machine learning (ML) is predominantly performed in the cloud or other computing facilities. While this computing method allows for the benefits of ML to be leveraged in urban settings, it may also lead to unfair sharing of the environment owing to the heat generated by servers in areas housing computing infrastructure. In this study, we developed a green distributed machine leaning (DML) concept-CoopL-to calculate the local consumption of computational resources based on DML, thereby mitigating the environmental burden. Moreover, we analyzed the impact of long-distance communication by incrementally raising the communication latency. Furthermore, the power consumption was examined by considering the hop count of the router.",S. Ono; T. Yamazaki; T. Miyoshi; Y. Nishiyama; K. Sezaki,Distributed Machine learning;Green computing;Power consumption;Communication latency,2023,cooperative local distributed machine learning considering communication latency and power consumption,1
270,Identifying power consumption signatures in LTE conformance tests using machine learning,978-1-5386-2311-4,10.1109/LASCAS.2018.8399980,2018 IEEE 9th Latin American Symposium on Circuits & Systems (LASCAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399980,"Considering that recent mobile smartphones are energy-hungry battery-powered devices and radio frequency (RF) conformance tests are currently executed with no current drain measurements, the objective of this paper is to propose a machine learning approach to identify power consumption signatures (PCSs) of smartphones under Long Term Evolution (LTE) user equipment RF conformance tests. Experimental results show that the proposed methodology can be used to build an operating history with PCSs for potential use cases.",S. A. L. Carvalho; L. M. F. Harada; R. N. Lima; C. M. A. Barbosa; D. C. Cunha; A. G. Silva-Filho,,2018,identifying power consumption signatures in lte conformance tests using machine learning,1
271,An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting,978-1-5386-4658-8,10.1109/ICASSP.2018.8461624,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461624,"Nearly all previous work on small-footprint keyword spotting with neural networks quantify model footprint in terms of the number of parameters and multiply operations for a feedforward inference pass. These values are, however, proxy measures since empirical performance in actual deployments is determined by many factors. In this paper, we study the power consumption of a family of convolutional neural networks for keyword spotting on a Raspberry Pi. We find that both proxies are good predictors of energy usage, although the number of multiplies is more predictive than the number of model parameters. We also confirm that models with the highest accuracies are, unsurprisingly, the most power hungry.",R. Tang; W. Wang; Z. Tu; J. Lin,spotting;power consumption,2018,an experimental analysis of the power consumption of convolutional neural networks for keyword spotting,1
272,Implementation of artificial neural networks performing basic logic operations on microcontroller with ultralow power consumption,978-1-5386-0777-0,10.1109/CTSYS.2017.8109548,2017 IEEE II International Conference on Control in Technical Systems (CTS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109548,"The paper considers the results of MATLAB modeling of artificial neural networks trained to perform basic logical operations: AND, OR, XOR and NOT. Below is a description of implementation of these artificial neural networks on a microcontroller by Texas Instruments family MSP430G2x, which is marketed by the manufacturer as an ultra-low power consumption device. Implementation of artificial neural networks on such an element base is not a typical task and, thus, lets the developers of digital signal processing and control systems expand their capabilities, as well as significantly reduce the costs.",A. K. Grineva; I. I. Zhukovskii; A. B. Stepanov,artificial neural network;microcontroller;implementation;ultralow power consumption,2017,implementation of artificial neural networks performing basic logic operations on microcontroller with ultralow power consumption,1
273,A Novel Proposed Approach for Real-Time Scheduling Based on Neural Networks Approach with Minimization of Power Consumption,978-1-5090-4114-5,10.1109/WSCAR.2016.24,2016 World Symposium on Computer Applications & Research (WSCAR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7791988,"While most embedded systems are designed for real-time applications, they suffer from resource constraints. Many techniques have been proposed for real-time task scheduling to reduce energy consumption. A combination of Dynamic Voltage Scaling (DVS) and feedback scheduling can be used to scale dynamically the frequency by adjusting the operating voltage, and improve the run-time reliability of embedded systems. We present in this paper a novel hybrid contribution that handles real-time scheduling of embedded systems and low power consumption based on the combination of DVS and Neural Feedback Scheduling NFS with the priority-energy earliest-deadline-first (PEDF) algorithm.",G. Rhaiem; H. Gharsellaoui; S. B. Ahmed,Optimization;Neural Networks;Real-Time Scheduling;Low-Power Consumption,2016,a novel proposed approach for real time scheduling based on neural networks approach with minimization of power consumption,1
275,Evaluation of neural networks with data quantization in low power consumption devices,978-1-7281-3427-7,10.1109/LASCAS45839.2020.9069011,2020 IEEE 11th Latin American Symposium on Circuits & Systems (LASCAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069011,"Image recognition is frequently carried out using a particular type of neural network called Convolutional Neural Networks (CNNs). Still, in general, any neural network requires powerful computational resources that are expensive and demand very high power consumption. It is a challenge to determine the best low power consumption devices and configuration parameters to train and run CNNs for image processing and recognition. These devices do not have the same capabilities as a computer, and the design and implementation of CNN algorithms should be adapted to reduce their size and computation time without affecting the performance and accuracy of results. Therefore, this research evaluates four CNN models with different data quantization to check their accuracy, processing, memory usage, model complexity, and inference time in four different low-power hardware platforms with varied computational capacity. The results showed that the efficiency obtained by each neural network in the classification tasks increases as the model complexity also increases, but the reduction of the model could also produce acceptable outcomes without critically affecting precision.",L. Torres-Valverde; N. Imamoglu; A. Gonzalez-Torres; T. Kouyama; A. Kanemura,Convolutional neural networks;FPGA;image recognition,2020,evaluation of neural networks with data quantization in low power consumption devices,1
277,Estimating Power Consumption of Servers Using Gaussian Mixture Model,978-1-5386-2087-8,10.1109/CANDAR.2017.44,2017 Fifth International Symposium on Computing and Networking (CANDAR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345468,"In a power-aware scheduling system, power models are leveraged as the basis of estimating the effect of scheduling tasks. Previous studies showed that power consumption of servers is a non-linear function of resource usage, and a single set of parameters in one model can't accurately estimate power consumption at different usage levels. Gaussian Mixture Model (GMM) is a unsupervised machine learning model, which contains multiple GMM clusters. These clusters can be used to co-relate power consumption with resource features at different usage levels. In this paper we further adapt GMM for power estimation in a distributed computing cluster. We use basic OS-reported resource features (CPU utilization, memory utilization etc.) of a server in our GMM, and this makes operators easily monitor and control the state of the server once scheduling decision is made. In addition, our GMM uses conditional probability to obtain fine-grained regression. We train the model using full features, which has the higher accuracy comparing with that only using CPU or part of features. In the end, we evaluate the power models in terms of not only accuracy but also usability. Compare to other linear or non-linear models, GMM has the highest accuracy but requires the longest training time.",H. Zhu; H. Dai; S. Yang; Y. Yan; B. Lin,Power Model;Workload Characterization;Power~Estimation;Machine Learning,2017,estimating power consumption of servers using gaussian mixture model,1
278,Bee-MMT: A load balancing method for power consumption management in cloud computing,978-1-4799-0192-0,10.1109/IC3.2013.6612165,2013 Sixth International Conference on Contemporary Computing (IC3),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612165,"Energy consumption management has become an essential concept in cloud computing. In this paper, we propose a new power aware load balancing, named Bee-MMT (artificial bee colony algorithm-Minimal migration time), to decline power consumption in cloud computing; as a result of this decline, CO2 production and operational cost will be decreased. According to this purpose, an algorithm based on artificial bee colony algorithm (ABC) has been proposed to detect over utilized hosts and then migrate one or more VMs from them to reduce their utilization; following that we detect underutilized hosts and, if it is possible, migrate all VMs which have been allocated to these hosts and then switch them to the sleep mode. However, there is a trade-off between energy consumption and providing high quality of service to the customers. Consequently, we consider SLA Violation as a metric to qualify the QOS that require to satisfy the customers. The results show that the proposed method can achieve greater power consumption saving than other methods like LR-MMT (local regression-Minimal migration time), DVFS (Dynamic Voltage Frequency Scaling), IQR-MMT (Interquartile Range-MMT), MAD-MMT (Median Absolute Deviation) and non-power aware.",S. M. Ghafari; M. Fazeli; A. Patooghy; L. Rikhtechi,Cloud computing;Artificial Bee Colony Algorithm (ABC);load balancing,2013,bee mmt a load balancing method for power consumption management in cloud computing,1
279,Can Approximate Computing Reduce Power Consumption on FPGAs?,978-1-5386-9562-3,10.1109/ICECS.2018.8618062,"2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618062,"Approximate computing allows tackling conflicting objectives, such as power and accuracy of computations. In this paper, we first describe how knowledge of stimuli's specific features can help in quantifying and improving power savings by means of approximate computing. We investigate FPGA implementations of several approximate circuits and compare their power consumption with non-approximating versions. In particular, we study approximate arithmetics and a clock-gate based technique called memoization. Moreover, we compare the accuracy of estimation techniques for power consumption evaluation versus real measurements under controlled environments. We also experimentally quantify the relationship between switching activity and power consumption. Two important results are concluded from our investigations: (1) Approximate arithmetics do not necessarily consume less power than conventional circuits, whereas memoization techniques can, in fact, reduce power consumption. (2) Simulation-based power evaluation for approximate FPGA implementations can reach fidelity values up to about 89% in input-dependent power characteristics. Yet, to evaluate absolute savings, measurements are required.",J. Echavarria; K. Schütz; A. Becher; S. Wildermann; J. Teich,Switching Activity;Power Consumption;Approximate Computing,2018,can approximate computing reduce power consumption on fpgas,1
280,A design of an adaptive peer-to-peer network to reduce power consumption using cloud computing,978-1-4673-2048-1,10.1109/ICACCCT.2012.6320770,2012 IEEE International Conference on Advanced Communication Control and Computing Technologies (ICACCCT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320770,"Information systems based on the cloud computing model and peer-to-peer (P2P) model are now getting popular. In the cloud computing model, a cloud of servers support thin clients with various types of service like Web pages and databases. On the other hand, every computer is peer and there is no centralized coordinator in the P2P model. It is getting more significant to discuss how to reduce the total electric power consumption of computers in information systems to realize eco-society. In this paper, we consider a Web type of application on P2P overlay networks. A model shows how much server peer consumes electric power to performWeb requests from client peers. Here we are creating VM migration to consolidate the server utilization. An algorithm is used for a client peer to select a server peer in a collection of server peers so that the total power consumption can be reduced. Lastly, we evaluate the algorithms in terms of the total power consumption and throughput compared with traditional round robin algorithm.",P. S. Apirajitha.; A. Angayarkanni,Distributed Computing;cloud computing;algorithm;Peer-Peer systems;Power Consumption,2012,a design of an adaptive peer to peer network to reduce power consumption using cloud computing,1
281,Reducing Power Consumption and Improving Quality of Service in Cloud Computing Environments,978-1-4673-2331-4,10.1109/NBiS.2012.38,2012 15th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354799,"The widespread use of cloud computing services is expected to increase the power consumption of ICT devices in a cloud computing environment and to damage a quality of service since the distance to a server becomes longer than before. This paper presents the method to reduce the power consumed by ICT devices in a cloud computing environment, which consists of installing WAN accelerators as part of cloud resources actively and increasing the packet transfer rate of communication link temporarily. Next, this paper indicates a possibility of detecting a sign of service quality deterioration by monitoring the power consumption pattern of ICT devices, on condition that smart grids are widely introduced and power sensors are attached to ICT devices. Then, in order to prevent the degradation in performance on live migration of virtual machines over a wide area, this paper proposes to dynamically apply WAN accelerator within the network when a virtual machine is moved to a distant center.",Y. Awano; S. -i. Kuribayashi,Cloud computing;Reducing power consumption;Quality of service;WAN accelerator,2012,reducing power consumption and improving quality of service in cloud computing environments,1
283,A Scheduling Strategy for Reduced Power Consumption in Mobile Edge Computing,978-1-7281-8695-5,10.1109/INFOCOMWKSHPS50562.2020.9162883,IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162883,"The emergence of cloud computing has promoted the explosive growth of applications, however, with the repaid generation of an unprecedented volume and variety of data, the demand for high-quality mobile services with low latency has been increasing. Edge computing is an emerging paradigm that settles some servers on the near-user side and allows some realtime requests from users to be directly returned to the user after being processed by these servers settled on the near-user side. At present, the industry has two major problems for edge computing. One is to reduce the delay for the tasks. The other one is to consider the endurance of power consumption. In this paper, we focus on saving the power consumption of the system to provide an efficient scheduling strategy in mobile edge computing. Our objective is to reduce the power consumption for the providers of the edge nodes while meeting the resources and delay constraints. We first approach the problem by virtualizing the edge nodes into master and slave nodes based on the sleep power consumption mode. After that, we propose a scheduling strategy through balancing the resources of virtual nodes that reducing the power consumption and guarantees the user's delay as well. We use iFogSim to simulate our strategy. The simulation results show that our strategy can effectively reduce the power consumption of the edge system. In the test of idle tasks, the highest energy consumption was 27.9% lower than the original algorithm.",J. Fang; Y. Chen; S. Lu,edge computing;energy-saving;task scheduling;sleep mode,2020,a scheduling strategy for reduced power consumption in mobile edge computing,1
284,User Power Consumption Cluster Analysis Based on Cloud Computing and Improved K-means Algorithm,978-1-7281-3066-8,10.1109/ICISCAE48440.2019.221685,2019 2nd International Conference on Information Systems and Computer Aided Education (ICISCAE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9075633,"Power companies store a huge amount of user historical electricity consumption data, which is in a complex, independent, and scattered state. If the historical electricity consumption data can be reasonably excavated, we can cluster users according to different users' electricity consumption, electricity usage habits and characteristics, etc. These are beneficial to both data management and power forecasting. Based on this, the electricity consumption data of some users in a certain city is used as the data source. Based on cloud computing and the usage of improved K-means algorithm, we could analyze its historical electricity consumption, monthly electricity consumption change, peak-to-valley power consumption per day and other data, which is useful to cluster the power consumption of each user. After clustering, we obtain the information about electricity consumption of users of each category, which presents distinctive features, guides users to passive and lagging in energy-saving renovation, and supports intelligent business analysis and decision-making.",Y. Song; Y. Su; H. Yang,historical electricity consumption;clustering;cloud computing;improved K-means algorithm,2019,user power consumption cluster analysis based on cloud computing and improved k means algorithm,1
285,Hybrid biogeography algorithm for reducing power consumption in cloud computing,978-1-5090-6367-3,10.1109/ICACCI.2017.8125827,"2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125827,"This paper purposes a hybrid biogeography algorithm that is the combination of biogeography and particle swarm optimization algorithm. A hybrid algorithm performs mutation, based on velocity instead of random mutation. The simulation results show that our proposed scheduling algorithm reduces the energy footprint of cloud data centers and improves a convergence rate of biogeography algorithm.",S. Singhal; J. Grover,Particle swarm optimization;biogeography based optimization;clusters;K-means,2017,hybrid biogeography algorithm for reducing power consumption in cloud computing,1
286,A Study on Improving Power-Consumption Performance Ratio in GPGPU Computing,978-1-4577-1796-3,10.1109/ICNC.2011.53,2011 Second International Conference on Networking and Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6131844,"Increased power consumption of computer has become an important issue in computer systems. Especially in high performance computing, its huge consumption is a serious issue. In this paper, we analyze relationship between performance and power consumption on GPGPU computing, and present a method of improving power-consumption performance ratio. First, we introduce an approach to measuring power consumption of a GPU. Second, we explore performance and power consumption, and discuss a way to improve its performance without substantial power consumption increase. Our experimental results demonstrate that memory access coalescing, utilizing shared memory, and making use of a large quantity of threads improve power-consumption performance ratio.",T. Matsumoto; S. Yamaguchi; T. Sakai,GPGPU;power consumption,2011,a study on improving power consumption performance ratio in gpgpu computing,1
287,Bottom Design of Power Consumption Acquisition System Based on Edge Computing,978-1-6654-3892-6,10.1109/ICMTMA52658.2021.00012,2021 13th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410014,"With the continuous development of science and technology, traditional electricity consumption information collection systems cannot meet the needs of transparent grid construction, the introduction of new technologies for transformation will become the future development trend of collection systems. First, this paper proposes to establish the model of the traditional electricity information collection system, and analyze the existing problems in combination with the business; then, based on Shannon’s theorem, analyze the data transmission process in the communication access layer when the network has noise interference effects, and study the transmission rate of data stream in the link and the relationship between network transmission capacity and transmission technology; finally, the data analysis method is used to analyze the channel distance to the task sink in the edge computing layer, and the change relationship between the comprehensive transmission capacity of the network and the ratio of the information distance is studied according to the network topology.",X. He; S. Xia; W. Cai; J. Zhang; Z. Cheng; L. Gong; M. Tian; X. Wang,Collection system;Edge computing;Shannon’s theorem;Transmission capacity;Information distance,2021,bottom design of power consumption acquisition system based on edge computing,1
289,CMOS Compatible Low Power Consumption Ferroelectric Synapse for Neuromorphic Computing,,10.1109/LED.2023.3234690,IEEE Electron Device Letters,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012315,"With the development of bioelectronics, brain-inspired artificial synapses become more and more important. To simulate artificial synapse, a HfAlO ferroelectric tunnel junction (FTJ) was fabricated, which can simulate short-term synaptic plasticity for neuromorphic computing. The devices realize the synaptic function with low power consumption of about 7.15 aJ per synaptic event. Moreover, to explore the effect of oxygen defects on ferroelectric properties of HfAlO-based device, the first-principle analysis was further carried out. These results pave the way of hafnium-based ferroelectric synaptic devices.",Z. Li; J. Meng; J. Yu; Y. Liu; T. Wang; P. Liu; S. Chen; H. Zhu; Q. Sun; D. W. Zhang; L. Chen,HfO₂-based FTJ;first-principles calculations;synaptic devices;neuromorphic computing,2023,cmos compatible low power consumption ferroelectric synapse for neuromorphic computing,1
291,Research and Application of Cloud Computing in Power Consumption Information Acquisition System,978-1-6654-7876-2,10.1109/SCSET55041.2022.00083,2022 International Seminar on Computer Science and Engineering Technology (SCSET),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700963,"With the development of the power Internet of things, higher requirements are imposed on the data processing of distribution network. The traditional Oracle database can no longer withstand the increasing data pressure of the power consumption information acquisition system, so it is urgent to alter the system. This paper uses cloud computing technology to transform the power consumption information acquisition system in distribution network. By setting business process verification scenarios to simulate the use of electricity information collection and storage experiments, the feasibility of business migration to the cloud and the cloud platform’s performance advantage are verified. Moreover, the security of the cloud platform architecture is analyzed, and the results show that the cloud computing technology can provide a certain level of support for the existing power consumption information acquisition system.",L. Li; K. Liu; S. Wang; Q. Hu,distribution network;cloud computing;information acquisition system,2022,research and application of cloud computing in power consumption information acquisition system,1
293,Comparison of regression and neural network approaches to forecast daily power consumption,978-1-5090-0855-1,10.1109/IFOST.2016.7884239,2016 11th International Forum on Strategic Technology (IFOST),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884239,"Forecasting of power consumption and planning of the balances of electric power may be said to be the main objective of management of EPS. The amount of energy consumption defines the structure of generating equipment, electric networks configuration, the production of electric and thermal energy, use of energy resources, reliability of power supply, the quality of electric power, and also plays an important role in pricing. Nowadays there is a set of methods and models of forecasting of power consumption including the following time ranges of management: quick (daily range), short-term (monthly range) and long-term (annual range). The planning accuracy is an actual task and it depends on calculation methods. This work shows a comparative analysis of regressive and neural network models for the solution of a problem of forecasting of daily power consumption. The power consumption of Siberia UPS over 5 years was calculated during the experiment. The problems of the models accuracy and adequacy of using them in forecasting are shown in the work.",K. Dmitri; A. Maria; A. Anna,forecasting of energy consumption;neural networks;regression analysis;forecasting model;prediction error,2016,comparison of regression and neural network approaches to forecast daily power consumption,1
294,Increasing Accuracy of Power Consumption Using Artificial Neural Network,978-1-5386-8052-0,10.1109/ICoICT.2019.8835371,2019 7th International Conference on Information and Communication Technology (ICoICT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835371,"This paper proposed a smart lighting system using Artificial Neural Network (ANN) algorithm. Power saving is one of the concerns of researchers to continue to be improved. The addition of predictions will increase the ability to save power on the use of smart home devices in the future. Through prediction, the system can decide when the lights are used and when the lights are not used. Therefore, an IoT-based smart light system that can predict the state of the lamp based on sensor data is needed. In this paper ANN algorithm is used to predict the state of the lamp. The purpose of this paper is to analyze the performance of the ANN by entering data from the light system based on the presence of lecturers using magnetic door and infrared sensors. The accuracy of the ANN application is influenced by the lamp state pattern. The result shows that an accuracy of 58.17% for training data and 52.54% for test data in predicting the state of the lamp. The significant power saving is calculated using Wilcoxon Method. It shows that this system provides significance for power saving of 31.75%.",A. M. Syukur; A. G. Putrada; M. Abdurohman,Artificial Neural Network;Prediction;Smart Lighting System;Power Saving;IoT,2019,increasing accuracy of power consumption using artificial neural network,1
296,Measurements analysis of the software-related power consumption in microprocessors,0-7803-7705-2,10.1109/IMTC.2003.1207899,Proceedings of the 20th IEEE Instrumentation Technology Conference (Cat. No.03CH37412),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207899,"In this paper the measurements taken for the development of instruction-level energy models for microprocessors are presented and analyzed. An appropriate measuring environment and a suitable measuring methodology were developed for taking the necessary measurements. The energy of an instruction is defined as a sum of three components. The pure base energy cost, the inter-instruction cost and the effect of the energy sensitive factors (instruction parameters). These components are characterized for each instruction of the ARM7TDMI embedded processor and their values are analyzed. Using the resulted models estimates of the energy consumption of real software kernels with only up to 5% error was determined.",N. Kavvadias; P. Neofotistos; S. Nikolaidis; K. Kosmatopoulos; T. Laopoulos,,2003,measurements analysis of the software related power consumption in microprocessors,1
297,Impact of workload assignment on power consumption in software-defined data center infrastructure,978-1-4799-2730-2,10.1109/CloudNet.2014.6969031,2014 IEEE 3rd International Conference on Cloud Networking (CloudNet),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969031,"We proposed a workload assignment policy for reducing power consumption by air conditioners in data centers. Power consumption was estimated by computational fluid dynamics for both the conventional equipment arrangement and the tandem arrangement newly developed to reuse the exhaust heat from servers. To reduce the air conditioner power consumption by raising the temperature set points of the air conditioners, the temperatures of all server back-planes were equalized by moving workload from the servers with the highest temperatures to the servers with the lowest temperatures. Consequently, the air conditioners' power consumption was reduced by 10.4% in the conventional arrangement. In the tandem arrangement, the air conditioners' power consumption was reduced by 53%, and also the total power consumption of the whole data center was exhibited to be reduced by 23% by reusing the exhaust heat from the servers.",T. Deguchi; Y. Taniguchi; G. Hasegawa; Y. Nakamura; N. Ukita; K. Matsuda; M. Matsuoka,Data center;Power consumption reduction;Workload assignment;Air conditioning;Computational fluid dynamics simulation,2014,impact of workload assignment on power consumption in software defined data center infrastructure,1
298,Low power consumption scheduling based on software Fault-tolerance,978-1-4673-4714-3,10.1109/ICNC.2013.6818273,2013 Ninth International Conference on Natural Computation (ICNC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818273,"The space computer puts forward high demands on the performance. Therefore, the high-performance digital signal processors are increasingly used in the space computer. However, the single particle effects caused by the cosmic radiation make the reliability of the space computer become a huge challenge. The COTS DSP chip has a huge advantage compared to the antiradiation DSP chip in performance, price, size and weight. The software implemented fault-tolerance technique can protect the program, but degrade the system performance and increase the power consumption. According to the DSP structural characteristics and in the premise of not reducing the detecting error ratio, this paper proposes an instruction scheduling method for the low power consumption, to reduce the overheads in terms of the performance and the energy incurred by the fault-tolerance technique.",T. Yao; H. Zhou; M. Fang; H. Hu,DSP;software fault-tolerant;power optimization;instruction scheduling,2013,low power consumption scheduling based on software fault tolerance,1
299,Compiler-based optimizations impact on embedded software power consumption,978-1-4244-4573-8,10.1109/NEWCAS.2009.5290480,2009 Joint IEEE North-East Workshop on Circuits and Systems and TAISA Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290480,"Compilers traditionally are not exposed to the energy details of the processor. In this paper, we present a quantitative study wherein we examine the influence of the global performance optimizations -o0 to -o3, of the code composer studio C/C++ compiler, on the energy and power consumption. The results show that the most aggressive performance optimization option -o3 reduce the execution time, on average, by 95%, while it increases the power consumption by 25%. Moreover, we inspect the optimizations effect on some other execution characteristics, such as the memory references and the data cache miss rate. The results show that the memory references decreases by 94%, while the IPC increases by 250% and consequently lead to the consumed power increase.",M. E. A. Ibrahim; M. Rupp; S. E. . -D. Habib,,2009,compiler based optimizations impact on embedded software power consumption,1
300,Implementation of Application Softwares for Reducing Power Consumption in Web Services,978-1-4799-1775-4,10.1109/WAINA.2015.95,2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096179,"In this study, we discuss about decreasing the power consumption of a client-server system. The decrease of the running cost and the improvement of availability are very important for the reduction of the power consumption in communication systems and services. We have conducted various experiments for power consumption by considering iOS and Android Operating Systems (OS). In this study, we present some experiments and their results to measure the performance related with power consumption and play time for web contents.",K. Nishimura; K. Sugita,communication system;measurement applications for power consumption;web contents;QoS,2015,implementation of application softwares for reducing power consumption in web services,1
301,Balancing power consumption and reliability in the embedded systems software design,978-1-4244-6747-1,,"2010 Argentine School of Micro-Nanoelectronics, Technology and Applications (EAMTA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5606368,"We propose a new approach, namely Optimized Embedded Signature Monitoring (OESM) to perform on-line control-flow fault detection. The underlined advantage of this approach is the ability to perform a profiling algorithm that analyses the control-flow graph of user program in order to optimize the number of checkpoints (i.e., signatures) to be inserted along with the application code. By optimization, we mean to find, for a given application, the best trade-off between the minimum number of signatures to be inserted in the code, for the maximum fault detection coverage, with the minimum impact in terms of power increase. The embedded signatures are checked at runtime by the processor against compilation-time pre-computed values every time the processor reaches these signature points.",F. Vargas; C. A. Rocha; B. Pianta,,2010,balancing power consumption and reliability in the embedded systems software design,1
302,Power Consumption Analysis of Microprocessor Unit Based on Software Realization,978-1-4799-1780-8,10.1109/CSCS.2015.75,2015 20th International Conference on Control Systems and Computer Science,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7168473,"With the advent of portable and high density microelectronic devices, the minimization of power consumption in CMOS VLSI circuits is becoming a critical concern. An embedded system is a combination of electronic hardware and software and sometimes additional parts designed to perform a dedicated function. In many cases system (microprocessor) must monitor the amount of power it uses and take appropriate steps to save the battery life. There are several methods to save power consumption of microprocessor unit including: clock control, power-sensitive processors, low-voltage and circuit shutdown. The effect of reducing power consumption can be achieved either by hardware or software optimization. This paper presents the software level power consumption analysis of MCU, focusing mainly on instruction and data realization.",M. Mackowski; M. Niezabitowski,power consumption;microprocessor unit;program code;microcontroller;software realization;instruction cycle;electromagnetic disturbances,2015,power consumption analysis of microprocessor unit based on software realization,1
304,Beyond CPU: Considering memory power consumption of software,978-989-758-234-9,,2016 5th International Conference on Smart Cities and Green ICT Systems (SMARTGREENS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7951380,"ICTs (Information and Communication Technologies) are responsible around 2% of worldwide greenhouse gas emissions (Gartner, 2007). And according to the Intergovernmental Panel on Climate Change (IPPC) recent reports, CO2 emissions due to ICTs are increasing widely. For this reason, many works tried to propose various tools to estimate the energy consumption due to software in order to reduce carbon footprint. However, these studies, in the majority of cases, takes into account only the CPU and neglects all others components. Whereas, the trend towards high-density packaging and raised memory involve a great increased of power consumption caused by memory and maybe memory can become the largest power consumer in servers. In this paper, we model and then estimate the power consumed by CPU and memory due to the execution of a software. Thus, we perform several experiments in order to observe the behavior of each component.",H. Acar; G. I. Alptekin; J. -P. Gelas; P. Ghodous,Power Consumption;Sustainable Software;Energy Efficiency;Green IT,2016,beyond cpu considering memory power consumption of software,1
307,Analyzing the software aspect of an embedded system's power consumption,978-1-4244-9789-8,10.1109/CCECE.2011.6030577,2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030577,"Today's embedded processors are becoming an important aspect of daily life. As a whole, a large amount of energy we consume everyday is dependant upon CPU technology and their applications. Hardware has continued to advance in finding new techniques for low power consumption. Software is an area that can also be improved for better power efficiency. In order to write efficient power programs, we need to know how much power each instruction uses. This paper looks at identifying the power consumption of the PIC microcontroller to understand the relationship between software and energy. After gathering all the power characteristics of the PIC assembly language a power estimator was developed for a PIC CPU simulator.",C. Robertson; C. J. Martinez,embedded systems;microcontrollers;low power;power estimator,2011,analyzing the software aspect of an embedded system s power consumption,1
308,"An Approximate Analysis of the Balance among Performance, Utilization and Power Estimation of Server Systems by Use of the Batch Service",978-1-4244-1229-7,10.1109/ICON.2007.4444133,2007 15th IEEE International Conference on Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4444133,"In this paper, we analyze the performance, utilization, and power estimation of server systems by both adopting the batch service and adjusting the batch size. In addition to reducing system utilization and power consumption the batch service can also maintain an adjustable system performance. When few events are accumulated in the queue of the batch service, a longer waiting time is needed to reach the threshold value for starting the batch service. Therefore we add a time counter to use in conjunction with the batch service in addition to an event counter; this time counter effectively reduces the mean system response time. But now the clock rate of developed server systems is becoming faster. Adopting the batch service is regarded as the system mechanism for processing events, but it may affect a system's performance and power consumption. We use the queueing model method to analyze the system state and to learn the variations among power consumption, system utilization and mean response time by adjusting the size of the batch service. Furthermore we can evaluate how to adjust a batch size via the derived equation in order to obtain a suitable balance among performance, utilization and power estimation for a server system.",Y. -W. Bai; Y. -S. Cheng; C. -H. Tsai,,2007,an approximate analysis of the balance among performance utilization and power estimation of server systems by use of the batch service,1
309,Computation Offloading in a Mobile Edge Communication Network: A Joint Transmission Delay and Energy Consumption Dynamic Awareness Mechanism,,10.1109/JIOT.2019.2939874,IEEE Internet of Things Journal,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827481,"Various problems arise in the maintenance of communication networks. For example, on-site maintenance personnel have insufficient work experience. Devices used for maintenance work have limited computing resources and battery life. Moreover, most maintenance systems still use the centralized single processing mode of traditional cloud computing, which increases the data center computing pressure and slows the data flow. To overcome these problems, we propose a communication network edge maintenance system based on smart wearable technology and introduce computation offloading technology for mobile edge computing (MEC). Before offloading, we propose a multimerged computing sorting segmentation (MCSS) algorithm to divide a part of the task to offload. When making an offloading decision, we access a suitable MEC service node for each user with the lowest transmission cost and establish a related model. We use an improved Kuhn-Munkras (KM) algorithm that considers fairness among users to solve this model. After that, we propose a dynamic energy-efficiency awareness strategy. When tasks are processed locally, we optimize the CPU clock frequency. When tasks are offloaded, we adaptively allocate the transmission power. Finally, we conduct a simulation experiment. The results demonstrate that the proposed scheme can reduce the transmission cost and improve the performance, thereby increasing the level of on-site maintenance work.",L. Rui; Y. Yang; Z. Gao; X. Qiu,Computation offloading;enter communication network;maintenance;mobile edge computing (MEC);smart wearable,2019,computation offloading in a mobile edge communication network a joint transmission delay and energy consumption dynamic awareness mechanism,1
310,"Optimal Energy Consumption for Communication, Computation, Caching, and Quality Guarantee",,10.1109/TCNS.2019.2913563,IEEE Transactions on Control of Network Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700288,"Energy efficiency is a fundamental requirement of modern data-communication systems, and its importance is reflected in much recent work on performance analysis of system energy consumption. However, most work has only focused on communication and computation costs without accounting for data caching costs. Given the increasing interest in cache networks, this is a serious deficiency. In this paper, we consider the problem of energy consumption in data communication, computation and caching (C3) with a quality-of-information (QoI) guarantee in a communication network. Our goal is to identify the optimal data compression rates and cache placement over the network that minimizes the overall energy consumption in the network. We formulate the problem as a mixed integer nonlinear programming (MINLP) problem with nonconvex functions, which is non-deterministic polynomial-time hard (NP-hard) in general. We propose a variant of the spatial branch-and-bound algorithm (V-SBB) that can provide an $\epsilon$-global optimal solution to the problem. By extensive numerical experiments, we show that the C3 optimization framework improves the energy efficiency by up to 88% compared to any optimization that only considers either communication and caching or communication and computation. Furthermore, the V-SBB technique provides comparatively better solutions than some other MINLP solvers at the cost of additional computation time.",F. Zafari; J. Li; K. K. Leung; D. Towsley; A. Swami,Data compression;energy efficiency;wireless sensor networks,2020,optimal energy consumption for communication computation caching and quality guarantee,1
311,Reducing mobile device energy consumption with computation offloading,978-1-4799-8676-7,10.1109/SNPD.2015.7176219,"2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7176219,"The need for increased performance of mobile device directly conflicts with the desire for longer battery life. Offloading computation to multiple devices is an effective method to reduce energy consumption and enhance performance for mobile applications. Android provides mechanisms for creating mobile applications but lacks a native scheduling system for determining where code should be executed. This paper presents Jade, a system that adds sophisticated energy-aware computation offloading capabilities to Android apps. Jade monitors device and application status and automatically decides where code should be executed. Jade dynamically adjusts offloading strategy by adapting to workload variation, communication costs, and energy status in a distributed network of Android and non-Android devices. Jade minimizes the burden on developers to build applications with computation offloading ability by providing easy-to-use Jade API. Evaluation shows that Jade can effectively reduce up to 39% of average power consumption for mobile application while improving application performance.",H. Qian; D. Andresen,code offload;energy management;distributed computing;scheduling;mobile computing,2015,reducing mobile device energy consumption with computation offloading,1
312,Performance and Energy Consumption Evaluation of Computation Offloading Using CAOS D2D,978-1-5386-4727-1,10.1109/GLOCOM.2018.8647732,2018 IEEE Global Communications Conference (GLOBECOM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8647732,"With the goal of simplifying the design and development of applications that use computation offloading, we developed the CAOS D2D platform to provide an abstraction layer for dealing with low-level tasks related to offloading of methods among Android mobile devices. This paper presents experiments performed to evaluate different aspects of the CAOS D2D, such as execution time and energy consumption of devices during method offloading. Besides that, we also performed experiments to evaluate the process of applications' dependency deployment. The experiments show that computation offloading can speedup the execution time by up to 4.55 times and reduce the power consumption by up to 88% in comparison to local executions of the same methods.",G. B. Dos Santos; F. A. M. Trinta; P. A. L. Rego; F. A. Silva; J. N. De Souza,offloading;performance;device to device,2018,performance and energy consumption evaluation of computation offloading using caos d d,1
313,Effect of computation offload on performance and energy consumption of mobile face recognition,978-1-4799-6588-5,10.1109/SiPS.2014.6986056,2014 IEEE Workshop on Signal Processing Systems (SiPS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986056,"Computation offloading is a paramount technology to leverage network resources for mobile devices. This paper studies effect of computation offloading on efficiency of mobile face recognition. It compares offloading alternatives used in existing mobile face-recognition system and reports on their efficiency in terms of energy consumption, processing time and recognition accuracy. The offloading method which leads to the best energy-performance tradeoff is outlined.",N. Sumi; A. Baba; V. G. Moshnyaga,face recognition;network-based system;computation offloading;performance;energy consumption;analysis,2014,effect of computation offload on performance and energy consumption of mobile face recognition,1
314,Orchestration of MEC Computation Jobs and Energy Consumption Challenges in 5G and Beyond,,10.1109/ACCESS.2022.3151389,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713879,"Mobile Edge Computing (MEC) technology philosophy inspires the next generation mobile networks to provide cloud computing capabilities in addition to a diverse range of Information Technology (IT) services with ultra-low latency and higher bandwidth at the edge. One of the most common challenges of 5G-MEC is the management and orchestration across all networks and infrastructure resources as well as end-to-end quality of experience. The decentralized architecture of MEC with independent and non-collaborative servers results in the situation of having underutilized servers with wasted energy. Moreover, the consequences of having highly utilized servers with highly consumed energy are not only the incapability to accommodate all the load of the computing jobs and the dramatic increase in the total OPEX cost, but it also creates some environmental problems. Orchestrating servers’ workload and control offloading the computation jobs is one of the technical advantages of MEC since it satisfies the increasing requirements of modern mobile applications while optimizing the energy consumption and cost. In this work, we consider cluster-based energy-aware offloading framework. The proposed work consists of dual-tier domain divided into clusters of Edge Servers  $ES_{s} $ . We have presented the results of our simulation as a proof of our concept that the formulated adaptive strategy to minimize the optimization problem calculation per cluster reduces the energy consumption and enhances the quality of experience while achieving the conservation of the related computing and storage resources cost.",R. Samir; H. El-Hennawy; H. M. El-Badawy,MEC;IT;5G;OPEX (operating expense);edge servers,2022,orchestration of mec computation jobs and energy consumption challenges in g and beyond,1
316,Energy Consumption Minimization for Near-Far Server Cooperation in NOMA-Assisted Mobile Edge Computing System,,10.1109/ACCESS.2020.3010571,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144588,"Mobile edge computing (MEC) is fast becoming a key communication technique by enabling mobile users to offload their computation tasks to the edge servers. However, the computation resource of each MEC server is limited which may lead to a worse offloading experience of dense edge users. Besides, the communication and computation resources are usually unevenly distributed among different MEC servers which affect the computational efficiency of the MEC network. In this paper, we propose a non-orthogonal multiple access (NOMA) assisted MEC system with two near-far edge servers performing cooperative communication, i.e., the edge user employs NOMA to offload partial computation workloads to a nearer MEC server and a farther MEC server, then the nearer server decodes and forwards the farther server's task data by full-duplex relaying mode. Based on the above system model, we formulate an optimization problem of the total system energy consumption minimization by jointly optimizing the local CPU frequency, the power allocation for the user and nearer MEC server, the system time assignment and the task partition. Due to the optimization problem is non-convex, a joint communication and computation resource iterative optimization (JCCRIO) algorithm based on approximation and alternation is designed. Firstly, the local CPU frequency is optimized so as to transform the original problem into a simplified equivalent form. In this way, then the simplified minimization problem can be solved iteratively in two steps. Finally, we obtain the closed-form solutions to the optimization variables at each step. Numerical results show that the proposed NOMA-assisted cooperative MEC scheme is more effective against the terms of energy consumption reduction than comparable schemes.",X. Duan; B. Li; W. Zhao,Mobile edge computing;NOMA;server cooperation;full-duplex;joint computation and communication resources optimization,2020,energy consumption minimization for near far server cooperation in noma assisted mobile edge computing system,1
317,Workload-Dependent Software Aging Impact on Performance and Energy Consumption in Server Virtualized Systems,978-1-5090-3601-1,10.1109/ISSREW.2016.31,2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789389,"Dependability modeling and performability analysis of server virtualized systems (SVSs) are today a key challenging problem to evaluate cost-effectiveness and savings in green data centers. This paper tackles various issues related to performability analysis of server virtualized system (SVS) handling workload-aware power management (PM) mechanism and subject to software aging, unplanned failures and Migrate-VM rejuvenation. In this work we develop a modeling approach based on stochastic reward nets (SRNs) to investigate dependencies between several SVS modules including virtual machine monitor (VMM), virtual machine (VM), data intensive applications and power-manageable component (PMC) with workload-aware timebased PM mechanism. We show through numerical analysis how availability, power usage and power-performance trade-off, of SVS, are impacted by aging and workload burstiness.",M. Escheikh; Z. Tayachi; K. Barkaoui,server virtualized systems;software aging;power-manageable;workload-aware timebased;stochastic reward nets,2016,workload dependent software aging impact on performance and energy consumption in server virtualized systems,1
318,Green Configuration: Can Artificial Intelligence Help Reduce Energy Consumption of Configurable Software Systems?,,10.1109/MC.2021.3120048,Computer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9734271,Reducing energy consumption of IT systems is fundamentally important for saving cost and reducing CO2 emissions. We explain the limits of pure artificial intelligence/machine learning (ML) methods when focusing on the source code and outline a conceptual framework for combining software engineering methods and ML to build white-box energy models.,N. Siegmund; J. Dorn; M. Weber; C. Kaltenecker; S. Apel,,2022,green configuration can artificial intelligence help reduce energy consumption of configurable software systems,1
321,Energy-Aware Resource Prediction in Virtualized Data Centers: A Machine Learning Approach,978-1-5386-5807-9,10.1109/ICCE-ASIA.2018.8552101,2018 IEEE International Conference on Consumer Electronics - Asia (ICCE-Asia),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552101,The availability and high utilization of the vast computational power in the current technological era results in a high electrical power consumption rate. This rapid growth and demand for computational power lead to the creation of large-scale data centers which have high power utilization requirements thus resulting in high operational costs. Based on these observations and analysis of machine learning for virtualized cloud data centers' this paper proposes a machine learning approach for energy-aware resource prediction in a virtualized data center environment. The proposed method utilizes the polynomial regression model to predict the likely power consumption and the number of machines that are physically needed based on the daily workload. The proposed model is also discussed.,A. Rayan; Y. Nah,,2018,energy aware resource prediction in virtualized data centers a machine learning approach,1
322,A Machine Learning Approach Applied to Energy Prediction in Job Shop Environments,978-1-5090-6684-1,10.1109/IECON.2018.8592763,IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8592763,"Energy efficiency has become a great challenge for manufacturing companies. Although it is possible to improve efficiency applying new and more efficient machines, decision makers tend to look for some less expensive alternatives. In this context, the adoption of more efficient strategies during the production planning can allow the reduction in energy consumption and associated emissions. Furthermore, the current reality of manufacturing companies, brought by Industry 4.0 concepts, requires more flexibility of production systems, thus, increasing complexity for machine rescheduling without compromising sustainable requirements. In this paper, we propose a method to predict total energy consumption in job shop systems applying machine learning techniques. Different schedules may result in different consumption rates. However, there is a nonlinear relationship between these targets. Therefore, an Artificial Neural Network (ANN) is applied for a quick estimation of total energy consumption. In order to validate the model, computational experiments, using digital manufacturing software tools, are performed on different job shop configurations to show the efficiency of the proposed model.",M. S. Pereira; F. Lima,,2018,a machine learning approach applied to energy prediction in job shop environments,1
324,Neural networks for energy flows prediction in facility systems,0-7803-5280-7,10.1109/SMCIA.1999.782713,SMCia/99 Proceedings of the 1999 IEEE Midnight - Sun Workshop on Soft Computing Methods in Industrial Applications (Cat. No.99EX269),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=782713,"A procedure for the short-term prediction of the thermal energy consumption of a hospital is shown in this paper. First, linear ARX models are built in order to obtain information on the influence of the input variables on the output of the system. Therefore, nonlinear models based on feedforward neural networks (NNARX) are built using the information provided by the linear estimate. The results obtained from the ARX and NNARX models are compared, concluding that NNARX models provide better results than ARX models, but the analysis of ARX models is necessary to obtain guidelines in the choice of the best regression vector as input for the neural models.",L. Frosini; G. Petrecca,,1999,neural networks for energy flows prediction in facility systems,1
325,Rapid software power estimation of embedded pipelined processor through instruction level power model,978-1-4244-4165-5,,2009 International Symposium on Performance Evaluation of Computer & Telecommunication Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5224149,"Embedded systems are characterized by the presence of a combination of dedicated processor and application specific software. With technological advances, although the number of transistors on a chip are increasing, the chip area is reducing thereby making power constraints a critical component of system design. In this paper, a scheme for efficient instruction level power profiling of an embedded processor is developed which incorporates a novel methodology to accurately determine the activity generated in the instruction stages of a pipelined processor. An accurate power model has been developed by using the associated net capacitances obtained from gate fanout values and the FPGA resource on which the respective nets are mapped. An open source LEON3 VHDL core has been employed at RTL level. An activity extraction tool has been developed that produces the activity count of each instruction from value change dump file produced by the simulator. To complement the power model, a capacitance extraction tool is also developed which takes mapping and routing information and gives the cumulative capacitance of each net. The activity count and associated capacitance of the nets provides a figure of merit for the power consumed by that instruction. Complete instruction set of LEON3 processor has been profiled in terms of power consumption. The corresponding power for any application is thus obtained instantaneously and consequently avoids low level power estimation overheads. Moreover, the effect as well as the dependence of instruction parameters such as operands and addresses on energy consumption has also been studied.",S. Sultan; S. Masud,Embedded Processors;Instruction Set;Power Profiling;Switching Activity,2009,rapid software power estimation of embedded pipelined processor through instruction level power model,1
326,Privacy-Preserving Power Consumption Prediction Based on Federated Learning with Cross-Entity Data,978-1-6654-7896-0,10.1109/CCDC55256.2022.10033866,2022 34th Chinese Control and Decision Conference (CCDC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10033866,"Big data analytics have become vastly popular in the power system. However, power-related datasets are often owned by different parties, and a centralized data mining scheme in the form of direct data sharing might compromise party benefits, individual privacy and even national security. To this end, we implement a systematic privacy-preserving federated learning framework in the power system, which enables collaborative learning of power consumption patterns with cross-entity data. Horizontal federated learning is employed when data are scattered by samples; vertical federated learning, on the other hand, is designed for the case with data scattered by features. Further, we propose an alternative encryption scheme based on the Diffie-Hellman key exchange protocol to greatly boost computational efficiency. Case studies show that models trained from the proposed federated learning framework are lossless, privacy-preserving, efficient and effective.",H. Liu; X. Zhang; X. Shen; H. Sun,Federated Learning;Power Consumption Prediction;Cross-Entity Data;Encryption Scheme,2022,privacy preserving power consumption prediction based on federated learning with cross entity data,1
327,Predicting Periodic Energy Saving Pattern of Continuous IoT Based Transmission Data Using Machine Learning Model,978-1-6654-1460-9,10.1109/ICICT4SD50815.2021.9396928,2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396928,"The emerging applications of the Internet of Things (IoT) in various sectors generate a gigantic amount of continuous time-series data. As IoT based sensors nodes are very energy-constrained devices, continuous transmission of huge amounts of sensor data from IoT nodes is challenging but inevitable. It requires massive energy consumption. In this paper, we present an energy-saving pattern by predicting the periodic sensor data after analyzing the continuous transmission data from IoT nodes (at the server beforehand). Our system consists of an IoT based sensor network and a data processing unit. In the sensor network, two types of sensor data, such as temperature and humidity, are collected from four different nodes and sent to the processing unit (integrated on Raspberry Pi). In the processing unit, we worked with two machine learning models-Autoregressive Integrated Moving Average (ARIMA) and Long Short Term Memory (LSTM), which are applied separately on the data of four nodes to make a prediction of future values. A comparative analysis of two models is done in terms of different evaluation metrics where the accuracy of LSTM outperforms ARIMA. Finally, it is shown that with the prediction accuracy of both models, the efficient energy-saving pattern is a chieved by effectively reducing the continuous transmission of data.",N. F. Aurna; F. S. Anika; M. T. M. Rubel; K. H. Kabir; M. S. Kaiser,ARIMA;LSTM;Energy consumption;Time series forecasting;IoT;Raspberry Pi;NodeMCU;MQTT broker,2021,predicting periodic energy saving pattern of continuous iot based transmission data using machine learning model,1
329,An Algorithm for Reducing the Total Power Consumption Based on the Computation and Transmission Rates,978-1-61284-709-2,10.1109/CISIS.2011.41,"2011 International Conference on Complex, Intelligent, and Software Intensive Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989078,"In information systems, it is critical to reduce the total electrical power consumption of computers and networks in order to realize the digital ecosystems and the green IT technologies. In the extended power consumption laxity-based (EPCLB) algorithm, a server is selected in a set of servers so as to not only satisfy deadline constraint but also reduce the total power consumption of servers in general types of applications. However, each time a load balancer receives a new request, the load balancer has to collect status of each server and calculate the estimated power consumption to perform the request. The load balancer spends large computation and communication overhead to estimate the power consumption if the number of clients is increased. In addition, since the status of each server might be changed during the estimation process, it is difficult to correctly estimate the power consumption. In this paper, we newly propose a CTRB (computation and transmission rate based) algorithm to select a server in a set of possible servers so that the total power consumption of servers and the overhead of a load balancer can be reduced. We evaluate the CTRB algorithm in terms of the power consumption of servers and the overhead of a load balancer compared with the EPCLB and traditional round-robin (RR) algorithms.",T. Enokido; A. Aikebaier; M. Takizawa,Green IT technology;Digital ecosystems;Power Consumption;CTRB algorithm;Round-robin algorithm,2011,an algorithm for reducing the total power consumption based on the computation and transmission rates,1
330,The Extended Power Consumption Model to Perform Computation Type Application Processes on Virtual Machines,978-1-5090-0987-9,10.1109/CISIS.2016.82,"2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7791857,"Scalable and high performance server cluster systems like cloud computing systems are equipped with virtual machines to efficiently utilize server resources. On the other hand, a large amount of electric energy is consumed in a server cluster system since multiple servers consume electric energy to perform application processes on virtual machines. In order to design and implement an energy-aware server cluster system, the computation model of a virtual machine and power consumption model of a server have to be defined. In our previous studies, we proposed the power consumption model of a server and computation model of a virtual machine to perform application processes on virtual machines. However, the proposed power consumption model and computation model does not consider the change of the clock frequency of each core in a server. In this paper, we consider the change of the clock frequency of each core in a server. Then, we newly proposed the extended power consumption model of a server and computation model of a virtual machine to perform computation type application processes.",T. Enokido; M. Takizawa,Multi-core CPU;Clock frequency;Virtual machines;Energy-aware systems;Green computing,2016,the extended power consumption model to perform computation type application processes on virtual machines,1
331,Autotuning Power Consumption and Computation Accuracy using ppOpen-AT,978-1-6654-6499-4,10.1109/MCSoC57363.2022.00041,2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008423,"Mixed-precision computation mainly focuses on shortening the execution time, at the expense of accuracy. To achieve speedups for numerical calculation using mixed-precision computation, it is necessary to tune software performance with respect to not only execution speed but also computation accuracy and power consumption. This increases the overall cost of tuning. Autotuning (AT) is one of the candidates among several technologies available for reducing the cost associated with tuning the software performance. In this study, we propose a method for AT to obtain speedups with respect to computation accuracy and power consumption. The proposed AT method uses an AT language that changes computation accuracy of the original code to mixed-precision by combining double and single precisions. Performance evaluation was carried out by using the Fujitsu PRIMEHPC FX1000, which is a “Fugaku” type supercomputer installed at the Information Technology Center, Nagoya University. The proposed method achieved a 1.5x reduction in execution time and energy consumption while retaining reasonable accuracy degradation from the original code of a global cloud resolving model.",S. Yamanashi; H. Yashiro; T. Katagiri; T. Nagai; S. Ohshima,Autotuning;Mixed-Precision Computation;Accuracy Optimization;Energy Optimization;ppOpen-AT,2022,autotuning power consumption and computation accuracy using ppopen at,1
332,Evaluating Performance and Energy on ARM-based Clusters for High Performance Computing,978-1-4673-2509-7,10.1109/ICPPW.2012.21,2012 41st International Conference on Parallel Processing Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337476,"The High-Performance Computing (HPC) community aimed for many years at increasing performance regardless to energy consumption. However, energy is limiting the scalability of next generation supercomputers. Current HPC systems already cost huge amounts of power, in the order of a few Mega Watts (MW). The future HPC systems intend to achieve 10 to 100 times more performance, but the accepted energy to power those machines must remain below 20 MW. Therefore, the scientific community is investigating ways to improve energy efficiency. This paper presents a study of the execution time, power consumption, maximum power and energy efficiency using developer boards with ARM processors. Our objective is to verify the feasibility of clusters using processors that target low power consumption. As a sub product of our research we built an unconventional cluster of Panda Boards each one featuring two ARM Cortex A9 cores. We believe that these unconventional solutions bring an alternative base to build HPC clusters that respect the limits of electric energy.",E. L. Padoin; D. A. G. d. Oliveira; P. Velho; P. O. A. Navaux,energy efficiency;ARM processors;developer boards;ARM-based cluster,2012,evaluating performance and energy on arm based clusters for high performance computing,1
333,"Using the Greenup, Powerup, and Speedup metrics to evaluate software energy efficiency",978-1-5090-0172-9,10.1109/IGCC.2015.7393699,2015 Sixth International Green and Sustainable Computing Conference (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393699,"With recognizing power as a first-class citizen in the HPC community and the growth of software running on battery-driven devices, the need to evaluate software design based on the combined effects of energy and performance has become eminent. Despite of the numerous metrics to evaluate software performance, the study on how to evaluate software energy efficiency is still in its early stage. In this paper, we propose the Greenup, Powerup, and Speedup metrics (GPS-UP) to categorize software implementation and optimization efficiency. The GPSUP metrics transform the performance, power and energy of a program into a point on the GPS-UP software energy efficiency quadrant graph. We present eight categories of possible scenarios of software optimization, with examples on how to obtain them. Four categories are green (save energy), and four are red (waste energy). Moreover, we compare our metrics to existing metrics such as Energy Delay Product (EDP).",S. Abdulsalam; Z. Zong; Q. Gu; Meikang Qiu,software energy efficiency;software power measurement;software optimization;software evaluation metrics,2015,using the greenup powerup and speedup metrics to evaluate software energy efficiency,1
335,An Artificial Neural Network Approach to Power Consumption Model Construction for Servers in Cloud Data Centers,,10.1109/TSUSC.2019.2910129,IEEE Transactions on Sustainable Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8685195,"The power consumption estimation or prediction of cloud servers is the basis of energy-aware scheduling to realize energy saving in cloud datacenters. The existing works are mainly based on the static mathematical formulas which establish the relationship between the server power consumption and the system performance. However, these models are weak in adaptability and generalization ability, not adaptable to the changes and fluctuation of different workload, and demanding on the clear and profound understanding of the inner relationship among related power consumption parameters. Therefore, we propose the ANN (Artificial Neural Network) method to model the power consumption of the servers in datacenters, a kind of end-to-end black box model. We performed a fine-grained and in-depth analysis about the system performance and power consumption characteristics of the CPU, memory, and disk of the server running different types of task loads, and selected a set of performance counters that can fully reflect the status of system power consumption as the input of the model. Then, we establish power consumption models based on BP neural network, Elman neural network, and LSTM neural network, respectively. In order to get a better result, we use data collected from four different types of task loads (i.e., CPU-intensive, memory-intensive, I/O-intensive, and mixed load) to train, validate, and test our target models. The experimental results show that, compared with multiple linear regression and support vector regression, the proposed three power models have better performance in predicting the server's real-time power consumption.",W. Lin; G. Wu; X. Wang; K. Li,Power consumption;cloud datacenters;artificial neural network;power modelling,2020,an artificial neural network approach to power consumption model construction for servers in cloud data centers,1
336,A Power Consumption Model for Cloud Servers Based on Elman Neural Network,,10.1109/TCC.2019.2922379,IEEE Transactions on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735730,"Leveraging power consumption models in software systems can achieve easy deployment of low-cost, high-availability power monitoring in cloud datacenters that are usually large-scale, heterogeneous and frequently scaling up. However, traditional regression-based power consumption models generally have two drawbacks. First, their mathematical forms are usually fixed and determined a priori. This may cause unacceptable increase of error or over-fitting as the power signatures of cloud servers are usually uncertain. Second, the characteristic of workload dispatched to cloud servers is constantly changing while regression-based models can hardly generalize to a wide range of servers and workload types. As a novel solution, we in this paper propose a server power consumption model based on Elman Neural Network (PCM-ENN), aiming to allow accurate and flexible power estimation. PCM-ENN is an end-to-end black box model capable of learning the temporal relation between samples in a time series of power consumption. We trained and evaluated PCM-ENN on two power sequence datasets collected from heterogeneous hardware and operating systems running quasi-production benchmarks like CloudSuite. Experimental result shows that PCM-ENN generated accurate estimates on server power consumption with only small errors, outperforming widely-used linear regression model and NARX model in terms of accuracy.",W. Wu; W. Lin; L. He; G. Wu; C. -H. Hsu,Cloud servers;cloud datacenters;power time series;power consumption models;Elman neural network,2021,a power consumption model for cloud servers based on elman neural network,1
337,Estimating the Energy Consumption of Executing Software Processes,978-0-7695-5046-6,10.1109/GreenCom-iThings-CPSCom.2013.40,"2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682054,"Power consumption in data centers is significant across the globe. The use of cloud-based services, e.g., infrastructure as a service and software as a service (such as Google Docs, Microsoft Office 365, Salesforce.com), is becoming a standard practice in modern IT frameworks. This paradigm shift in the IT industry indicates that the demand for data-center-based services will continue to increase in the future, with concomitant increases in power consumption. In such a scenario, optimizing the IT resources to improve energy efficiency is a necessity. The first step of such an optimization at the application level is knowing how much energy an application is consuming. One of the main challenges in this domain is developing a software-based energy metering tool that can measure an OS processes' energy consumption. Many existing solutions depend on an external watt-meter or other hardware-based enhancements, these are not practical for real-world use in data centers. To overcome the limitations of existing solutions, we have developed an OS process-level power metering tool that can accurately estimate the energy usage of each OS process running on a Linux server without an online watt-meter. Based on a set of experiments, we demonstrated that our method and implementation provides energy consumption estimation for complex e-business applications with above 95% accuracy.",V. K. Singh; K. Dutta; D. VanderMeer,Energy;Power Meter;Green IT;Measurement;Modeling,2013,estimating the energy consumption of executing software processes,1
339,Load Prediction for Energy-Aware Scheduling for Cloud Computing Platforms,978-1-5386-1792-2,10.1109/ICDCS.2017.201,2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7980250,"We address online scheduling for servers of Cloud service providers. Each server is composed of several variable-speed processors whose power function is convex. The servers may be busy, idle or switched off. The objective of our scheduling is to minimize the energy consumed by a Cloud computing platform. To achieve this goal, we try to anticipate computing demands by predicting a workload, then we modify the set of available servers to fit this prediction and finally we schedule our jobs on the available servers. To schedule jobs we have developed the POD (Predict Optimize Dispatch) algorithm. We evaluate its performance for real-life traces in the presence of different types of prediction. The analysis shows that our scheduling reduces energy consumption considerably.",A. Dambreville; J. Tomasik; J. Cohen; F. Dufoulon,scheduling;predictor;multi-armed bandit;Cloud;energy consumption,2017,load prediction for energy aware scheduling for cloud computing platforms,1
340,Ultra low energy cloud computing using adaptive load prediction,978-1-889335-42-1,,2010 World Automation Congress,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665423,"The explosion of cloud computing networks throughout the world has lead to a need to reduce the sizeable energy footprint of cloud systems. We discuss a research investigation leading to ultra-low power cloud computing systems. Our methods apply to system such as those used in data centers and web hosting companies. Our analysis indicates massive power reductions up to 80% when optimal dynamical allocation of data center components occurs. We base this upon the application of adaptive load prediction and smart task distribution systems that can be built from current commercial off the shelf (COTS) components integrated with our new concepts. We show that adaptive prediction algorithm in ultra-low power cloud models, coupled with optimal task allocation, leads to design methods for cloud computer architectures optimized around low latency, lower power, and energy dissipation proportional to workloads.",K. M. Nagothu; B. Kelley; J. Prevost; M. Jamshidi,Cloud computing;Energy optimization;Prediction algorithms,2010,ultra low energy cloud computing using adaptive load prediction,1
341,Application of Energy Performance Contracting in Distribution Transformer Based on Neural Network Prediction,978-1-5386-6243-4,10.1109/ITNEC.2019.8729195,"2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8729195,"Energy Performance Contracting has a positive impact on energy clean applications and reducing carbon emissions from a commercial and operational perspective. It is mainly applied to energy-consuming facilities and equipment, but there is still no clear application system on the distribution network side with large domestic losses. From the perspective of predictiveness, this paper analyzes the effect of energy-saving benefits of distribution transformers by using neural network algorithm, and proposes a power contract benefit management model for distribution transformers. Through the model, the expected benefit target of the distribution transformer can be clearly analyzed. The method of this paper can be used to calculate the comprehensive recycling cycle of energy-saving service companies to carry out energy performance contracting business for distribution transformers. The model is robust and proposes a feasible direction for the integrated energy service business on the distribution network side.",X. Wang; C. Lai; D. Yu; Y. Xu; Y. He,Energy Performance Contracting;distribution transformer;neural network;benefit model;recovery cycle,2019,application of energy performance contracting in distribution transformer based on neural network prediction,1
342,Incorporation of weighted linear prediction technique and M/M/1 Queuing Theory for improving energy efficiency of Cloud computing datacenters,978-1-4673-8490-2,10.1109/LISAT.2016.7494148,"2016 IEEE Long Island Systems, Applications and Technology Conference (LISAT)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494148,"Cloud computing refers to the services supplied over the internet and the hardware and software that delivers such services. It has the capability to cover a large part of the IT industry and make software even more appealing as a service. It can also reshape how IT hardware is designed and acquired. Nevertheless, datacenters that offer cloud applications consumes a large amount of power which can substantially increase operational costs. As technology is evolving and growing at a rapid pace, more people are dependent on technology and utilizing the cloud. There's a larger demand to extend the platforms needed to improve the development of Cloud computing. As a result, in parallel with this development of infrastructure, there has also been a great deal of attention paid to energy consumption in cloud computing technology. This research will report on incorporating weighted linear prediction technique and M/M/1 Queuing Theory for enhancing the energy efficiency of cloud data centers. The goal is to simulate the effect of various workloads on energy consumption of the cloud system using CloudSim or similar software.",E. Akbari; F. Cung; H. Patel; A. Razaque; H. N. Dalal,weighted linear prediction;cloud computing;CloudSim,2016,incorporation of weighted linear prediction technique and m m queuing theory for improving energy efficiency of cloud computing datacenters,1
343,Study on the prediction of energy demand based on master slave neural network,978-1-4673-9194-8,10.1109/ITNEC.2016.7560335,"2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560335,"The development of economy, the progress of the society and the modern civilization is inseparable from the energy. Along with rapid development of economy and society, the energy demand grows continuously. Therefore energy demand forecasting has important theoretic and realistic significance. The BP neural network is usually applied to energy demand forecasting. But traditional BP neural network easily gets into part minimum, which leads to non convergence of algorithm and fail training. The master slave neural network (MSNN) is consisted with two Hopfield networks as master network and a BP network as slave network because of its good dynamic evolution performance. It can solve the problem well. Compared with BP neural netwok, MSNN has smaller system error and quicker asymptotic convergence rate. This paper proposes the energy forecasting new model and it is applied to predict energy demand in the last five years. The result shows that MSNN has a more rapid convergence rate. Besides it has smaller network system errors. It predicts ultimately energy demand well. Therefore, the MSNN can improve effect of energy demand forecasting better.",N. Zhao,master slave neural network;energy demand forecasting;BP neural network;Hopfield neural network,2016,study on the prediction of energy demand based on master slave neural network,1
344,Neural Network Adaptive Contribution Evaluation and Prediction Model of Energy Intensity,978-1-6654-5864-1,10.1109/IAEAC54830.2022.9929778,"2022 IEEE 6th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC )",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9929778,"Development of low carbon environmental protection energy becomes requirements, peak in carbon, carbon neutral requirement is raised, extensive international track evaluation index, to evaluate a region cut carbon emission reductions, energy intensity in the whole society as a comprehensive key indicators, both associated with control of the total energy consumption, also related to the benefit of the unit of energy output. This paper proposes a adaptive neural network computing, from the perspective of the connotation of decomposition by multiple elements of social energy intensity contribution model, can be decomposed contribution of various elements on the current energy consumption and to quantify the energy consumption intensity influence key factor prediction, calculation under a given energy intensity target, social economy, efficiency, structure and matching index of growth. Solve the blindness of energy intensity prediction and the matching of policy objectives.",X. Wang; K. Yang; X. Yang; P. Zhu,Energy intensity;Adaptive neural network;Contribution;Indicators,2022,neural network adaptive contribution evaluation and prediction model of energy intensity,1
345,Study on data center server management system for using server power estimation technology,978-1-6654-9927-9,10.1109/APCC55198.2022.9943609,2022 27th Asia Pacific Conference on Communications (APCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943609,"The increasing power consumption in servers is a problem in data centers. One approach to address this is to optimize physical resource allocation for virtualized functions. For this approach, power consumption needs to be estimated, and many papers have proposed models to estimate server power consumption. However, applying such estimation techniques to data center servers presents an operational challenge. Specifically, it is difficult to reduce the cost of model building and data collection while maintaining estimation accuracy. To address this problem, we propose a management system with a modeling function and a data selection function. The modeling function builds accurate models in accordance with application requirements, and the data selection function selects data related to server power consumption and then instructs data collection to each processing server. Our main effort in this paper was to address the monitoring function issue to reduce server power consumption during data collection. We analyze the relationship between server performance data and server power consumption and reduce the type of data. Experimental results showed that our selected data are sufficient to construct a server power modeling. Furthermore, by limiting the amount of data collected, we were able to reduce server power consumption by about 3 W and monitoring overhead by about 30%.",K. Fujita; E. Iwasa; M. Kaneko,server;power consumption;statistical analysis;machine learning,2022,study on data center server management system for using server power estimation technology,1
346,Predicting data structures for energy efficient computing,978-1-5090-0172-9,10.1109/IGCC.2015.7393698,2015 Sixth International Green and Sustainable Computing Conference (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393698,"Dynamic data structures in software applications have been shown to have a large impact on system performance. In this paper, we explore energy saving opportunities of interface-based dynamic data structures. Our results suggest that opportunities do exist in the C5 Collection, at least 16.95% and up to 97.50%. We propose an architecture for building adaptive green data structures by applying machine learning tools to build a model for predicting energy efficient data structures. Our neural network model can classify energy efficient data structures based on features such as the number of elements, frequency of operations, interface and set/bag semantics. The 10-fold cross validation results show 96.01% accuracy on the training data and 95.80% on the training validation data. Our n-gram model can accurately predict the most energy efficient data structure sequence in 19 simulated and real-world programs-on average, with more than 50% accuracy and up to 98% using a bigram predictor.",J. Michanan; R. Dewri; M. J. Rutherford,Energy;Power;Efficiency;Performance;Machine Learning;Neural Network;N-Gram;Bigram;C5 Collection;Green Data Structure;Software Adaptation,2015,predicting data structures for energy efficient computing,1
347,Predicting Cooling Energy Demands of Adaptive Facades Using Artificial Neural Network,978-1-71-385288-9,10.23919/ANNSIM55834.2022.9859413,2022 Annual Modeling and Simulation Conference (ANNSIM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859413,"Adaptive Façades (AFs) have proven to be effective as a building envelope that can enhance energy efficiency and thermal comfort. However, evaluating the performance of these AFs using the current building performance simulation (BPS) tools is complex, time-consuming, and computationally intensive. These limitations can be overcome by using a machine learning (ML) model as a method to assess the AF system efficiently during the early design stage. This study presents an alternative approach using an Artificial Neural Network (ANN) model that can predict the hourly cooling loads of AF in significantly less time compared to BPS. To construct the model, a generative parametric simulation of office tower spaces with an AF shading system were simulated in terms of energy consumption using Honeybee add-on in Grass-hopper which are linked to EnergyPlus for training the ANN model. The prediction results showed a highly accurate model that can estimate cooling loads within seconds.",A. Alammar; W. Jabi,Adaptive Façade;Automatic Control;Cooling Energy Demand;Machine Learning;Artificial Neural Network.,2022,predicting cooling energy demands of adaptive facades using artificial neural network,1
349,A Machine Learning Approach to the Estimation of Near-Optimal Electrostatic Force in Micro Energy-Harvesters,978-1-7281-2140-6,10.1109/WiSEE.2019.8920332,2019 IEEE International Conference on Wireless for Space and Extreme Environments (WiSEE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920332,"Wearable medical sensors are one of the key components of remote health monitoring systems which allow patients to stay under continuous medical supervision away from the hospital environment. These sensors are typically powered by small batteries which allow the device to operate for a limited time. Any disruption in the battery power could lead to temporary loss of vital data. Kinetic-based micro-energy-harvesting is a technology that could prolong the battery lifetime or equivalently reduce the frequency of recharge or battery replacement. Focusing on a Coulomb-Force Parametric Generator (CFPG) micro harvesting architecture, several machine learning approaches are presented in this paper to optimally tune the electrostatic force parameter; and therefore, maximize the harvested power.",M. Roudneshin; K. Sayrafian; A. G. Aghdam,energy harvesting;wearable sensors;microgenerator;CFPG,2019,a machine learning approach to the estimation of near optimal electrostatic force in micro energy harvesters,1
351,"Power Consumption Estimation Models for Processors, Virtual Machines, and Servers",,10.1109/TPDS.2013.183,IEEE Transactions on Parallel and Distributed Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6570721,"The power consumption of presently available Internet servers and data centers is not proportional to the work they accomplish. The scientific community is attempting to address this problem in a number of ways, for example, by employing dynamic voltage and frequency scaling, selectively switching off idle or underutilized servers, and employing energy-aware task scheduling. Central to these approaches is the accurate estimation of the power consumption of the various subsystems of a server, particularly, the processor. We distinguish between power consumption measurement techniques and power consumption estimation models. The techniques refer to the art of instrumenting a system to measure its actual power consumption whereas the estimation models deal with indirect evidences (such as information pertaining to CPU utilization or events captured by hardware performance counters) to reason about the power consumption of a system under consideration. The paper provides a comprehensive survey of existing or proposed approaches to estimate the power consumption of single-core as well as multicore processors, virtual machines, and an entire server.",C. Möbius; W. Dargie; A. Schill,Power consumption models;energy-efficiency;server's power consumption;processor's power consumption;virtual machine's power consumption;power consumption estimation,2014,power consumption estimation models for processors virtual machines and servers,1
352,A Low Power Branch Prediction for Deep Learning on RISC-V Processor,978-1-6654-2701-2,10.1109/ASAP52443.2021.00037,"2021 IEEE 32nd International Conference on Application-specific Systems, Architectures and Processors (ASAP)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516665,"A key factor in reducing power consumption for processors is to improve the accuracy of branch prediction and the optimal use of Branch Target Buffer (BTB) size. The power consumption can be reduced by improving the accuracy of branch prediction if additional increase in power consumption due to prediction logic cannot offset the gain from accurate branch prediction. For applications like Convolutional Neural Networks(CNN), we design a new method called PC-Mix to optimize branch direction prediction and BTB size for reduction of power consumption of RISC-V processors. In simulation, 2.5GHz RISC-V processor design is shown that PC-Mix reduces the power consumption of the original processor on CNN by 35% while keeping performance unchanged or better. Compared with the well-known Gshare mechanism, PC-Mix reduces the total power consumption of CNN by 4% in a worst case scenario. At the same the branch prediction accuracy of our scheme exceeds 95%. Meantime hardware overhead are reduced in the design without affecting performance.",M. Sun; Y. Li; S. Chen; Y. Kang,RISC-V;low power;branch prediction;BTB;Convolutional Neural Networks,2021,a low power branch prediction for deep learning on risc v processor,1
353,Machine learning for performance and power modeling/prediction,978-1-5386-3890-3,10.1109/ISPASS.2017.7975264,2017 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975264,"Effective design space exploration relies on fast and accurate pre-silicon performance and power models. Simulation is commonly used for understanding architectural tradeoffs, however many emerging workloads cannot even run on many full-system simulators. Even if you manage to run an emerging workload, it may be a tiny part of the workload, because detailed simulators are prohibitively slow. This talk presents some examples of how machine learning can be used to solve some of the problems haunting the performance evaluation field. An application for machine learning is in cross-platform performance and power prediction. If one model is slow to run real-world benchmarks/workloads, is it possible to predict/estimate its performance/power by using runs on another platform? Are there correlations that can be exploited using machine learning to make cross-platform performance and power predictions? A methodology to perform cross-platform performance/power predictions will be presented in this talk. Another application illustrating the use of machine learning to calibrate analytical power estimation models will be discussed. Yet another application for machine learning has been to create max power stressmarks. Manually developing and tuning so called stressmarks is extremely tedious and time-consuming while requiring an intimate understanding of the processor. In our past research, we created a framework that uses machine learning for the automated generation of stressmarks. In this talk, the methodology of the creation of automatic stressmarks will be explained. Experiments on multiple platforms validating the proposed approach will also be described.",L. K. John,,2017,machine learning for performance and power modeling prediction,1
355,Accurate Performance and Power Prediction for FPGAs Using Machine Learning,978-1-6654-8332-2,10.1109/FCCM53951.2022.9786072,2022 IEEE 30th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786072,"Although high-level synthesis (HLS) tools have allowed software engineers to investigate FPGAs, they are slow to synthesize and simulate, and they require users’ knowledge and setup time. Using machine learning algorithms (ML) to predict applications’ execution time and power consumption on FPGAs can significantly speed up the process. Oneal et al. [1] used random forest along with CPU code and its microarchitecture-dependent runtime features to predict the performance and power of FPGAs. However, they split benchmarks into several windows of execution time (data points), which can be similar. Many similar data points in the dataset result in a model that may not generalize well for new applications. In this work, we propose a fast, accurate, and generalizable method to predict the execution time, and power consumption of applications on FPGAs using ensemble ML. Our method uses CPU code and related features at three levels LLVM-IR, source code, and dynamic runtime. We use cross-validation and ensure that our method is accurate, robust, and generalizable.",L. Sawalha; T. Abuaita; M. Cowley; S. Akhmatdinov; A. Dubs,,2022,accurate performance and power prediction for fpgas using machine learning,1
356,A Comparative Study of Machine Learning Algorithms in Demand Power Prediction,978-1-7281-4988-2,10.1109/ICCSP48568.2020.9182214,2020 International Conference on Communication and Signal Processing (ICCSP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182214,"The usage of electrical energy is evident. Therefore the generation of electrical power is not so easy. Consumption of electrical energy can be classified into two categories viz. residential and commercial. In the case of the residential sector, heavy fluctuation may occur according to the energy usage pattern concerning time. This unusual variation in power patterns may give stress to generating units. Therefore, if we can predict the demand in early stages we could take remedies like increasing/decreasing power generation capacity, inheriting data power and reducing its usage, giving less stress and also will not transfer stress to other appliances. Thus the prediction of electricity consumption is required. During peak and off-peak hours mainly our aim is for approximately predicting the required demand with the help of demand response to match the available energy resources. As a result of this load at the power station would be balanced. From the demand prediction, we try to swap the resources from peak hours (which consume high energy) to off-peak hour (which consume minimal energy).",M. Kaur; S. Panwar; A. Joshi; K. Gupta,Demand;prediction;energy consumption;residential.,2020,a comparative study of machine learning algorithms in demand power prediction,1
357,A benchmark implementation for evaluating the performance of power-aware routing algorithms in practical Software-Defined Networks,978-1-5386-2855-3,10.1109/SDS.2017.7939151,2017 Fourth International Conference on Software Defined Systems (SDS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939151,"The increase in demand for high network bandwidth has significantly increased the network power consumption and hence, capital expenditure and operational expenditure costs. Service providers are investigating various approaches to reduce operational and management costs, while delivering richer services across their networks. Recently, several centralized power-aware routing heuristic algorithms have been proposed leveraging the centralized control of the Software Defined Networking (SDN) architecture. However, a base solution for benchmarking the performance of these algorithms has not been developed yet. In this paper we propose an implementation of the centralized power-aware routing problem for SDN in GAMS. This implementation facilitates solving the problem using commercial packages and hence serves as a benchmark for accessing the performance of centralized power-aware routing algorithms. Experimental results demonstrate the efficiency of the developed implementation.",Y. Rafique; M. K. Awad; G. Neama,,2017,a benchmark implementation for evaluating the performance of power aware routing algorithms in practical software defined networks,1
358,Creating and Evaluating a Software Power Model for Linux Single Board Computers,978-1-4503-5732-6,,2018 IEEE/ACM 6th International Workshop on Green And Sustainable Software (GREENS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449401,"The number of Single Board Computers (SBCs) is increasing, and so is the cumulative energy consumed by this category of device. Moreover, such devices are often always-on or running on batteries. Therefore, it is worth investigating their energy consumption to provide software developers and users with indicators for understanding how much energy the device is consuming while running a software application. In this paper, we explain a procedure for the creation of an energy consumption model of SBCs based on the usage of its components. We apply the procedure on a Raspberry PI 2 model B to test the model with a set of real applications. The results demonstrate the practical feasibility of the approach and show that estimated consumption values on our device have an average error of 2.2%, which is a good approximation without using external and expensive measuring devices.",L. Ardito; M. Torchiano,energy consumption;software energy consumption;software engineering;energy consumption data;computer engineering,2018,creating and evaluating a software power model for linux single board computers,1
359,Simulators Usage Analysis to Estimate Power Consumption in Cloud Computing Environments,978-1-7281-3772-8,10.1109/WSCAD.2018.00020,2018 Symposium on High Performance Computing Systems (WSCAD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8748875,"Cloud computing is one of the most popular technologies since it offers many benefits to IT companies around the world. However, cloud providers are facing increasing demand for computing services and requiring more and more power consumption. This paper evaluates the power consumption in large data centers through the use of cloud computing simulators, with various resources arrangements and how they impact on total power consumption. The results demonstrate how simulators could estimate energy costs for different types of infrastructures. Furthermore, we present an analysis of hardware utilization during the simulators execution.",V. Meyer; R. Krindges; T. C. Ferreto; C. A. F. De Rose; F. Hessel,"Cloud Computing, Power Consumption, Energy-aware Simulation",2018,simulators usage analysis to estimate power consumption in cloud computing environments,1
360,Power Usage Modelling and Prediction Using Artificial Neural Networks,978-1-6654-9981-1,10.1109/ICSSA54161.2022.9870959,2022 4th International Conference on Smart Sensors and Application (ICSSA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870959,"In recent years, improving energy efficiency in the building sector has been a major trend globally due to its high consumption of electricity. The purpose of this study is to implement a data-driven method of Artificial Neural Networks (ANN) to predict a building’s energy consumption at one of the ministry buildings in Putrajaya. The prediction models were developed based on historical data on the electricity consumption of the building and weather forecasts including temperature, relative humidity and pressure from September 2009 to April 2017. Various configurations were tested based on the ‘trial and error’ method to improve the accuracy of the model. The forecasting model achieved 0.8237% of Mean Absolute Percentage Error (MAPE) and 99.17% of accuracy. The findings of the study will enable the management to model and predict the power usage of the facility using ANN in WEKA. The power usage prediction will help to provide input in understanding the future energy consumption behavior of the facility and will enable the management to assess potential energy efficiency improvements and behavior modification of the building towards achieving higher energy savings.",U. N. A. Hamilludin; H. Abdullah; N. A. Bani; N. M. Noor; S. Z. A. Jalil; S. H. Ismail,energy;efficiency;ANN;WEKA;forecasting,2022,power usage modelling and prediction using artificial neural networks,1
361,Improving Multicore Server Performance and Reducing Energy Consumption by Workload Dependent Dynamic Power Management,,10.1109/TCC.2015.2440238,IEEE Transactions on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118153,"The technique of using workload dependent dynamic power management (i.e., variable power and speed of processor cores according to the current workload) to improve system performance and to reduce energy consumption is investigated. Typically, the power supply and the core speed are increased when there are more tasks in a server, such that tasks can be processed faster and the average task response time is reduced. On the other hand, the power supply and the core speed are decreased when there are less tasks in a server, such that energy consumption can be reduced without significant performance degradation. A queueing model of multicore server processors with workload dependent dynamic power management is established. Several speed schemes are proposed and it is demonstrated that for the same average power consumption, it is possible to design a multicore server processor with workload dependent dynamic power management, such that its average task response time is shorter than a multicore server processor of constant speed (i.e., without workload dependent dynamic power management). It is shown that given certain application environment and average power consumption, there is an optimal speed scheme that minimizes the average task response time. For two-speed schemes, the problem of optimal design of a two-speed scheme for given power supply and power consumption model is formulated and solved. It is pointed out that power consumption reduction subject to performance constraints can be studied in a similar way as performance improvement (i.e., average task response time reduction) subject to power consumption constraints. To the best of our knowledge, this is the first work on analytical study of workload dependent dynamic power management.",K. Li,Dynamic power management;energy consumption;multicore server processor;queueing model;response time;Dynamic power management;energy consumption;multicore server processor;queueing model;response time,2016,improving multicore server performance and reducing energy consumption by workload dependent dynamic power management,1
362,Energy-Efficient Server Selection Algorithm Based on the Extended Simple Power Consumption Model,978-1-4673-1233-2,10.1109/CISIS.2012.29,"2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245597,"In information systems, a client first selects a server in a cluster of servers and issues a request to the server. The request is performed as a process in the server. In this paper, we consider a computation process which mainly consumes CPU resource. Cooling devices like fans consume the electric power in addition to CPU and other devices in a server. The rotation speed of a fan is changed in servers according to the temperature of a server. Thus, the total power consumption of a server depends on not only computational devices like CPU but also cooling devices. The extended simple power consumption (ESPC) model of a server is proposed to perform processes. In this paper, the ESPC model is improved to consider a server with a multi-core CPU. It is critical to discuss how to select a server for each request from clients in order to not only achieve performance objectives but also reduce the total power consumption of a system based on the ESPC model. The improved power consumption laxity based (IPCLB) algorithm for selecting a server is proposed in this paper, which consumes the minimum power to perform the process. We evaluate the ESPC model and the IPCLB algorithm in terms of the power consumption and elapse time in this paper.",T. Enokido; M. Takizawa,Energy-aware information systems;Green IT technology;Power consumption model;Extended simple power consumption (ESPC) model;IPCLB algorithm;multi-core CPU,2012,energy efficient server selection algorithm based on the extended simple power consumption model,1
363,Research on Deep Learning Energy Consumption Prediction Based on Generating Confrontation Network,,10.1109/ACCESS.2019.2949030,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880551,"In the context of increasingly tight energy supply and rising prices, it is of great significance to carry out research on energy consumption prediction models with energy conservation as the goal. In order to improve energy efficiency, it is not only necessary to conduct statistics and analysis on energy historical data, but also to predict future energy data. In this paper, Bicubic interpolation algorithm and convolutional neural network are used to spatially predict energy consumption. The model framework structure for energy consumption prediction is given, and the two models are experimentally analyzed. The results show that the convolutional neural network is better than the Bicubic interpolation method, and the prediction result is closer to the actual value. For the high spatial complexity of energy consumption data, the definition and framework of the RessNetGAN model are first given. Secondly, the specific structure of the generator is given. How to extract the spatial eigenvalue of energy consumption through 3D convolution operation is introduced, and the experiment is carried out by changing the pooling parameters of the energy consumption to be predicted. The results show that the RessNetGAN model with generated confrontation structure has better prediction performance than the convolutional neural network model, and when the input energy consumption data is very low precision, there will be no serious distortion of the prediction result.",S. Fan,Energy consumption forecasting;deep learning;generating confrontation networks;spatial domain reconstruction,2019,research on deep learning energy consumption prediction based on generating confrontation network,1
364,Exploring Deep Learning and Tree-Based Ensemble Models for Chiller Energy Consumption Predictions,978-1-6654-2637-4,10.1109/ICIIS53135.2021.9660662,2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660662,"During the past century, the energy consumption of the entire planet has drastically increased due to various factors, including technological and population-based. Therefore increasing energy efficiency is of great importance to achieve overall sustainability. Energy consumption of buildings regarding Heating, Ventilation, and Air Conditioning (HVAC) plays a significant role in commercial buildings. Predicting the energy consumption of a building aids tremendously when optimizing its energy consumption. Knowing the energy consumption of the building beforehand provides the advantage to make informed decisions for enhanced energy efficiency by facility managers and utilities. At present, Machine Learning (ML) and Deep Learning (DL) play an essential role in making predictions using past data. This paper presents a comparative analysis of using Feedforward Neural Networks (FNN), Random Forest (RF) and Recurrent Neural Network (RNN) models for predicting energy data of a chiller system and introduces best practices to improve the model performances.",U. Kanewala; S. Weerakoon; R. Nawarathna,HVAC Systems;Energy Consumption;Machine Learning;Deep Learning;Feedforward Neural Networks;Random Forrest;Recurrent Neural Networks,2021,exploring deep learning and tree based ensemble models for chiller energy consumption predictions,1
365,Genetic Algorithm Based Optimized Feature Engineering and Hybrid Machine Learning for Effective Energy Consumption Prediction,,10.1109/ACCESS.2020.3034101,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240924,"Smart grids are developing rapidly, leading to the need for accurate forecasts of power consumption. However, developing a precise time series model for energy forecasting is difficult. It has to be trained using optimal meteorological features such as temperature and time lags to qualify for a beneficial model. We have proposed an approach that uses an ensemble machine learning model based on XGBoost, support vector regressor (SVR), and K-nearest neighbors (KNN) regressor algorithms. We have also used the genetic algorithm (GA) to predict total load consumption from optimal feature selection. Using Jeju island's electricity consumption data as a case study shows that the proposed ensemble model optimized with GA is more accurate than the individual machine learning models. Using only the best-selected weather and time features, the proposed model records all the features of a complicated time series and shows a reduction in the mean absolute percentage error (MAPE) and the root mean square log error for the week ahead forecasts. We got 3.35 % MAPE of the three months test data by applying the proposed model. The smart grids operators can manage resources effectively to provide excellent services to the consumers based on the recommended model outcomes.",P. W. Khan; Y. -C. Byun,Energy forecasting;ensemble model;feature engineering;genetic algorithm;K-nearest neighbors;meteorological features;power consumption;smart grids;support vector regressor;XGBoost,2020,genetic algorithm based optimized feature engineering and hybrid machine learning for effective energy consumption prediction,1
367,Recent advances in detection and prediction of customers energy consumption patterns through the use of machine learning techniques,978-1-6654-2714-2,10.1109/ICEET53442.2021.9659738,2021 International Conference on Engineering and Emerging Technologies (ICEET),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659738,"Due to the increasing volume of energy losses from power companies, identifying fraudulent consumers who use illegal practices to gain advantages over energy consumption has become an important process. By analizing data on energy consumption collected from customers, it is possible to trace usage patterns and further employ them to build smart algorithms capable of detecting illegal usage of power, thus aiding companies to fix irregularities and recover the damages caused by fraudulent consumers. In this paper, we present and discuss recent researches that have been published in the literature regarding energy losses, energy consumption forecasts and prediction of illegal consumption. Most of the studies in electricity consumption field aim for trying to detect fraudulent customers based on their kwh consumption, comparing the oldest pattern of the customer analyzed or neighborhood pattern, identifying possible load deviation due to fraudulent usage.",G. Ribeiro; C. Maione; C. Gonçalves; D. de Castro Rodrigues; R. M. Barbosa,Energy losses;non-techinical losses;consumption forecasts;electricity theft;machine learning,2021,recent advances in detection and prediction of customers energy consumption patterns through the use of machine learning techniques,1
368,Comparative LSTM and SVM Machine Learning Approaches for Energy Consumption Prediction: Case Study in Akmola,978-1-6654-6790-2,10.1109/SIST54437.2022.9945776,2022 International Conference on Smart Information Systems and Technologies (SIST),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9945776,"Load forecasting is one of the most important aspects of power systems and Smart City concept. Forecasting a load of a power system with great accuracy not only for a few weeks but also for several years is important in terms of both technical and economic aspects. Nowadays, there exist many methods that are modeled to forecast the consumer's load. This paper will mainly focus on developing forecasting model basing on two Machine Learning (ML) techniques. The first is the branch of RNN method, which is named as Long-Short Term Memory (LSTM). The second one is Support Vector Machine. Both methods solve the problems related with prediction and show high accuracy and precision in time-series application.",A. Satan; A. Khamzina; D. Toktarbayev; Z. Sotsial; I. Bapiyev; N. Zhakiyev,Energy System;Energy Consumption Prediction;Machine Learning;LSTM;SVM,2022,comparative lstm and svm machine learning approaches for energy consumption prediction case study in akmola,1
369,Comparison and Analysis of Prediction Models for Locomotive Traction Energy Consumption Based on the Machine Learning,,10.1109/ACCESS.2023.3268531,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10105190,"Locomotive traction energy consumption is a multivariate coupled nonlinear system closely related to many factors such as locomotive properties, routing, line conditions, and operating methods. In order to accurately calculate and predict locomotive traction energy consumption, three prediction models are constructed based on a large number of measured operation data of the HX $_{\mathrm {D}}1$  locomotive. This research uses two neural network methods of backpropagation and radial basis functions, as well as support vector machines. Among them, the training group uses 600 data; the validation group uses 200 data. The above methods can be compared and analyzed with prediction performance between different neural networks and machine learning algorithm models. The results show that the RBF and BP neural networks can effectively predict locomotive traction energy consumption among the different neural network models. The  $\text{R}^{2}$  of the two neural network model test groups is 0.9926 and 0.9885, the MAPE is 2.91% and 7.28%, and the MSE is 0.02% and 0.08%, respectively. Moreover, we have avoided the influence of the randomness of the neural network algorithm through repeated running. It shows that RBF neural network is better than BP neural network in predicting locomotive traction energy consumption, with more powerful approximation performance and higher accuracy. Among the different machine learning algorithms, the  $\text{R}^{2}$  of the SVM algorithm model test group is 0.9983, the MAPE is 2.01%, and the MSE is 0.02%, which shows the prediction accuracy and overall performance of the SVM algorithm model are better than the neural network model. Finally, we prove the broad generalization of the SVM algorithm through the application on other lines. The SVM algorithm model can be a powerful tool for calculating and predicting the traction energy consumption of HX $_{\mathrm {D}}1$  locomotives.",H. Liang; Y. Zhang; P. Yang; L. Wang; C. Gao,Machine learning;neural network models;support vector machine models;traction energy prediction,2023,comparison and analysis of prediction models for locomotive traction energy consumption based on the machine learning,1
370,Architecture-Level Energy Estimation for Heterogeneous Computing Systems,978-1-7281-8643-6,10.1109/ISPASS51385.2021.00042,2021 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408176,"Due to the data and computation intensive nature of many popular data processing applications, e.g., deep neural networks (DNNs), a variety of accelerators have been proposed to improve performance and energy efficiency. As a result, computing systems have become increasingly heterogeneous, with application-specific processing offloaded from the CPU to specialized accelerators. To understand the energy efficiency of such systems, it is desirable to characterize holistically the energy consumption of the CPU, the accelerator, and the data transfers in between. We present a modularized architecture-level energy estimation framework that captures the energy breakdown across the various CPU and accelerator components with a unified energy estimation back-end that allows easy integration of accelerator modeling frameworks for emerging designs. Using DNN workloads as examples, we show that CPU-end preprocessing and data transfers to and from the accelerator can account for up to 45-50% of total energy when assessing the system as a whole. Related open-source code is available at https://accelergy.mit.edu.",F. Wang; Y. N. Wu; M. Woicik; J. S. Emer; V. Sze,Architecture-Level Estimation;SoC Energy Estimation;Deep Neural Network Accelerators,2021,architecture level energy estimation for heterogeneous computing systems,1
371,Developing an environment for embedded software energy estimation,0-7803-8138-6,10.1109/IDAACS.2003.1249508,"Second IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, 2003. Proceedings",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1249508,We present a complete description and evaluation of the features of a novel method for the instruction-level energy consumption measurement and the corresponding modeling approach for embedded microprocessors. According to the proposed method the base and inter-instruction energy costs of the ARM7 embedded processor as well as the energy cost due to different values in the instruction parameters are modeled. These models can be used in the estimation of the energy consumed by the processor to execute real software programs. A software tool has been developed for this estimation. The energy models derived for the instructions of ARM7 embedded processor are analyzed and the energy estimation framework is presented,S. Nikolaidis; T. Laopoulos; A. Chatzigeorgiou,,2003,developing an environment for embedded software energy estimation,1
373,Evolutionary Neural Network Based Energy Consumption Forecast for Cloud Computing,978-1-5090-0144-6,10.1109/ICCCRI.2015.17,2015 International Conference on Cloud Computing Research and Innovation (ICCCRI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7421894,"The success of Hadoop, an open-source framework for massively parallel and distributed computing, is expected to drive energy consumption of cloud data centers to new highs as service providers continue to add new infrastructure, services and capabilities to meet the market demands. While current research on data center airflow management, HVAC (Heating, Ventilation and Air Conditioning) system design, workload distribution and optimization, and energy efficient computing hardware and software are all contributing to improved energy efficiency, energy forecast in cloud computing remains a challenge. This paper reports an evolutionary computation based modeling and forecasting approach to this problem. In particular, an evolutionary neural network is developed and structurally optimized to forecast the energy load of a cloud data center. The results, both in terms of forecasting speed and accuracy, suggest that the evolutionary neural network approach to energy consumption forecasting for cloud computing is highly promising.",Y. W. Foo; C. Goh; H. C. Lim; Z. -H. Zhan; Y. Li,hadoop;cloud computing;energy efficiency;evolutionary computing;genetic algorithm;neural networks,2015,evolutionary neural network based energy consumption forecast for cloud computing,1
374,Energy Consumption Averaging and Minimization for the Software Defined Wireless Sensor Networks With Edge Computing,,10.1109/ACCESS.2019.2955691,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911459,"The software-defined (SD) and edge computing (EC) are emerging technologies that have been used to improve the network operation efficiency of wireless sensor networks (WSNs). Due to the advantages of the SD and EC technologies, the area of WSNs has achieved a new dimension and breakthrough. However, the limited energy allocation mechanism in edge-SD wireless sensor networks (ESDWSNs) makes the energy consumption of different nodes unbalanced. In this paper, we propose an energy allocation optimization (EAO) algorithm that solves the energy averaging and minimization (ECAM) problem in ESDWSNs by selecting appropriate relay nodes and de-duplicated data flows. Specifically, we first establish a novel three-layer network architecture based on the edge computing and software-defined technologies. Then we proposed the ECAM problem, which minimizes the energy consumption in ESDWSNs. Furthermore, we propose an adaptive Levenberg-Marquardt algorithm and derive the optimization value of energy cost function. The extensive simulation results based on the NS-2 simulator demonstrate the energy balance efficiency of the EAO algorithm in ESDWSNs.",G. Li; Y. Xu,Edge computing (EC) technology;energy allocation optimization (EAO) algorithm;energy consumption averaging and minimization;software-defined (SD) technology;wireless sensor networks (WSNs),2019,energy consumption averaging and minimization for the software defined wireless sensor networks with edge computing,1
378,The College Compus Energy Monitoring Platform for Artificial Intelligence Application,978-1-5386-4291-7,10.1109/ISGT-Asia.2018.8467982,2018 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467982,"In this paper, an energy consumption monitoring platform for the college compus has been developed. The implemented platform can realize the distributed monitoring and centralized control & management for the real-time energy and water consumption data for four-level measurement. It can provide data analysis, data storage, information remote transmission and intuitive display to the administrative control center and personnel. Furthermore, it can realize the water metering balance and appropriate public air-conditioner energy adjusting consumption. The water and electricity consumption of the student dormitories and office buildings can be monitored, remotely measured and intelligently paid, possessing the antitheft function. Besides, the specific energy APPs are also developed to control the terminals remotely via the mobile phone. The designed energy monitoring system has been implemented in the compus successfully.",Y. Zhou; Z. Yang; Y. Guo; Q. Wu,Energy consumption;Compus;Communication network;Platform,2018,the college compus energy monitoring platform for artificial intelligence application,1
379,A Multi-Path Routing Protocol Based on Link Lifetime and Energy Consumption Prediction for Mobile Edge Computing,,10.1109/ACCESS.2020.2986078,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057666,"During mobile edge computing, due to the movement of nodes and the exhaustion of node energy, link failure occurs thus reducing the network lifetime in the mobile ad-hoc network. When the route fails, because the single-path protocols need to restart the route discovery process, the delay of the network is greatly increased. Therefore, the multi-path routing protocol is proposed, saving the cost of route discovery. In this paper, we propose an ad hoc on-demand multi-path distance vector (AOMDV) routing protocol based on link lifetime and energy consumption prediction (named LLECP-AOMDV) for mobile edge computing. In the route discovery phase, the energy grading strategy is adopted. When the node energy is lower than the threshold, it no longer participates in the route discovery. In the routing selected phase, the path is selected based on the lifetime of the route link and the minimum energy consumption of the route. According to energy consumption, packet delivery rate, end-to-end delay performance indicators, we evaluate the comparison results. The result shows that under most network performance indicators and parameters, the proposed LLECP-AOMDV is superior to the other three protocols, which improves the network lifetime, reduces the node’s energy consumption and the average end-to-end delay. The protocol is very useful for mobile edge computing.",D. -G. Zhang; L. Chen; J. Zhang; J. Chen; T. Zhang; Y. -M. Tang; J. -N. Qiu,Mobile edge computing;MANET;AOMDV;energy threshold;link lifetime;energy consumption,2020,a multi path routing protocol based on link lifetime and energy consumption prediction for mobile edge computing,1
380,A comparative study on neural network-based prediction of smart community energy consumption,978-1-5386-0435-9,10.1109/UIC-ATC.2017.8397441,"2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8397441,"This paper presents a comparative study on designing accurate prediction of future energy consumption at both the household level and the community level. Different Neural Network (NN), including conventional NN, Deep Neural Networks (DNN), and Sliding Window Neural Networks (SWNN), are compared in this work, where a SWNN uses a window of historical data to predict the future energy consumption. Our experimental study shows that the conventional NN can achieve high accuracy in prediction while deep NN does not generate better results. Through data normalization and temporal relationship exploration, SWNN becomes superior to conventional methods and achieves above 99.5% accuracy with a more condensed error distribution.",L. Sun; J. Hu; Y. Liu; L. Liu; S. Hu,Sliding Window Neural Networks;Deep Neural Networks;Energy Consumption;Prediction;Smart Community,2017,a comparative study on neural network based prediction of smart community energy consumption,1
382,A novel approach to memory power estimation using machine learning,978-1-4244-8275-7,10.1109/ICEAC.2010.5702284,2010 International Conference on Energy Aware Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5702284,"Reducing power consumption has become a priority in microprocessor design as more devices become mobile and as the density and speed of components lead to power dissipation issues. Power allocation strategies for individual components within a chip are being researched to determine optimal configurations to balance power and performance. Modelling and estimation tools are necessary in order to understand the behaviour of energy consumption in a run time environment. This paper discusses a novel approach to power metering by estimating it using a set of observed variables that share a linear or non-linear correlation to the power consumption. The machine learning approaches exploit the statistical relationship among potential variables and power consumption. We show that Support Vector Machine regression (SVR), Genetic Algorithms (GA) and Neural Networks (NN) can all be used to cheaply and easily predict memory power usage based on these observed variables.",M. Stockman; M. Awad; R. Khanna; C. Le; H. David; E. Gorbatov; U. Hanebutte,Support Vector Machine;Genetic Algorithm;Neural Network;Power Estimation;Machine Learning,2010,a novel approach to memory power estimation using machine learning,1
384,High-Level Early Power Estimation of FPGA IP Based on Machine Learning,978-1-6654-8823-5,10.1109/ICECS202256217.2022.9970952,"2022 29th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9970952,"When high speed and high performance are key features of a specific FPGA-based system, increase in energy consumption becomes the main hurdle to be tackled while keeping a trade-off between speed, performance and power consumption. Therefore, power optimization has become a major concern for most digital hardware designers, particularly in early design phases and especially in limited power budget systems (battery-operated hand-held devices, electro-optical pluggable modules, IoT and green energy systems, etc.). In this paper we present and evaluate an accurate power modeling and estimation technique based on machine learning. We estimate the power consumption of specific digital circuits based on control and input signals characteristics. The proposed Artificial Neural Network (ANN) model is trained using real measurement data sets appended to the input switching activity information. Upon applying the proposed model to an FPGA circuit, experimental results demonstrate its efficiency and confirm its accuracy. Results are presented in terms of the mean absolute percentage estimation error being less than 1% for the estimated average power consumption. This work aims at presenting a practical yet efficient power optimization approach that may be extended to online power management.",M. Richa; J. -C. Prévotet; M. Dardaillon; M. Mroué; A. E. Samhat,Data generation and acquisition;power measurement;FPGA;power estimation and modeling;machine learning;artificial neural networks,2022,high level early power estimation of fpga ip based on machine learning,1
385,An Optimised Energy Efficient Task Scheduling Algorithm based on Deep Learning Technique for Energy Consumption,979-8-3503-4696-1,10.1109/ISCON57294.2023.10112019,2023 6th International Conference on Information Systems and Computer Networks (ISCON),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10112019,"The information technology (IT) and mobile computing industries are now in the development stages of cloud computing (CC). Instead of being purchased, resources such as software, CPUs, memory, I/O hardware, and others are used and charged as needed. The massive expansion of CC necessitates enormous energy consumption, or data centers house a diverse spectrum of computers. Consequently, cloud service providers are exploring low-cost strategies for reducing energy use and carbon emissions. Therefore, work planning has garnered great attention and critical consideration about effective resources and bad energy consumption. This paper proposes a machine learning technique called short-term or Long-Term Memory (LSTM) for efficient power task scheduling to address growing carbon or energy emissions. The recommended strategy for scheduling considers the finish time or exclusive usage of a resource task, as well as the standardizing process. The Novel Black Window is used to reduce weight and improve the performance of LTSM. The simulated analysis is used to evaluate the efficiency of the LSTM-NBW in aspects of makes pan, power consumption, task completion time, and resource utilization. The findings show that the suggested model only obtained 400KWh more for the 80kB user job than the original LSTM model.",J. Mahilraj; P. Sivaram; N. Lokesh; B. Sharma,Cloud Computing;Deep Learning Technique;Energy Consumption;optimization;Resource Utilization;Task Scheduling Algorithm,2023,an optimised energy efficient task scheduling algorithm based on deep learning technique for energy consumption,1
388,Temperature Distribution Prediction in Data Centers for Decreasing Power Consumption by Machine Learning,978-1-4673-9560-1,10.1109/CloudCom.2015.49,2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7396226,"To decrease the power consumption of data centers, coordinated control of air conditioners and task assignment on servers is crucial. It takes tens of minutes for changes of operational parameters of air conditioners including outlet air temperature and volume to be actually reflected in the temperature distribution in the whole data center. Proactive control of the air conditioners is therefore required according to the predicted temperature distribution, which is highly dependent on the task assignment on the servers. In this paper, we apply a machine learning technique for predicting the temperature distribution in a data center. The temperature predictor employs regression models for describing the temperature distribution as it is predicted to be several minutes in the future, with the model parameters trained using operational data monitored at the target data center. We evaluated the performance of the temperature predictor for an experimental data center, in terms of the accuracy of the regression models and the calculation times for training and prediction. The temperature distribution was predicted with an accuracy of 0.095°C. The calculation times for training and prediction were around 1,000 seconds and 10 seconds, respectively. Furthermore, the power consumption of air conditioners was decreased by roughly 30% through proactive control based on the predicting temperature distribution.",Y. Tarutani; K. Hashimoto; G. Hasegawa; Y. Nakamura; T. Tamura; K. Matsuda; M. Matsuoka,Data center;Energy management;Machine learning;Temperature pridiction,2015,temperature distribution prediction in data centers for decreasing power consumption by machine learning,1
389,Source-Level Energy Consumption Estimation for Cloud Computing Tasks,,10.1109/ACCESS.2017.2778309,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8123619,"In the cloud computing environment, the source-level energy consumption (EC) estimation is employed to approximately measure the EC of a cloud computing task before it is executed. The EC estimation on tasks is critical to task scheduling and source-code improvement in the aspect of EC optimization. The existing studies treat a task as a program, and EC of the task as the simple summation of each statement's EC. However, EC of two tasks consisting of the same statements with different structures is unequal; therefore, the code structure should be highlighted in source-level EC estimation. In this paper, an abstract energy consumption (AEC) model, which is static and runtime-independent, is proposed. For the model, the two quantitative measurements, “cross-degree”and “reuse-degree,”are proposed as the code structure features, and the relationship between EC and the measurements is formulated. Although AEC is not a precise EC measurement, it can properly represent the EC of a task, compare with other tasks, and verify the optimization effect. Experimental results show that the ratios between the EC and AEC with 50 test cases are stable; the standard deviation is 0.0002; and the mean value is 0.005. The regularities of EC and code structures, represented as “cross-degree”and “reuse-degree,”are also validated. Though AEC, it is easier to schedule the cloud computing tasks properly and further reduce the consumed energy.",H. Liu; F. Yan; S. Zhang; T. Xiao; J. Song,Abstract energy consumption;code structure;energy consumption estimation;cloud computing tasks;source-level,2018,source level energy consumption estimation for cloud computing tasks,1
390,Data Analysis for Embedded Software Performance and Energy Consumption Estimation,978-1-7281-3882-4,10.1109/UKRCON.2019.8879787,2019 IEEE 2nd Ukraine Conference on Electrical and Computer Engineering (UKRCON),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879787,"This paper proposes a data processing and cleaning method for performance and energy consumption estimation methodology. The primary goal is to develop a MATLAB-based prototype program for extracting necessary information to create an estimation model. The existing data acquisition (DAQ) system was initially combined with spreadsheet based data processing that did not satisfy the data analysis needs. A modular MATLAB-based data processing and cleaning solution was developed in order to manage the requirements. The prototype solution was developed even further, as it was optimised for speed. As a result, more than 70% program execution speed-up was achieved compared to the prototype program. In this paper the MATLAB-based data processing and cleaning as well as analysis are described.",P. Ruberg; E. Liiv; K. Lass; P. Ellervee,data analysis;MATLAB;embedded software,2019,data analysis for embedded software performance and energy consumption estimation,1
391,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,,10.1109/ACCESS.2018.2872750,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8479359,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. Although, there are many existing energy-aware approaches focusing on minimizing energy consumption while ignoring the SLA violation at the time of a virtual machine (VM) selection from overloaded hosts. Also, they do not consider that the current network traffic causes performance degradation and thus may not really reduce SLA violation under a variety of workloads. In this context, this paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation. Energy-aware methods for overloaded host detection and VM selection from an overloaded host are necessary to improve the energy efficiency and SLA violation of a cloud data center after migrating all VM from underloaded host turn to idle host, which switch to energy-saving mode is also beneficial. Gdr and MCP are adaptive energy-aware algorithms based on the robust regression model, for overloaded host detection. A Bw dynamic VM selection policy selects VM according to the network traffic from the overloaded host under SLAs. Experimental results on the real workload traces show that the proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center using a CloudSim simulator to validate the proposed algorithms.",R. Yadav; W. Zhang; O. Kaiwartya; P. R. Singh; I. A. Elgendy; Y. -C. Tian,Cloud computing;cloud data center;energy-efficiency;green computing;host overloaded detection;regression method;service level agreements,2018,adaptive energy aware algorithms for minimizing energy consumption and sla violation in cloud computing,1
392,Deep learning versus traditional machine learning methods for aggregated energy demand prediction,978-1-5386-1953-7,10.1109/ISGTEurope.2017.8260289,2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260289,"In this paper the more advanced, in comparison with traditional machine learning approaches, deep learning methods are explored with the purpose of accurately predicting the aggregated energy consumption. Despite the fact that a wide range of machine learning methods have been applied to probabilistic energy prediction, the deep learning ones certainly represent the state-of-the-art artificial intelligence methods with remarkable success in a spectrum of practical applications. In particular, the use of Multi Layer Perceptrons, recently enhanced with deep learning capabilities, is proposed. Furthermore, its performance is compared with the most commonly used machine learning methods, such as Support Vector Machines, Gaussian Processes, Regression Trees, Ensemble Boosting and Linear Regression. The analysis of the day-ahead energy prediction demonstrates that different prediction methods present significantly different levels of accuracy in the case of a challenging dataset that comprises an interesting mix of consumers, wind and solar generation. The results show that Multi Layer Perceptrons outperform all the eight methods used as a benchmark in this study.",N. G. Paterakis; E. Mocanu; M. Gibescu; B. Stappers; W. van Alst,deep learning;energy consumption;energy prediction;forecasting;machine learning,2017,deep learning versus traditional machine learning methods for aggregated energy demand prediction,1
393,Neural network based power estimation on chip specification,978-1-4244-7386-1,10.1109/ICICIS.2010.5534739,The 3rd International Conference on Information Sciences and Interaction Sciences,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5534739,"This paper forwards a neural network based VLSI power estimation on VLSI chip specification. This paper used neural network to perform VLSI power estimation. Experiments were made on chip specification parameters extracted from the datasheet of TI series micro-controllers. Different net structure, training plans and vector organizations were applied. Based on limited number of test vector, experimental results showed the neural network based power estimation could give acceptable results on chip power with specific net structure. This method can achieve a much faster power estimation result on datasheet of the same kind of VLSI chips without simulation and analysis or simulations of detail structure and interconnections. Higher training/testing ratio leads to a more accurate power estimation value.",L. Hou; X. Wu; W. Wu,power estimation;neural network;chip specification,2010,neural network based power estimation on chip specification,1
394,Estimation of Reasonable Line Loss in Low Power and Light Load Station Area Based on Robust Neural Network,978-1-6654-9993-4,10.1109/PSGEC54663.2022.9881195,2022 Power System and Green Energy Conference (PSGEC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881195,"In order to actively respond to the “double carbon” policy, reduce energy consumption and improve the economic operation of small power and light load stations. In the operation of the power system, a set of benchmark indicators for line loss in a light load station area is established to provide “rulers” for line loss in various station areas, which can indicate the direction of loss reduction in the light load station area. We propose a reasonable line loss estimation approach that is based on robust neural networks for low power and light load station areas, and the minimum redundancy maximum relevance algorithm is suggested to screen the line loss rate factors on the basis of the actual operation of the light load station area and to evaluate the effectiveness of the relevant features based on the forward search strategy. The constructed model can calculate a reasonable line loss numerical value and confirm a sensible upper limit of power loss for the lightly loaded station area. The validity of the improved algorithm is demonstrated by using a sample of station data from a city in Jiangsu Province.",F. Liu; W. Huang; B. Xu; M. Xu; F. Zhang,Small power and light load platform area;robust neural network;forward search;line loss rate,2022,estimation of reasonable line loss in low power and light load station area based on robust neural network,1
395,Trading off prediction accuracy and power consumption for context-aware wearable computing,0-7695-2419-2,10.1109/ISWC.2005.52,Ninth IEEE International Symposium on Wearable Computers (ISWC'05),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1550781,"Context-aware mobile computing requires wearable sensors to acquire information about the user. Continuous sensing rapidly depletes the -wearable system's energy, which is a critically constrained resource. In this paper, we analyze the trade-off between power consumption and prediction accuracy of context classifiers working on dual-axis accelerometer data collected from the eWaich sensing and notification platform. We improve power consumption techniques by providing competitive classification performance even in the low frequency region of 1-10 Hz and for the highly erratic wrist based sensing location. Furthermore, we propose and analyze a collection of selective sampling strategies in order to reduce the number of required sensor readings and the computation cycles even further. Our results indicate that optimized sampling schemes can increase the deployment lifetime of a wearable computing platform by a factor of four without a significant loss in prediction accuracy.",A. Krause; M. Ihmig; E. Rankin; D. Leong; Smriti Gupta; D. Siewiorek; A. Smailagic; M. Deisher; U. Sengupta,,2005,trading off prediction accuracy and power consumption for context aware wearable computing,1
396,Prediction of induced draft fan power consumption in 500MW steam generators using artificial neural network,978-1-5090-6400-7,10.1109/ICBDACI.2017.8070811,2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070811,The Indian power generation market is moving towards deregulation. Deregulation forces the utilities to operate the plant efficiently and economically with reduced in-house auxiliary power consumption. The increase in auxiliary power consumption increases the operation cost of the plant. In future utilities have to correctly predict the power consumption at in-plant auxiliaries to arrive at the total capacity available for selling and to estimate the operational cost. Auxiliary power consumption is an important index that describes how well a thermal power plant is operating. Induced draft (ID) fan power consumption is almost one-third of the total power consumption by in-house auxiliaries. This paper details the methodology adopted for prediction of ID fan power consumption by artificial neural network. Operational parameters from fifty number of boilers have been collected and used for the analysis. Nine influential parameters that accurately describe the power consumption at ID fan are identified. The identified influential parameters are used in the Artificial Neural Network model for predicting the ID fan power consumption. The proposed methodology can be used by power plant operator and designers for effectively predicting the power consumption by ID fan.,A. Sriram; P. R. Venkateswaran; S. P. Simon,Power consumption;induced draft fan;auxiliary power;steam generator;prediction,2017,prediction of induced draft fan power consumption in mw steam generators using artificial neural network,1
399,Model for software power estimation of an 8-bit microcontroller,978-1-61284-172-4,10.1109/SMICND.2011.6095842,CAS 2011 Proceedings (2011 International Semiconductor Conference),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095842,"Over the last years, power has became a primary consideration in hardware design, and it is critical in computer systems especially for portable devices where the batteries should last long before they need to be replaced or recharged. Starting from this consideration the paper presents a model for estimation of power consumption of an 8-bit microcontroller early in the design cycle of embedded software. The tool analyses the assembly code being executed and provides an estimate of its average power consumption.",R. Dochia; D. Bogdan; C. Burileanu,power characterization;power estimation;instruction set characterization;microcontroller simulator,2011,model for software power estimation of an bit microcontroller,1
400,Topics on measuring real power usage on high performance computing platforms,978-1-4244-5011-4,10.1109/CLUSTR.2009.5289179,2009 IEEE International Conference on Cluster Computing and Workshops,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5289179,"Power has recently been recognized as one of the major obstacles in fielding a Peta-FLOPs class system. To reach Exa-FLOPs, the challenge will certainly be compounded. In this paper we will discuss a number of High Performance Computing power related topics. We first describe our implementation of a scalable power measurement framework that has enabled us to examine real power use (current draw). [Using this framework, samples were obtained at a per-node (socket) granularity, at frequencies of up to 100 samples per second.] Additionally, we describe how we applied this capability to implement power conserving measures on our Catamount Light Weight Kernel, where we achieved an 80% improvement. This ability has enabled us to quantify the amount of energy used by applications and to contrast application energy use between a Light Weight and General Purpose operating system. Finally, we show application energy use increases proportionally with the increase in run-time due to operating system noise. Areas of future interest will also be discussed.",J. H. Laros; K. T. Pedretti; S. M. Kelly; J. P. Vandyke; K. B. Ferreira; C. T. Vaughan; M. Swan,,2009,topics on measuring real power usage on high performance computing platforms,1
403,Prediction of Future Loads Using Neural Networks for Energy-Efficient Computing,978-1-5090-2655-5,10.1109/CANDAR.2016.0105,2016 Fourth International Symposium on Computing and Networking (CANDAR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7818675,"In modern data centers a large amount of energy can be saved by intelligently distributing load on the available servers and transferring idle nodes into low energy modes. Distributing load leads to a more energy-efficient usage of the servers within a server farm. Additionally, the use of energy saving modes like suspend to main memory can decrease the energy consumption dramatically. The selection of nodes to be transferred into a low energy mode is based on the information of an energy-efficient load distribution. The usage of low energy modes requires knowledge about future loads. Having a variable load profile, i.e. variations in loads over time, leads to time periods in which servers are idle (denoted as gaps). Within these gaps, servers can be transferred into one of various supported energy saving modes. It is crucial to have information about future gaps in advance to make the right decision in regard to the chosen energy saving mode. Usually, information about the future is not directly available but can be predicted using sophisticated algorithms. In this paper, we present an approach to predict future loads using trends, seasonal data, and neural networks.",J. Lenhardt; W. Schiffmann; S. Jannevers,energy-efficient computing;load prediction;neural networks;server farms;trend analysis,2016,prediction of future loads using neural networks for energy efficient computing,1
404,A Power Consumption Estimation Approach for Embedded Software Design Using Trace Analysis,978-1-4673-7585-6,10.1109/SEAA.2015.34,2015 41st Euromicro Conference on Software Engineering and Advanced Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302432,"With the explosion of advanced power control knobs such as dynamic voltage frequency scaling, mastering energy constraints in embedded systems is becoming challenging for software developers. Several power estimation techniques have been proposed over the past years, from electrical level to more abstract models such as SystemC/TLM. They offer various tradeoffs between performance and accuracy, but suffer from a number of shortcomings. They are expensive and time-consuming, requiring intricate models of the architecture and finally, fail to be applied from the software developer perspective. In this paper, we propose a lightweight and cost-effective approach suitable for software developers. It relies on trace analysis and high-level modeling of architectures to perform quick and efficient power consumption estimations without loosing accuracy. This approach is fully supported by a tool and is validated using a simple thermal mitigation case study and checked against physical measurements. We show that, for our case study, the relative error between our tool and real values is 8% in average.",Y. B. Atitallah; J. Mottin; N. Hili; T. Ducroux; G. Godet-Bar,power consumption;embedded software design;power management and trace analysis,2015,a power consumption estimation approach for embedded software design using trace analysis,1
406,"An empirical study of performance, power consumption, and energy cost of erasure code computing for HPC cloud storage systems",978-1-4673-7891-8,10.1109/NAS.2015.7255220,"2015 IEEE International Conference on Networking, Architecture and Storage (NAS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7255220,"Erasure code storage systems are becoming popular choices for cloud storage systems due to cost-effective storage space saving schemes and higher fault-resilience capabilities. Both erasure code encoding and decoding procedures are involving heavy array, matrix, and table-lookup compute intensive operations. Multi-core, many-core, and streaming SIMD extension are implemented in modern CPU designs. In this paper, we study the power consumption and energy efficiency of erasure code computing using traditional Intel x86 platform and Intel Streaming SIMD extension platform. We use a breakdown power consumption analysis approach and conduct power studies of erasure code encoding process on various storage devices. We present the impact of various storage devices on erasure code based storage systems in terms of processing time, power utilization, and energy cost. Finally we conclude our studies and demonstrate the Intel x86's Streaming SIMD extensions computing is a cost-effective and favorable choice for future power efficient HPC cloud storage systems.",Hsing-bung Chen; G. Grider; J. Inman; P. Fields; J. A. Kuehn,Erasure code;SIMD Vectorization;Power measurement;Energy cost;Power consumption;Cloud storage,2015,an empirical study of performance power consumption and energy cost of erasure code computing for hpc cloud storage systems,1
408,POMMEL: Exploring Off-Chip Memory Energy & Power Consumption in Convolutional Neural Network Accelerators,978-1-6654-2703-6,10.1109/DSD53832.2021.00073,2021 24th Euromicro Conference on Digital System Design (DSD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556365,"Reducing the power and energy consumption of Convolutional Neural Network (CNN) Accelerators is becoming an increasingly popular design objective for both cloud and edge-based settings. Aiming towards the design of more efficient accelerator systems, the accelerator architect must understand how different design choices impact both power and energy consumption. The purpose of this work is to enable CNN accelerator designers to explore how design choices affect the memory subsystem in particular, which is a significant contributing component. By considering high-level design parameters of CNN accelerators that affect the memory subsystem, the proposed tool returns power and energy consumption estimates for a range of networks and memory types. This allows for power and energy of the off-chip memory subsystem to be considered earlier within the design process, enabling greater optimisations at the beginning phases. Towards this, the paper introduces POMMEL, an off-chip memory subsystem modelling tool for CNN accelerators, and its evaluation across a range of accelerators, networks, and memory types is performed. Furthermore, using POMMEL, the impact of various state-of-the-art compression and activity reduction schemes on the power and energy consumption of current accelerations is also investigated.",A. Montgomerie-Corcoran; C. -S. Bouganis,Convolutional Neural Networks;Power Modelling;Machine Learning Acceleration,2021,pommel exploring off chip memory energy power consumption in convolutional neural network accelerators,1
410,PAM: An efficient power-aware multi-level cache policy to reduce energy consumption of Software Defined Network,978-1-6319-0022-8,10.4108/icst.iniscom.2015.258322,2015 1st International Conference on Industrial Networks and Intelligent Systems (INISCom),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7157817,"Nowadays energy consumption is one of the most significant aspects in Internet operations, where multi-level routing is widely used. In a typical hierarchical router cache structure, the upper level storage serves as a cache for the lower level, which forms a distributed multi-level cache system. In the past two decades, several classic LRU-based multi-level cache policies were proposed to improve the overall I/O performance of storage systems. However, few power-aware multi-level cache policies focus on the storage devices in the bottom level, which consume more than 27% energy of the whole system [20]. To address this problem, in this paper, we propose a novel Power-Aware Multi-level cache (PAM) policy, which can reduce the energy consumption of storage devices with both high performance and high I/O bandwidth. In our PAM policy, a proper number of cold dirty blocks in the upper level cache are identified and selected to flush directly to the storage devices, which provides high probability to extend the duration time of data disks with standby status. Thus the energy consumption can be reduced. Simulation results show that, compared to the existing popular cache schemes such as PA-LRU, PB-LRU and Demote, PAM saves the power consumption by up to 15% under different I/O workloads, which improves the energy efficiency by up to 50.5%.",Xiaodong Meng; Long Zheng; Li Li; Jie Li,Storage System;Multi-level Cache;Energy Consumption;I/O Performance;Hint,2015,pam an efficient power aware multi level cache policy to reduce energy consumption of software defined network,1
411,"A Green IoT Node Incorporating Transient Computing, Approximate Computing and Energy/Data Prediction",978-1-7281-3893-0,10.1109/CCNC46108.2020.9045177,2020 IEEE 17th Annual Consumer Communications & Networking Conference (CCNC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045177,"In an effort towards designing a batteryless Internet of Things (IoT) sensor node that is powered by miniaturized energy-harvesting source(s), we combine the techniques of transient computing, approximate computing, data and energy predictions so as to handle the unpredictable power shortages of the miniaturized energy harvesting sources and reduce the overall power consumption of the IoT node. To evaluate the feasibility of our proposed approach, we build upon and extend an existing platform that consists of a peer-to-peer network (a sender node and a receiver node) where each of these nodes combines a Texas Instruments' FRAM-based micro-controller with a low cost, low power radio module and exchanging its data through SimpliciTI protocol. Our results illustrate that combining transient computing, approximate computing, data and energy predictions adds up their individual benefits to achieve an overall better utilization of the harvested energy of the node. Our results show that out of the total 60 transmissions that were due in an interval of 5 hours, for sending the temperature data from sender node to the receiver node every 5 minutes, a total of 32 transmissions were avoided, leading to a saving of more than 50% of the radio transmissions in the sender node.",S. Z. Khan; R. Kakar; M. M. Alam; Y. L. Moullec; H. Pervaiz,Transient Computing;Energy Prediction;Data Prediction;Approximate Computing;SimipliciTI,2020,a green iot node incorporating transient computing approximate computing and energy data prediction,1
412,Integration of Minimum Energy Point Tracking and Soft Real-Time Scheduling for Edge Computing,978-1-7281-7641-3,10.1109/ISQED51717.2021.9424343,2021 22nd International Symposium on Quality Electronic Design (ISQED),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424343,"In the upcoming Internet of Things era, reducing energy consumption of embedded processors is highly desired. Minimum Energy Point Tracking (MEPT) is one of the most efficient methods to reduce both dynamic and static energy consumption of a processor. Previous works proposed a variety of MEPT methods over the past years. However, none of them incorporate their algorithms with practical real-time operating systems, although edge computing applications often require low energy task execution with guaranteeing real-time properties. The difficulty comes from the time complexity for identifying MEP and changing voltages, which often prevents real-time task scheduling. This paper proposes an approximated MEPT algorithm, which reduces the complexity of identifying MEP down to that of Dynamic Voltage and Frequency Scaling (DVFS). We also propose a task scheduling algorithm, which adjusts processor performance to the workload, and provides a soft real-time capability to the system. With these two methods, MEPT became a general task, and the operating system stochastically adjusts the average response time of a processor to be equal to a specified deadline. The experiments using a fabricated test chip show that the energy loss induced by the proposed algorithm is only 0.5% at most, and the algorithm does not sacrifice the fundamental real-time properties.",T. Komori; Y. Masuda; J. Shiomi; T. Ishihara,Minimum Energy Point Tracking (MEPT);Dynamic Voltage and Frequency Scaling (DVFS);Adaptive Body Biasing (ABB);Real-Time Operating System (RTOS);Soft Real-Time Scheduling,2021,integration of minimum energy point tracking and soft real time scheduling for edge computing,1
413,Integrated Energy Monitoring and Control IoT System and Validation Results from Neural Network Control Demonstration,978-1-6654-3568-0,10.1109/AIIoT52608.2021.9454222,2021 IEEE World AI IoT Congress (AIIoT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454222,"Increasing use of renewable and distributed power generation creates opportunities for customer resources to support power system operations by adjusting power consumption and generation to address grid needs, based on system-wide and local grid conditions. We present an integrated Energy Internet of Things (E-IoT) testbed including (1) distributed Advanced Realtime Grid Energy Monitor Systems (ARGEMS) with sensing, communication, and control capabilities, (2) distributed smart home sites, including smart home hubs for monitoring and control of physical and simulated Internet of Things (IoT) distributed energy resources (DERs) such as solar systems, home batteries, and smart appliances, and (3) control algorithms based on artificial intelligence and optimization, which manage customer DERs to respond to power grid conditions while serving customer needs. The integration of these three components enables demonstration and assessment of a variety of advanced DER monitoring and control strategies for improved power grid operations and customer benefits. We validate the functionality of this E- IoT testbed by demonstrating control of a simulated home battery by a neural network imitation learning algorithm running on a physical smart home hub, where the controller responds to grid services events triggered by an ARGEMS device based on local power system measurements and simulated bulk power system conditions. The developed neural network controller imitates the performance of a model predictive control optimization algorithm, but requires nearly 20,000 times less computational time and can run on small distributed computers.",D. Ellman; P. Shukla; Y. Xiao; M. Iskander; K. Davies,internet of things;smart grid;smart home;neural network;imitation learning;demand response,2021,integrated energy monitoring and control iot system and validation results from neural network control demonstration,1
415,Runtime monitoring of software energy hotspots,978-1-4503-1204-2,10.1145/2351676.2351699,2012 Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494916,"GreenIT has emerged as a discipline concerned with the optimization of software solutions with regards to their energy consumption. In this domain, most of the state-of-the-art solutions concentrate on coarse-grained approaches to monitor the energy consumption of a device or a process. However, none of the existing solutions addresses in-process energy monitoring to provide in-depth analysis of a process energy consumption. In this paper, we therefore report on a fine-grained runtime energy monitoring framework we developed to help developers to diagnose energy hotspots with a better accuracy than the state-of-the-art. Concretely, our approach adopts a 2-layer architecture including OS-level and process-level energy monitoring. OS-level energy monitoring estimates the energy consumption of processes according to different hardware devices (CPU, network card). Process-level energy monitoring focuses on Java-based applications and builds on OS-level energy monitoring to provide an estimation of energy consumption at the granularity of classes and methods. We argue that this per-method analysis of energy consumption provides better insights to the application in order to identify potential energy hotspots. In particular, our preliminary validation demonstrates that we can monitor energy hotspots of Jetty web servers and monitor their variations under stress scenarios.",A. Noureddine; A. Bourdon; R. Rouvoy; L. Seinturier,Bytecode Instrumentation;Power Model;Power Monitoring;Profiling,2012,runtime monitoring of software energy hotspots,1
416,SEMFI: A Software-Based and Real-Time Energy Monitoring Platform for WiFi IoT Devices,978-1-6654-5097-3,10.1109/GHTC55712.2022.9911022,2022 IEEE Global Humanitarian Technology Conference (GHTC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9911022,"Many WiFi-based Internet of Things (IoT) devices rely on limited energy resources such as a battery. Although monitoring and studying the energy consumption of these devices is essential, the use of external, hardware-based energy measurement tools is costly, non-scalable, and introduces many challenges regarding the connectivity of such tools with devices. In this paper, we propose Software-based Energy Management Tool for WiFi (SEMFI), a novel tool to collect, analyze, and monitor the power cycles of IoT devices without the need for any external tools. The basic idea is to modify the WiFi Access Point (AP)’s software to keep track of the power status of devices reported in packets. SEMFI also includes back-end and front-end components for data storage, analysis, and visualization. We demonstrate the effectiveness and features of SEMFI via empirical evaluations.",A. Chawla; N. Kannan; S. Goyalia; V. Ramanna; J. Sheth; B. Dezfouli,Energy Efficiency;Energy Monitoring;Mission-critical Applications;Duty Cycle;Sustainability,2022,semfi a software based and real time energy monitoring platform for wifi iot devices,1
417,Hardware and software innovations in energy-efficient system-reliability monitoring,978-1-5386-0362-8,10.1109/DFT.2017.8244435,2017 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244435,"Many threats that can undermine the reliability of a system can be realized at design, while others only during its online operation. As the availability of system monitoring sensors and run-time software increases in heterogeneous platforms, there is a demand for a novel platform-independent framework that can capture and deliver, in a holistic way, system level self-assessment and adaptation capabilities at run-time. In this paper, two groups from academia and one from industry present the following three contributions. First, system reliability is considered from the perspective of novel timing guardband designs for aging mitigation. Effective timing guardband models are presented from the physical to the system level, while targeting multiple wear-out mechanisms. Second, a technique for correlating complex software and micro-architectural events with power integrity loss is presented. The presented technique uses an embedded voltage noise sensor, a power-network model and a genetic algorithm for identifying workload that triggers power-network resonances which can ultimately lead to system failures. Third, the `PRiME' cross-layer programming framework is presented that unites available sensors and dynamic-voltage and frequency scaling actuators with learning-based run-time process mapping and scheduling algorithms. Scenarios on exploring the energy efficiency and reliability of heterogeneous platforms using run-time software derived from the developed framework are also reviewed.",V. Tenentes; C. Leech; G. M. Bragg; G. Merrett; B. M. Al-Hashimi; H. Amrouch; J. Henkel; S. Das,,2017,hardware and software innovations in energy efficient system reliability monitoring,1
420,Accurate and Low-Overhead Process-Level Energy Estimation for Modern Hard Disk Drives,978-0-7695-5046-6,10.1109/GreenCom-iThings-CPSCom.2013.50,"2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682064,"Measuring the energy consumed by modern secondary storage devices and attributing it to the causative application's processes can guide optimization of application energy efficiency. Prior work has focused on hard disk drive or file system energy management using custom-built measurement systems and models, but suffers from limitations that prohibit the attribution of the hardware energy consumption to the causative processes. This paper presents a novel process-level disk drive energy estimation system that monitors the operating system kernel to predict the storage power consumption created by individual processes of a software application. Evaluation reveals that the system is accurate with prediction errors around 7% even for workloads involving simultaneous file system operations from multiple processes. The system creates virtually no power consumption overhead in the CPU and about 4% overhead in the RAM module. Results using I/O benchmarks demonstrate that a large portion of the energy usage (up to 100% in some cases) in modern disk drives can occur after the causative processes have already completed execution. Hence, results obtained using power meters or direct energy measurement systems based solely on a benchmark's execution lifetime can drastically underestimate the benchmark application's storage energy demands.",J. Yan; C. K. Lonappan; A. Vajid; D. Singh; W. J. Kaiser,energy efficiency;energy measurement;Linux kernel;power consumption;I/O scheduler;secondary storage,2013,accurate and low overhead process level energy estimation for modern hard disk drives,1
421,Long-Term and Short-Term Energy Prediction using BIM Energy Simulations and Machine Learning Techniques,978-1-6654-6697-4,10.1109/ELECOM54934.2022.9965261,"2022 4th International Conference on Emerging Trends in Electrical, Electronic and Communications Engineering (ELECOM)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9965261,"Buildings consume the largest share of electricity in a country’s power grid. There is an ongoing challenge to reduce the energy consumption of buildings. One solution is efficient management of the different systems in the building such as HVAC systems to reduce energy consumption while maintaining the comfort level of people. For proper automation of the systems, there is a need to forecast the energy consumption of a building both in the long term and the short term. The Professor Sir Edouard Lim Fat Engineering Tower building was modelled on Autodesk Revit and energy simulations were performed on the model using Autodesk Green Building Studio. The simulation results were then compared to actual energy consumption. The same building was also used to test machine learning techniques; Gradient Boosting Machine, Support Vector Machine and Deep Neural Network ability to perform short-term energy prediction using data about energy consumption, weather and ambient environment of the building. It was observed that energy simulations overestimated the actual energy consumption by 27%, 29.6%, 59.7% and 60.6% for the months of October, November, December and January respectively. On the machine learning side, Gradient Boosting was observed to outperform SVM and DNN in training time, RMSE and Coefficient of Determination.",R. T. F. Ah King; B. Rajkumarsingh; Y. Gopee,Building Energy Modelling;Gradient Boosting Machine;Support Vector Machine;Deep Neural Network,2022,long term and short term energy prediction using bim energy simulations and machine learning techniques,1
424,How Is Energy Consumed in Smartphone Deep Learning Apps? Executing Locally vs. Remotely,978-1-7281-0962-6,10.1109/GLOBECOM38437.2019.9013647,2019 IEEE Global Communications Conference (GLOBECOM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9013647,"Applying deep learning to object detection provides the capability to accurately detect and classify complex objects in the real world. However, currently, few mobile applications use deep learning because such technology is computation- and energy-intensive. This paper, to the best of our knowledge, presents the first detailed experimental study of the smartphone's energy consumption and the detection latency of executing deep Convolutional Neural Networks (CNN) optimized object detec- tion, either locally on the smartphone or remotely on an edge server. We experiment with a variety of smartphones, obtaining different levels of computation capacities, in order to ensure that we are not profiling a specific device. Our detailed measurements refine the energy analysis of smartphones and reveal some interesting perspectives regarding the energy consumption of executing the deep CNN optimized object detection. We believe that these findings will guide the design of energy efficient processing pipeline of the CNN optimized object detection.",H. Wang; B. Kim; J. Xie; Z. Han,,2019,how is energy consumed in smartphone deep learning apps executing locally vs remotely,1
425,Deep Learning Based Modeling for Cutting Energy Consumed in CNC Turning Process,978-1-5386-6650-0,10.1109/SMC.2018.00244,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616240,"This paper studies a predictive modeling for cutting energy consumption in CNC turning process by using deep learning methods. An analysis of energy consumption in cutting period is firstly presented, based on which the impact factors of energy are clarified. Then the data collection platform and data pre-processing are introduced, followed by a brief review of Convolutional Neural Network (CNN), Stacked Auto-Encoder (SAE) and Deep Belief Network (DBN). These modeling methods are tested by k-fold cross-validation. The obtained results show that SAE is the most suitable method to model the relationship between process parameters, machining configuration and cutting energy.",Q. Xiao; C. Li; Y. Tang; Y. Du; Y. Kou,Deep learning;Energy consumption;CNC turning,2018,deep learning based modeling for cutting energy consumed in cnc turning process,1
426,A Low-Power Deep Neural Network Online Learning Processor for Real-Time Object Tracking Application,,10.1109/TCSI.2018.2880363,IEEE Transactions on Circuits and Systems I: Regular Papers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554277,"A deep neural network (DNN) online learning processor is proposed with high throughput and low power consumption to achieve real-time object tracking in mobile devices. Four key features enable a low-power DNN online learning. First, a proposed processor is designed with a unified core architecture and it achieves 1.33× higher throughput than the previous state-of-the-art DNN learning processor. Second, the new algorithms, binary feedback alignment (BFA), and dynamic fixed-point based run-length compression (RLC), are proposed and reduce power consumption through the reduction of external memory accesses (EMA). The BFA and dynamic fixed-point-based RLC reduce the EMA by 11.4% and 32.5%, respectively. Third, the new data feeding units, including an integral RLC (iRLC) decoder and a transpose RLC (tRLC) decoder, are co-designed to maximize throughput alongside the proposed algorithms. Finally, a dropout controller in this processor reduces redundant power consumption coming from the unified core and the data feeding architecture by the proposed dynamic clock-gating scheme. This enables the proposed processor to operate DNN online learning with 38.1% lower power consumption. Implemented with 65 nm CMOS technology, the 3.52 mm2 DNN online learning processor shows 126 mW power consumption and the processor achieves 30.4 frames-per-second throughput in the object tracking application.",D. Han; J. Lee; J. Lee; H. -J. Yoo,Deep neural network;online learning;object tracking;feedback alignment;run-length compression;dynamic fixed-point representation;dropout,2019,a low power deep neural network online learning processor for real time object tracking application,1
427,A study of hardware performance monitoring counter selection in power modeling of computing systems,978-1-4673-2154-9,10.1109/IGCC.2012.6322289,2012 International Green Computing Conference (IGCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322289,"Power management and energy savings in high-performance computing has become an increasingly important design constraint. The foundation of many power/energy saving methods is based on power consumption models, which commonly rely on hardware performance monitoring counters (PMCs). Various events are provided by processor manufacturers to be monitored using PMCs. PMC event selection has been mainly based on architectural intuitions. However, efficient use of PMCs requires a carefully selected set of events. Therefore, a comprehensive study of PMC events with regards to power modeling is needed to understand and enhance such power models. In this paper, we study the relationship of PMC events with power consumption in the context of single-PMC and multi-PMC power models. Our OpenMP applications are from NAS Parallel Benchmark (BT, CG, LU, and SP) running on an AMD machine. We present the single-PMC selection results for each of our test applications, as well as a unified list for all four applications. Unlike other work that do not consider PMCs as each others' covariates, we present a method to select the most correlated set of PMC events for a given application. Our method finds the desired set of events with 6 times less number of executions compared to a principal component analysis (PCA) method. In addition, we have investigated variability of measurement for correlation coefficients. The 95% confidence interval of power-PMC and PMC-PMC correlation coefficients falls within 1.6% and 2.3% of their measured values, respectively. Furthermore, we study the power and PMC trends in the context of time-series and show that power estimates can be enhanced more than common regression methods. We show that the ARMAX model, a time-series candidate for real-time power estimation, can estimate system power consumption with a mean absolute error (total signal) of 0.1-0.5% in our applications.",R. Zamani; A. Afsahi,performance monitoring counters;power modeling;energy saving,2012,a study of hardware performance monitoring counter selection in power modeling of computing systems,1
428,Lightweight Power Monitoring Framework for Virtualized Computing Environments,,10.1109/TC.2019.2936018,IEEE Transactions on Computers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811765,"The pervasive use of virtualization techniques in today's datacenters poses challenges in power monitoring since it is not possible to directly measure the power consumption of a virtual entity such as a virtual machine (VM) and a container. In this paper, we present cWatts++, a lightweight virtual power meter that enables accurate power usage measurement in virtualized computing environments such as VMs and containers of Cloud data centers. At the core of cWatts++ is its application-agnostic power model. To this end, we devise two power models (eventModel and raplModel) that are driven by CPU event counters and the Running Average Power Limit (RAPL) feature of modern Intel CPUs, respectively. While eventModel is more generic and, thus, applicable to a wide range of workloads, raplModel is particularly good for CPU-bound workloads. We have evaluated cWatts++ with its two power models in a real system using the PARSEC benchmark suite and our in-house benchmarks. Our evaluation study demonstrates that these power models have an average error of 4.55 and 1.25 percent, respectively, compared with actual power usage measurements of a real power meter, Cabac Power-Mate.",J. Phung; Y. C. Lee; A. Y. Zomaya,Energy efficiency;power monitoring;containers;power model;running average power limit;virtualization,2020,lightweight power monitoring framework for virtualized computing environments,1
429,Combining software and hardware monitoring for improved power and performance tuning,0-7695-1889-3,10.1109/INTERA.2003.1192356,"Seventh Workshop on Interaction Between Compilers and Computer Architectures, 2003. INTERACT-7 2003. Proceedings.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1192356,"By anticipating when resources will be idle, it is possible to reconfigure the hardware to reduce power consumption without significantly reducing performance. This requires predicting what the resource requirements will be for an application. In the past, researchers have taken one of two approaches: design hardware monitors that can measure recent performance, or profile the application to determine the most likely behavior for each block of code. This paper explores a third option which is to combine hardware monitoring with software profiling to achieve lower power utilization than either method alone. We demonstrate the potential for this approach in two ways. First, we compare hardware monitoring and software profiling of IPC for code blocks and show that they capture different information. By combining them, we can control issue width and ALU usage more effectively to save more power. Second, we show that anticipating stalls due to critical load misses in the L2 cache can enable fetch halting. Again, hardware monitoring and software profiling must be used together to effectively predict misses and criticality of loads.",E. Chi; A. M. Salem; R. I. Bahar; R. Weiss,,2003,combining software and hardware monitoring for improved power and performance tuning,1
430,WattsKit: Software-Defined Power Monitoring of Distributed Systems,978-1-5090-6611-7,10.1109/CCGRID.2017.27,"2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973738,"The design and the deployment of energy-efficient distributed systems is a challenging task, which requires software engineers to consider all the layers of a system, from hardware to software. In particular, monitoring and analyzing the power consumption of a distributed system spanning several-potentially heterogeneous-nodes becomes particularly tedious when aiming at a finer granularity than observing the power consumption of hosting nodes. While the state-of-the-art in software-defined power meters fails to deliver adaptive solutions to offer such service-level perspective and to cope with the diversity of hardware CPU architectures, this paper proposes to automatically learn the power models of the nodes supporting a distributed system, and then to use these inferred power models to better understand how the power consumption of the system's processes is distributed across nodes at runtime. Our solution, named WattsKit, offers a modular toolkit to build software-defined power meters ""à la carte"", thus dealing with the diversity of user and hardware requirements. Beyond the demonstrated capability of covering a wide diversity of CPU architectures with high accuracy, we illustrate the benefits of adopting software-defined power meters to analyze the power consumption of complex layered and distributed systems. In particular, we illustrate the capability of our approach to monitor the power consumption of a system composed of Docker Swarm, Weave, Elasticsearch, and Apache Zookeeper. Thanks to WattsKit, developers and administrators are now able to identify potential power leaks in their software infrastructure.",M. Colmant; P. Felber; R. Rouvoy; L. Seinturier,,2017,wattskit software defined power monitoring of distributed systems,1
431,Virtual Machine Power Accounting with Shapley Value,978-1-5386-1792-2,10.1109/ICDCS.2017.235,2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7980105,"The ever-increasing power consumption of datacenters has eaten up a large portion of their profit. One possible solution is to charge datacenter users for their actual power usage. However, it poses a great technical challenge as the power of VMs co-existing in a physical machine cannot be measured directly. It is thus critical to develop a fair method to disaggregate the power of a physical machine to individual VMs. We tackle the above challenge by modeling the power disaggregation problem as a cooperative game and propose non-deterministic Shapley value to discover the fair power share of VMs (in the sense of satisfying four desired axiomatic principles), while compensating the negative impact of VM power variation. We demonstrate that the results from existing power model-based solution can deviate from the ""ground truth"" by 25.22% ~46.15%. And compared with the exact Shapley value, our non-deterministic Shapley value can achieve less than 5% error for 90% of the time.",W. Jiang; F. Liu; G. Tang; K. Wu; H. Jin,Virtual Machine;Power Accounting;Power Disaggregation;Fairness;Shapley Value,2017,virtual machine power accounting with shapley value,1
432,Dynamic Virtual Machine migration algorithms using enhanced energy consumption model for green cloud data centers,978-1-4799-5313-4,10.1109/HPCSim.2014.6903785,2014 International Conference on High Performance Computing & Simulation (HPCS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903785,"Cloud data centers consume an enormous amount of energy. Virtual Machine (VM) migration technology can be applied to reduce energy consumption by consolidating VMs onto the minimal number of servers and turn idle servers into power-saving modes. While most existing energy models consider mainly computing energy, an enhanced energy consumption model is formulated, which includes energy consumption for computation, for servers to switch from standby to active modes, and for communication during VM migrations. Next, two new dynamic VM migration algorithms are proposed. They apply a local regression method to predict potentially over-utilized servers, and the 0-1 knapsack dynamic programming to find the best-fit combination of VMs for migration. The time complexity of these algorithms is analyzed, which indicates that they are highly scalable. Performance is evaluated and compared with existing algorithms. The two new heuristics have significantly reduced the number of VM migration, the number of rebooted servers, and energy consumption. Furthermore, one of them has achieved the least overall SLA violations. We believe that the new energy formulation and the two new heuristics contribute significantly towards achieving green cloud computing.",J. Huang; K. Wu; M. Moh,cloud computing;communication energy;energy formulation;energy efficiency;SLA;switching energy;virtual machine placement,2014,dynamic virtual machine migration algorithms using enhanced energy consumption model for green cloud data centers,1
433,Intra-Balance Virtual Machine Placement for Effective Reduction in Energy Consumption and SLA Violation,,10.1109/ACCESS.2019.2920010,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726286,"Cloud computing has emerged as one of the most important technological revolutions globally. However, the rapid growth of cloud computing has imposed a massive financial burden and resulted in environmental side effects due to excessive energy consumption. The high power consumption is not only attributed to the size of data centers but also to the ineptitude of resource usage. Most of the extant research has focused on reducing power consumption by an aggressive VM consolidation, which leads to the violation of the service level agreement (SLA). Furthermore, the unbalanced resource consumption exacerbates the unavailable wasted resources that are referred to as unavailable resource fragmentation. In this paper, we propose the use of a balanced resources consumption algorithm called BRC-IBMMT in order to enhance the efficiency of resource consumption while achieving an acceptable balance between conflicting correlation objectives of power consumption as well as SLA violation. The extensive simulation results of different types of workload validate and lend credence to the significance of the proposed method in reducing power consumption and SLA violation of the cloud data center.",A. -M. Ammar; J. Luo; Z. Tang; O. Wajdy,Balanced resource placement;VM consolidation;energy consumption;cloud computing,2019,intra balance virtual machine placement for effective reduction in energy consumption and sla violation,1
434,Dynamic Virtual Machine Consolidation Algorithm Based on Balancing Energy Consumption and Quality of Service,,10.1109/ACCESS.2022.3194514,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843955,"Virtual machine consolidation (VMC) is an effective way to solve the problems of high power consumption and low utilization in cloud data centers. However, large-scale virtual machine migrations (VMMs) can result in additional workloads, service-level agreement violations (SLAVs), and considerable energy consumption (EC). Existing studies have made great progress in this respect, but the following problems remain: first, the potential overload of the physical host is not considered in the load detection of the physical host; second, the resource-demand scaling of physical hosts is not considered during virtual machine (VM) placement, which results in the lack of accuracy in selecting suitable hosts. In view of the above problems, this study firstly constructs a virtual resource consolidation model based on green energy conservation (GEC-VRCM), which defines the specific process and related attributes of VMC, which is beneficial to improve the consolidation efficiency of virtual resources. Second, based on this model, we propose a dynamic virtual machine consolidation algorithm based on balancing energy consumption and quality of service (EQ-DVMCA) to achieve efficient consolidation of virtual resources. Finally, experiments show that, compared with the selected 12 benchmark algorithms and two advanced VMC algorithms, EQ-DVMCA not only reduces the number of VMMs and EC, but also maintains a high level of Quality of Service (QoS) and achieves a balance between EC and QoS.",W. Li; Q. Fan; W. Cui; F. Dang; X. Zhang; C. Dai,Virtual machine consolidation;energy consumption;virtual machine migration;quality of service,2022,dynamic virtual machine consolidation algorithm based on balancing energy consumption and quality of service,1
435,DeepPM: Transformer-based Power and Performance Prediction for Energy-Aware Software,978-3-9819263-6-1,10.23919/DATE54114.2022.9774589,"2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774589,"Many system-level management and optimization techniques need accurate estimates of power consumption and performance. Earlier research has proposed many high-level/source-level estimation modeling works, particularly for basic blocks. However, most of them still need to execute the target software at least once on a fine-grained simulator or real hardware to extract required features. This paper proposes a performance/power prediction framework, called Deep Power Meter (DeepPM), which estimates them accurately only using the compiled binary. Inspired by the deep learning techniques in natural language processing, we convert the program instructions in the form of vectors and predict the average power and performance of basic blocks based on a transformer model. In addition, unlike existing works based on a Long Short-Term Memory (LSTM) model structure, which only works for basic blocks with a small number of instructions, DeepPM provides highly accurate results for long basic blocks, which takes the majority of the execution time for actual application runs. In our evaluation conducted with SPEC2006 benchmark suite, we show that DeepPM can provide accurate prediction for performance and power consumption with 10.2% and 12.3% error, respectively. DeepPM also outperforms the LSTM-based model by up to 67.2% and 34.9% error for performance and power, respectively.",J. S. Shim; B. Han; Y. Kim; J. Kim,Power and performance modeling;system resource prediction;transformer,2022,deeppm transformer based power and performance prediction for energy aware software,1
437,A regression analysis into Nepali ICT's energy consumption and its implications,978-1-4673-6744-8,10.1109/SKIMA.2015.7400034,"2015 9th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400034,"This work is a preliminary investigation into the energy demand of the Nepali Information and Communications Technology (ICT) sector. We formulate a logistic growth model for telecommunication users' diffusion and then present a ridge regression based model to analyse the contribution of the ICT sector in the national energy consumption scenario with a specific focus on the telecommunication sector. Although our analysis leaves out some important dimensions due to lack of publicly available data, the stable ridge regression model can easily be expanded to accommodate new dimensions (indicators). The results show that even with the most lenient assumptions regarding the behaviour of the ICT sector, it is a significant consumer of energy at the national level. As Nepal is suffering from the chronic problem of energy crisis, further development of the ICT sector will surely raise new energy related challenges. The understanding of the context of energy use is as important as the technology that delivers energy savings. We therefore recommend that an energy audit of the ICT sector along with large scale studies on the context of technology use has to be done simultaneously. These have to precede the wholesale changes portrayed by the dreams of the ICT policy, e-governance master plan and the like.",N. Regmi; S. B. Pandey,Nepali ICT;energy demand;energy efficiency;ridge regression,2015,a regression analysis into nepali ict s energy consumption and its implications,1
438,Virtual Machine packing algorithms for lower power consumption,978-1-4673-4510-1,10.1109/CloudCom.2012.6427493,4th IEEE International Conference on Cloud Computing Technology and Science Proceedings,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6427493,"Virtual Machine(VM)-based flexible capacity management is an effective scheme to reduce total power consumption in the data centers. However, there remain the following issues, trade-off between power-saving and user experience, decision on VM packing plans within a feasible calculation time, and collision avoidance for multiple VM live migration processes. In order to resolve these issues, we propose two VM packing algorithms, a matching-based (MBA) and a greedy-type heuristic (GREEDY). MBA enables to decide an optimal plan in polynomial time, while GREEDY is an aggressive packing approach faster than MBA. We investigate the basic performance and the feasibility of proposed algorithms under both artificial and realistic simulation scenarios, respectively. The basic performance experiments show that the algorithms reduce total power consumption by between 18% and 50%, and MBA makes suitable VM packing plans within a feasible calculation time. The feasibility experiments show that the proposed algorithms are feasible to make packing plans for an actual supercomputer, and GREEDY has the advantage in power consumption, but MBA shows the better performance in user experience.",S. Takahashi; H. Nakada; A. Takefusa; T. Kudoh; M. Shigeno; A. Yoshise,,2012,virtual machine packing algorithms for lower power consumption,1
439,Short-Term Energy Consumption Forecasting at the Edge: A Federated Learning Approach,,10.1109/ACCESS.2021.3094089,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469923,"Residential short-term energy consumption forecasting plays an essential role in modern decentralized power systems. The rise of innovative prediction methods able to handle the high volatility of users' electrical load has posed the basis to accomplish this task. However these methods, which mostly rely on Artificial Neural Networks, require that a huge amount of users' fine-grained sensitive consumption data are centrally collected to train a generalized forecasting model, with implications on privacy and scalability. This paper proposes an innovative architecture specifically designed to overcome this need. By exploiting Federated Learning and Edge Computing capabilities, many Long Short-Term Memory (LSTM) models are locally trained by different users based on their own historical energy consumption samples. Such models are then aggregated by a specific-purpose node to build a generalized model that is re-distributed for improved forecasting at the edge. For better forecasting, our proposed local training procedure takes as input relevant features related to calendar (i.e., hour, weekday and average consumption of previous days) and weather conditions (i.e., clustered apparent temperature), and the architecture can group users according to consumption similarities (using K-means) or socioeconomic affinities. We thoroughly evaluate the approach through simulations, showing that it can lead to similar forecasting performance than a state-of-the-art centralized solution in terms of Root Mean Square Error (RMSE), but with up to an order of magnitude lower training time and up to 50 times less exchanged data when samples are recorded at finer granularity than one hour. Nonetheless, it keeps sensitive data local and therefore guarantees users' privacy.",M. Savi; F. Olivadese,Energy consumption forecasting;federated learning;edge computing;LSTM,2021,short term energy consumption forecasting at the edge a federated learning approach,1
440,Scheduling Algorithms for Federated Learning With Minimal Energy Consumption,,10.1109/TPDS.2023.3240833,IEEE Transactions on Parallel and Distributed Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032558,"Federated Learning (FL) has opened the opportunity for collaboratively training machine learning models on heterogeneous mobile or Edge devices while keeping local data private. With an increase in its adoption, a growing concern is related to its economic and environmental cost (as is also the case for other machine learning techniques). Unfortunately, little work has been done to optimize its energy consumption or emissions of carbon dioxide or equivalents, as energy minimization is usually left as a secondary objective. In this paper, we investigate the problem of minimizing the energy consumption of FL training on heterogeneous devices by controlling the workload distribution. We model this as the Minimal Cost FL Schedule problem, a total cost minimization problem with identical, independent, and atomic tasks that have to be assigned to heterogeneous resources with arbitrary cost functions. We propose a pseudo-polynomial optimal solution to the problem based on the previously unexplored Multiple-Choice Minimum-Cost Maximal Knapsack Packing Problem. We also provide four algorithms for scenarios where cost functions are monotonically increasing and follow the same behavior. These solutions are likewise applicable on the minimization of other kinds of costs, and in other one-dimensional data partition problems.",L. L. Pilla,Dynamic programming;energy conservation;federated learning;knapsack problems;machine learning;optimization;parallel processing;scheduling,2023,scheduling algorithms for federated learning with minimal energy consumption,1
441,Data center power management for regulation service using neural network-based power prediction,978-1-5090-5404-6,10.1109/ISQED.2017.7918343,2017 18th International Symposium on Quality Electronic Design (ISQED),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918343,"The underlying infrastructure of cloud computing relies on data centers monitored and maintained by the cloud service providers. Data centers usually incur enormous power consumption and are expected to have a significant impact on the local power grid due to dramatically increasing power consumption and fluctuation. In order to mitigate such fluctuation and balance the power demand and supply in the power grid in real time, the regulation service (RS) opportunity has been provided, which offers the electricity consumers to dynamically adjust their power consumption and reduce their electricity cost. Data centers can be active RS participants due to their flexibility and controllability in load dispatching and scheduling temporally (within a server) and spatially (among multiple servers). In order for the data centers to provide better RS, prediction on the data center power consumption becomes essential. In this work, we first adopt artificial neural network (ANN)-based method and long short term memory (LSTM) neural network-based method for the prediction of future data center power consumption. Based on the prediction results, we formulate a novel optimal power management problem of data center to minimize the total cost. Experimental results demonstrate that the total cost of the data center can be reduced by up to 20.6% compared with the baseline systems.",N. Liu; X. Lin; Y. Wang,Data center;power management;smart grid;regulation service;artificial neural network;long short term memory network,2017,data center power management for regulation service using neural network based power prediction,1
442,Fine-Grained Energy Consumption Model of Servers Based on Task Characteristics in Cloud Data Center,,10.1109/ACCESS.2017.2732458,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022680,"In this paper, we address the problem of accurately modeling the cloud data center energy consumption. As minimizing energy consumption has become a crucial issue for the efficient operation and management of cloud data centers, an energy consumption model plays an important role in cloud datacenter energy management and control. Moreover, such model is essential for guiding energy-aware algorithms, such as resource provisioning policies and virtual machine migration policies. To this end, we propose a holistic cloud data center energy consumption model that is based on the principal component analysis and regression methods. Unlike the exiting approaches that focus on single system component in the datacenter, the proposed approach takes into account the energy consumption of the processing unit, memory, disk, and network interface card as well as the application characteristics. The proposed approach is validated through extensive experiments with the SPECpower benchmark. The experimental results show that the proposed energy consumption model achieves more than 95% prediction accuracy.",Z. Zhou; J. H. Abawajy; F. Li; Z. Hu; M. U. Chowdhury; A. Alelaiwi; K. Li,Energy consumption model;energy consumption contribution;task characteristic;principal component analysis,2018,fine grained energy consumption model of servers based on task characteristics in cloud data center,1
443,A Measurement-Based Characterization of the Energy Consumption in Data Center Servers,,10.1109/JSAC.2015.2481198,IEEE Journal on Selected Areas in Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274318,"In this work, we present an exhaustive empirical characterization of the power requirements of multiple components of data center servers. To do so, we devise different experiments to stress these components, taking into account the multiple available frequencies and the fact that we are working with multicore servers. In these experiments, we measure energy consumption of server components and identify their optimal operational points. Our study proves that the curve defining the minimal CPU power utilization, as a function of the load in active cycles per second, is neither concave nor purely convex. Instead, it definitively shows a super-linear dependence on the load. Similarly, we present results on how to improve the efficiency of network cards and disks. Finally, we validate the accuracy of the model derived from our characterization by comparing the real energy consumed by two Hadoop applications-PageRank and WordCount-with the estimation from our model, obtaining errors below 4.1% on average.",J. A. Aroca; A. Chatzipapas; A. F. Anta; V. Mancuso,Cloud Computing;CPU;data centers;disk;DVFS;energy efficiency;energy measurements;network;Cloud computing;CPU;data centers;disk;DVFS;energy efficiency;energy measurements;network,2015,a measurement based characterization of the energy consumption in data center servers,1
444,Balancing peer and server energy consumption in large peer-to-peer file distribution systems,978-1-4244-9519-1,10.1109/GreenCom.2011.6082511,2011 IEEE Online Conference on Green Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082511,"Network induced energy consumption is a significant fraction of all ICT energy consumption. This paper investigates the most energy efficient way to distribute a file to a large number of recipients. It is shown that using peer-to-peer and naively minimizing the transfer time results in energy consumption that is an order of magnitude larger than simply distributing directly from a server, but that with careful management peer-to-peer systems can reduce the server's cost without increasing overall energy consumption.",L. L. H. Andrew; A. Sucevic; T. T. T. Nguyen,,2011,balancing peer and server energy consumption in large peer to peer file distribution systems,1
445,Efficient allocation of VMs in servers of data center to reduce energy consumption,978-1-5386-1115-9,10.1109/CloudTech.2017.8284743,2017 3rd International Conference of Cloud Computing Technologies and Applications (CloudTech),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284743,"Cloud computing has become over the last years an important paradigm in the computing landscape. Its principle is to provide decentralized services and allows client to consume resources on a pay-as you-go model. The growing demand for this type of service brings providers service clouds to increase the size of their infrastructure to the point that the energy consumption and associated costs become very important. This cloud infrastructure comprises several components such as servers, cooling systems, etc. In this paper, we present three policies (FDT, DDT and DRT) each one with two phases. The selection phase which is based on physical resources thresholds (one or two physical resources) and the allocation phase to place the migrated VMs on hosts. We simulate the proposed approaches on CloudSim simulator and compare them with two existed approaches. Our proposal allows reducing energy consumption, number of migrations, the number of SLA violations and thus minimizing the CO2 emission.",D. Dad; G. Belalem,Data center;Cloud Computing;Energy consumption;Virtualization;Migration;Service Level Agreement;Green Cloud Computing;Lower Threshold;Upper Threshold;CPU Utilization;RAM Capacity,2017,efficient allocation of vms in servers of data center to reduce energy consumption,1
447,Energy Consumption Characteriation of Heterogeneous Servers,978-0-7695-5058-9,10.1109/ChinaGrid.2013.20,2013 8th ChinaGrid Annual Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6623860,"Energy and cooling cost is becoming the main cost of data centers. Many studies focused on how to schedule job and migrate Virtual Machine between servers to save energy. An accurate energy consumption model is the basic of energy management. Most past studies show that energy consumption has linear relation with resource utilization. We found that different servers have different energy consumption characters even with same CPU and similar workloads. Most past models were only validated on several servers. These models did not reflect the characters of different kinds of servers in a heterogeneous data center. In this paper, we verified the accuracy of the linear model on 392 servers. The data come from the results of SPECPower_ssj2008 benchmark. The benchmark was released in 2007. There are 392 servers from 26 vendors were tested in the past six years. These servers represent most common used servers in heterogeneous data centers. We use several methods to validate the accuracy of the linear model. The results show the model does not work well for all kinds of servers. We also analyze the trend of energy consumption of last six years.",X. Zhang; J. Lu; X. Qin,Energy consumption model;Heterogeneous data center;Resource Utilization,2013,energy consumption characteriation of heterogeneous servers,1
448,Data Center Server Energy Consumption Optimization Algorithm,978-1-5386-7890-9,10.1109/MED.2018.8442890,2018 26th Mediterranean Conference on Control and Automation (MED),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8442890,"Understanding, modelling and reducing data center power consumption is a complicated undertaking. Individual data centers are highly complex systems, with a number of interacting mechanical, electrical and computational subsystems. The paper presents an optimization algorithm which reduces the energy consumed by the informational systems by assign virtual machines to physical servers. This action is achieved taking into account the different degrees of freedom of the used resources. The considered problem is formulated as a mixed integer linear programming problem where all transfer functions, constraint functions and objective function are expressed under a linear form.",I. Stamatescu; S. Ploix; I. Făgărăşan; G. Stamatescu,,2018,data center server energy consumption optimization algorithm,1
449,Joint Optimization of Energy Consumption and Latency Based on DRL: An Edge Server Activation and Task Scheduling Scheme in IIoT,978-1-6654-5085-0,10.1109/WCSP55476.2022.10039283,2022 14th International Conference on Wireless Communications and Signal Processing (WCSP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039283,"Edge computing has been proposed as a promising solution to alleviate the computation intensive requirement of Industrial Internet of Things (IIoT) scenarios. In edge computing based network, task latency and energy consumption are two key metrics, while the tradeoff of them is of great importance on impacting the overall performance of the system. In this paper, we formulate a joint optimization problem to minimize the weighted summation of latency and energy consumption in the network where the task scheduling and server dormant mode are both taken into account. To solve this problem, we designed a Deep Reinforcement Learning (DRL) based algorithm considering both the number of active edge servers and the task scheduling scheme per time slot. Simulation results show that our algorithm has advantages compared with other algorithms and reduces the overall cost of the system.",R. Ma; X. Zhou; H. Zhang; D. Yuan,IIoT;Computation offloading;Server mode selection;DRL,2022,joint optimization of energy consumption and latency based on drl an edge server activation and task scheduling scheme in iiot,1
450,A basic-block power annotation approach for fast and accurate embedded software power estimation,978-1-4799-0524-9,10.1109/VLSI-SoC.2013.6673261,2013 IFIP/IEEE 21st International Conference on Very Large Scale Integration (VLSI-SoC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6673261,"We propose a new power simulation technique that effectively considers dynamic program execution behaviors such as cache hit/miss or branch predicted/mis-predicted and achieves fast and accurate power estimation results. Traditionally, accurate software power estimation relies on slower fine-grained simulations while faster coarse-grained simulations often lead to inaccurate estimation results. We pre-characterize detailed circuit power consumption, pipeline and branch effects of each basic block for accuracy and then apply efficient instruction-set simulators to compute total software power consumption. The experimental result shows that our approach achieves over 200 MIPS performance with a less than 3% error rate.",C. -M. Lee; C. -K. Chen; R. -S. Tsay,,2013,a basic block power annotation approach for fast and accurate embedded software power estimation,1
452,Research on the Transformation Path Of Energy Consumption Based On Artificial Intelligence,978-1-6654-5637-1,10.1109/ICKECS56523.2022.10060481,2022 International Conference on Knowledge Engineering and Communication Systems (ICKES),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060481,"Under the background of the “dual carbon” strategy and rapid response, Shanxi Province formulated the “dual carbon work implementation opinions” and the carbon peak implementation plan, actively promoted the energy transformation and upgrading, and explored the transformation path. Based on the theory of low-carbon economy, it is found that the total energy consumption is still in a growing state, and it is necessary to control the total energy consumption and improve the energy efficiency to realize the transformation of energy consumption. On the one hand, the energy consumption transformation of Shanxi Province should improve the utilization efficiency of fossil energy, reduce the carbon footprint in industrial production, and use low-carbon technology and recycling services to reduce the environmental pollution of fossil energy. On the other hand, we should reduce the use of fossil energy, increase the proportion of electric energy in terminal consumption, and replace high carbon energy with clean energy and low carbon energy.",H. Guo; G. Yan; Z. Li; P. Qin; M. Li,carbon-perk;carbon-neutrality;energy transition;roadmap analysis;artificial intelligence;grey prediction,2022,research on the transformation path of energy consumption based on artificial intelligence,1
453,Virtual Machine Consolidation with Multiple Usage Prediction for Energy-Efficient Cloud Data Centers,,10.1109/TSC.2017.2648791,IEEE Transactions on Services Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807360,"Virtual machine consolidation aims at reducing the number of active physical servers in a data center so as to decrease the total power consumption. In this context, most of the existing solutions rely on aggressive virtual machine migration, thus resulting in unnecessary overhead and energy wastage. Besides, virtual machine consolidation should take into account multiple resource types at the same time, since CPU is not the only critical resource in cloud data centers. In fact, also memory and network bandwidth can become a bottleneck, possibly causing violations in the service level agreement. This article presents a virtual machine consolidation algorithm with multiple usage prediction (VMCUP-M) to improve the energy efficiency of cloud data centers. In this context, multiple usage refers to both resource types and the horizon employed to predict future utilization. Our algorithm is executed during the virtual machine consolidation process to estimate the long-term utilization of multiple resource types based on the local history of the considered servers. The joint use of current and predicted resource utilization allows for a reliable characterization of overloaded and underloaded servers, thereby reducing both the load and the power consumption after consolidation. We evaluate our solution through simulations on both synthetic and real-world workloads. The obtained results show that consolidation with multiple usage prediction reduces the number of migrations and the power consumption of the servers while complying with the service level agreement.",N. T. Hieu; M. D. Francesco; A. Ylä-Jääski,Virtual machine consolidation;virtual machine migration;multiple resource prediction;cloud computing;data centers,2020,virtual machine consolidation with multiple usage prediction for energy efficient cloud data centers,1
454,Virtual Machine Consolidation with Usage Prediction for Energy-Efficient Cloud Data Centers,978-1-4673-7287-9,10.1109/CLOUD.2015.104,2015 IEEE 8th International Conference on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214114,"Virtual machine consolidation aims at reducing the number of active physical servers in a data center, with the goal to reduce the total power consumption. In this context, most of the existing solutions rely on aggressive virtual machine migration, thus resulting in unnecessary overhead and energy wastage. This article presents a virtual machine consolidation algorithm with usage prediction (VMCUP) for improving the energy efficiency of cloud data centers. Our algorithm is executed during the virtual machine consolidation process to estimate the short-term future CPU utilization based on the local history of the considered servers. The joint use of current and predicted CPU utilization metrics allows a reliable characterization of overloaded and under loaded servers, thereby reducing both the load and the power consumption after consolidation. We evaluate our proposed solution through simulations on real workloads from the Planet Lab and the Google Cluster Data datasets. In comparison with the state of the art, the obtained results show that consolidation with usage prediction reduces the total migrations and the power consumption of the servers while complying with the service level agreement.",N. T. Hieu; M. Di Francesco; A. Ylä-Jääski,Virtual machine consolidation;virtual machine migration;resource prediction;cloud computing;data centers,2015,virtual machine consolidation with usage prediction for energy efficient cloud data centers,1
458,"Improving the Energy Efficiency of Real-time DNN Object Detection via Compression, Transfer Learning, and Scale Prediction",978-1-6654-5408-7,10.1109/NAS55553.2022.9925528,"2022 IEEE International Conference on Networking, Architecture and Storage (NAS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925528,"In recent years, computational accessibility has enabled the use of Deep Neural Network (DNN) for computer vision applications on devices with limited computational resources. We focus on the real-time object detection algorithms deployed on UAV -friendly devices. The hardware deployed on UAV must be lightweight and thus limited in processing power, memory, and storage capacity. Lightweight modeling architecture does not suffice for high-recall reconnaissance applications. In this paper, we propose to reduce power consumption of YOLOv5 DNN architecture. We decided to use compressed convolutional technique, transfer learning, backbone shrinkage, and scale prediction to reduce the number of learnable parameters from the YOLOv5model. Our approach reduced the size of the model significantly and lowered the power consumption in turn. GPU memory and the Billion Floating-Point Operations Per Second (GFLOPS) for the YOLOv5model will keep the performance measure of the model as the baseline state-of-the-art. The best resulting model has a 63.86% mean average precision (mAP) and a GFLOPS of 97.7 on “DIOR”, an overhead imagery data set. The proposed approach has lowered GPU memory consumption of the model by 34% and lowered the energy consumption by 10 Watts compared to the baseline model.",D. Biswas; M. M. M. Rahman; Z. Zong; J. Tešić,Energy Efficiency;YOLOv5;real-time object detection;Mobile Computing;UAV,2022,improving the energy efficiency of real time dnn object detection via compression transfer learning and scale prediction,1
459,Reducing disk power consumption in servers with DRPM,,10.1109/MC.2003.1250884,Computer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1250884,"Although effective techniques exist for tackling disk power for laptops and workstations, applying them in a server environment presents a considerable challenge, especially under stringent performance requirements. Using a dynamic rotations per minute approach to speed control in server disk arrays can provide significant savings in I/O system power consumption without lessening performance.",S. Gurumurthi; A. Sivasubramaniam; M. Kandemir; H. Franke,,2003,reducing disk power consumption in servers with drpm,1
460,Analysis of the Power Consumption of a Multimedia Server under Different DVFS Policies,978-1-4673-2892-0,10.1109/CLOUD.2012.31,2012 IEEE Fifth International Conference on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6253579,"Dynamic voltage and frequency scaling (DVFS) has been a useful power management strategy in embedded systems, mobile devices, and wireless sensor networks. Recently, it has also been proposed for servers and data centers in conjunction with service consolidation and optimal resource-pool sizing. In this paper, we experimentally investigate the scope and usefulness of DVFS in a server environment. We set up a multimedia server which will be used in two different scenarios. In the first scenario, the server will host requests to download video files of known and available formats. In the second scenario, videos of unavailable formats can be accepted; in which case the server employs a trans coder to convert between AVI, MPEG and SLV formats before the videos are downloaded. The workload we generate has a uniform arrival rate and an exponentially distributed video size. We use four dynamic scaling policies which are widely used with existing mainstream Linux operating systems. Our observation is that while the gain of DVFS is clear in the first scenario (in which a predominantly IO-bound application is used), its use in the second scenario is rather counterproductive.",W. Dargie,Energy consumption of servers;dynamic voltage and frequency scaling;power consumption analysis;dynamic power management;energy consumption,2012,analysis of the power consumption of a multimedia server under different dvfs policies,1
461,Analysis of the Power and Hardware Resource Consumption of Servers under Different Load Balancing Policies,978-1-4673-2892-0,10.1109/CLOUD.2012.30,2012 IEEE Fifth International Conference on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6253578,"Most Internet applications employ some kind of load balancing policies in a cluster setting to achieve reliable service provision as well as to deal with a resource bottleneck. However, these policies may not ensure the utilization of \textit{all} of the hardware resources in a server equally efficiently. This paper experimentally investigates the relationship between the power consumption and resource utilization of a multimedia server cluster when different load balancing policies are used to distribute a workload. Our observations are the following: (1) A bottleneck on a single hardware resource can lead to a significant amount of underutilization of the entire system. (2) A ten times increment in the network bandwidth of the entire cluster can double the throughput of individual servers. The associated increment in power consumption of the individual servers is 1.2% only. (3) For TCP-based applications, session information is more useful than other types of status information to utilize power more efficiently. (4) The use of dynamic frequency scaling does not affect the overall throughput of IO-bound applications but reduces the power consumption of the servers; but this reduction is only 12% of the overall power consumption. More power can be saved by avoiding a resource bottleneck or through service consolidation.",W. Dargie; A. Schill,Cluster computing;load balancing;power consumption;resource utilization;service consolidation,2012,analysis of the power and hardware resource consumption of servers under different load balancing policies,1
463,Can We Speculate Running Application With Server Power Consumption Trace?,,10.1109/TCYB.2017.2703941,IEEE Transactions on Cybernetics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7933202,"In this paper, we propose to detect the running applications in a server by classifying the observed power consumption series for the purpose of data center energy consumption monitoring and analysis. Time series classification problem has been extensively studied with various distance measurements developed; also recently the deep learning-based sequence models have been proved to be promising. In this paper, we propose a novel distance measurement and build a time series classification algorithm hybridizing nearest neighbor and long short term memory (LSTM) neural network. More specifically, first we propose a new distance measurement termed as local time warping (LTW), which utilizes a user-specified index set for local warping, and is designed to be noncommutative and nondynamic programming. Second, we hybridize the 1-nearest neighbor (1NN)-LTW and LSTM together. In particular, we combine the prediction probability vector of 1NN-LTW and LSTM to determine the label of the test cases. Finally, using the power consumption data from a real data center, we show that the proposed LTW can improve the classification accuracy of dynamic time warping (DTW) from about 84% to 90%. Our experimental results prove that the proposed LTW is competitive on our data set compared with existed DTW variants and its noncommutative feature is indeed beneficial. We also test a linear version of LTW and find out that it can perform similar to state-of-the-art DTW-based method while it runs as fast as the linear runtime lower bound methods like LB_Keogh for our problem. With the hybrid algorithm, for the power series classification task we achieve an accuracy up to about 93%. Our research can inspire more studies on time series distance measurement and the hybrid of the deep learning models with other traditional models.",Y. Li; H. Hu; Y. Wen; J. Zhang,Long short term memory (LSTM);recurrent neural network (RNN);time series classification;time warping,2018,can we speculate running application with server power consumption trace,1
465,Power Consumption Model of a Server to Perform Communication Type Application Processes on Virtual Machines,978-1-4673-8315-8,10.1109/BWCCA.2015.67,"2015 10th International Conference on Broadband and Wireless Computing, Communication and Applications (BWCCA)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424836,"High performance, scalable, and fault-tolerant application services can be provided by balancing processing load among virtual machines to perform application processes in server cluster systems. On the other hand, a large amount of electric energy is consumed in a server cluster system since multiple virtual machines are performed on multiple servers which consume electric energy to perform application processes. In this paper, we consider communication type application processes to be performed on virtual machines. A communication type application process transmits a large volume of data to a client like downloading. In order to design and implement an energy-efficient server cluster system, the transmission model and power consumption model of a server to perform communication type application processes on multiple virtual machines have to be defined. In this paper, we newly define the transmission model and power consumption model of a server to perform communication type application processes on virtual machines.",T. Enokido; M. Takizawa,Green computing;nergy-efficient server cluster systems;Virtual machines;Power consumption models;Communication type application processes,2015,power consumption model of a server to perform communication type application processes on virtual machines,1
466,Reducing Event Latency and Power Consumption in Mobile Devices by Using a Kernel-Level Display Server,,10.1109/TMC.2018.2857809,IEEE Transactions on Mobile Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8413093,"Mobile devices differ from desktop computers in that they have a limited power source, a battery, and they tend to spend more CPU time on the graphical user interface (GUI). These two facts force us to consider different software approaches in the mobile device kernel that can conserve battery life and reduce latency, which is the duration of time between the inception of an event and the reaction to the event. One area to consider is a software package called the display server. The display server is middleware that handles all GUI activities between an application and the operating system, such as event handling and drawing to the screen. In both desktop and mobile devices, the display server is located in the application layer. However, the kernel layer contains most of the information needed for handling events and drawing graphics, which forces the application-level display server to make a series of system calls in order to coordinate events and to draw graphics. These calls interrupt the CPU which can increase both latency and power consumption, and also require the kernel to maintain event queues that duplicate event queues in the display server. A further drawback of placing the display server in the application layer is that the display server contains most of the information required to efficiently schedule the application and this information is not communicated to existing kernels, meaning that GUI-oriented applications are scheduled less efficiently than they might be, which further increases power consumption. We propose moving the display server to the kernel layer, so that it has direct access to many of the event queues and hardware rendering systems without having to interrupt the CPU. This adjustment has allowed us to implement two power saving strategies, discussed in other papers, that streamline the event system and improve the scheduler. The combination of these two techniques reduces power consumption by an average of 30 percent and latency by an average of 17 ms. Even without the implementation of these power saving techniques, the KDS increases battery life by 4.35 percent or on average about 10 extra minutes for a typical mobile phone or 30 extra minutes for a typical tablet computer. It also reduces latency by 1.1 milliseconds.",S. Marz; B. V. Zanden; W. Gao,Graphical user interfaces;kernel display server;event handling,2019,reducing event latency and power consumption in mobile devices by using a kernel level display server,1
467,Modelling and analysing the power consumption of idle servers,978-3-901882-46-3,,2012 Sustainable Internet and ICT for Sustainability (SustainIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6388007,"To the best of our knowledge, there have been no efforts in devising power consumption prediction models for an idle server, where this latter contributes approximately 66% of the maximum power drain. In this paper, we propose power consumption prediction models for idle servers by taking into account their constituent components such as processor, memory, hard disk, fan and power supply unit. To this end, we identify the relevant energy-related attributes of each component necessary for the idle power consumption predictions. Furthermore, based on the proposed models, we provide an in-depth analysis by considering several types of servers (e.g. rackable, blade, etc) having different hardware characteristics and energy-aware mechanisms.",R. Basmadjian; F. Niedermeier; H. De Meer,modelling;idle power consumption;servers;data centres,2012,modelling and analysing the power consumption of idle servers,1
468,Emulating the Power Consumption Behavior of Server Workloads Using CPU Performance Counters,978-1-5386-2764-8,10.1109/MASCOTS.2017.17,"2017 IEEE 25th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8107442,"The accurate measurement of a server's power consumption when running realistic workloads enables characterization of its energy efficiency and helps to make better provisioning and workload placement decisions. Information on the energy efficiency of a server for a given target workload can greatly influence such decisions and thus the final energy efficiency of a cluster or data center. However, measuring energy efficiency and power consumption of server applications has become challenging as applications are often distributed or require work intensive configuration, setup, and specialized load drivers for reproducible testing. As a result, it may be not feasible to perform tests using the actual workload that is to be deployed. We introduce an approach to create small-scale workloads that emulate the power consumption-relevant behavior of an application by deliberately triggering specific power relevant performance counter events. These workloads can then be easily deployed on a target server for fast and efficient power characterization. We validate the proposed approach by approximating the power consumption behavior of different workloads at multiple load levels. We show that our approach is capable of producing small-scale workloads that reflect the power consumption behavior of their reference applications over multiple load levels with a minimum error of less than 1%.",N. Schmitt; J. von Kistowski; S. Kounev,Energy Efficiency;Power;Benchmarking;CPU;Performance Counter;Workload;NFV;SERT;PET,2017,emulating the power consumption behavior of server workloads using cpu performance counters,1
469,Optimizing cooling and server power consumption,978-1-4577-1481-8,10.1109/ICCP.2011.6047916,2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6047916,"This paper proposes new solution strategies for a challenging optimization problem, called Cooling-aware Workload Placement Problem, that looks for a workload placement that optimizes the overall data center power consumption given by the sum of the server power consumption and of the computer room air conditioner power consumption. We formulate CWPP as a Mixed Integer Non Linear Problem using a cross-interference matrix that links the workload placement to the cold air temperature. Since state-of-the-art Mixed Integer Non Linear solvers can solve to optimality only the smallest instances, we devised two heuristics to obtain good feasible solutions: (i) a heuristic algorithm based on an integer linear relaxation of the problem, and (ii) a Variable Neighborhood Search algorithm. Both heuristic algorithms are evaluated against the best lower bounds obtained with a Mixed Integer Non Linear solver. Computational results show that both heuristics provide solutions that have a small percentage gap from the optimal solutions.",P. Cremonesi; A. Sansottera; S. Gualandi,data center;cooling aware consolidation;CFD,2011,optimizing cooling and server power consumption,1
470,Towards Power Consumption Modeling for Servers at Scale,978-0-7695-5697-0,10.1109/UCC.2015.50,2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7431425,"As of 2010 data centers use 1.5% of global electricity production and this is expected to keep growing [1]. There is a need for a near real-time power consumption modeling/monitoring system that could be used at scale within a Software Defined Data Center (SDDC). The power consumption models and information they provide can then be used to make better decisions for data center orchestration, e.g., whether to migrate virtual machines to reduce power consumption. We propose a scalable system that would 1) create initial power consumption models, as needed, for data center components, and 2) could be continually refined while the components are in use. The models will be used for the near real-time monitoring of power consumption, as well as predicting power consumption before and after potential orchestration decisions. The first step towards this goal of whole data center power modeling and prediction is to be able to predict the power consumption of one server effectively, based on high level utilization statistics from that server. In this paper we present a novel method for modeling whole system power consumption for a server, under varying random levels of CPU utilization, with a scalable random forest based model, that utilizes statistics available at the data center management level.",T. W. Harton; C. Walker; M. O'Sullivan,power consumption models;power consumption estimation;server power consumption;processor power consumption;virtual machines;random forests;energy-efficiency,2015,towards power consumption modeling for servers at scale,1
471,Redundant Execution Algorithm for Reducing Total Power Consumption of Server Clusters by Differentiating the Starting Time of Processes,978-1-4799-2510-0,10.1109/NBiS.2013.6,2013 16th International Conference on Network-Based Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685370,"In order to realize reliable and energy-aware server clusters, application processes have to be reliably and energy-efficiently performed in presence of server faults. In one way, an application process can be redundantly performed on multiple servers. In the improved redundant power consumption laxity-based (IRPCLB) algorithm which is proposed in our previous studies, since each application process is redundantly performed on more than one server, the reliability and availability of the cluster increase. However, the larger amount of electric power is consumed than non-redundant execution. In the IRPCLB algorithm, once a process terminates on a server, meaningless redundant processes on the other servers are forced to terminate in order to reduce the total power consumption. In this paper, we newly discuss the extended IRPCLB (EIRPCLB) algorithm to furthermore reduce the total power consumption of a server cluster. Here, in addition to forcing meaningless processes to terminate, each server is made reduce the consumption of computation resource to perform a redundant process by differentiating starting time of each redundant process. We evaluate the EIRPCLB algorithm in terms of total power consumption of a cluster and the average response time and number of servers to perform each process compared with the IRPCLB algorithm.",T. Enokido; A. Aikebaier; M. Takizawa,Energy-aware system;Green computing;Fault tolerance;Replication;Power consumption model;Server cluster,2013,redundant execution algorithm for reducing total power consumption of server clusters by differentiating the starting time of processes,1
472,Dynamic Clusters of Servers to Reduce Total Power Consumption,978-0-7695-4992-7,10.1109/CISIS.2013.23,"2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6603871,"Electric power consumed by servers has to be reduced in order to realize green societies. A server has to be selected in a cluster of servers so that the total power consumption can be reduced. We consider computation (CP) and storage (ST) types of application processes performed on servers in this paper, where CPU and storage drives are mainly used, respectively. In our previous studies, the energy-aware (EA) algorithm is discussed to select a server in a cluster of servers for each request so that the total power consumption of the servers can be reduced. However, an idle server consumes electric power even if no process is performed. In this paper, we discuss a dynamic energy-aware, heterogeneous (DEA-H) cluster. Here, only servers required to perform request processes but no idle servers are included in each cluster. In a DEA-H cluster, servers are selected in a server pool if the traffic increases and idle servers leave for the server pool if the traffic decreases. A server for each request is selected in a heterogeneous DEA cluster so that the total power consumption of servers can be reduced. We evaluate the DEA algorithm on a heterogeneous cluster (DEA-H) in terms of the total power consumption and average execution time.",T. Inoue; A. Aikebaier; T. Enokido; M. Takizawa,power consumption model;dynamic energy-aware (DEA) cluster;heterogeneous cluster;storage and computation based power consumption (SCBPC) model;storage and computation based processing (SCBP) model,2013,dynamic clusters of servers to reduce total power consumption,1
474,Per-task Energy Accounting in Computing Systems,,10.1109/L-CA.2013.24,IEEE Computer Architecture Letters,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6998104,We present for the first time the concept of per-task energy accounting (PTEA) and relate it to per-task energy metering (PTEM). We show the benefits of supporting both in future computing systems. Using the shared last-level cache (LLC) as an example: (1) We illustrate the complexities in providing PTEM and PTEA; (2) we present an idealized PTEM model and an accurate and low-cost implementation of it; and (3) we introduce a hardware mechanism to provide accurate PTEA in the cache.,Q. Liu; V. Jimenez; M. Moreto; J. Abella; F. J. Cazorla; M. Valero,,2014,per task energy accounting in computing systems,1
477,Edge-assisted Attention-based Federated Learning for Multi-Step EVSE-enabled Prosumer Energy Demand Prediction,978-1-6654-6268-6,10.1109/ICOIN56518.2023.10048987,2023 International Conference on Information Networking (ICOIN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048987,"Energy demand prediction for the prosumer building, which is capable of playing the role of an electric vehicle (EV) charging station (EVCS) with installed EV supply equipment (EVSE), is currently of paramount importance for ameliorating energy efficiency and mitigating energy wastage. However, the time-dependency characteristics between successive energy demand data, the stochasticity of the number of EVs, and the randomness of the energy demand data of EVs and prosumers cause challenges in accurately predicting energy demand. Therefore, it is urgent to do energy demand prediction for prosumers. Nevertheless, energy demand prediction through centralized training is an extravagant process. This is because transferring energy data to a centralized machine for prediction will not only cause network bandwidth and energy consumption, but also cause communication delay. Thus, in this paper, an edge-assisted attention-based federated learning (FL) algorithm is proposed for multi-step energy demand prediction of prosumers, where the goal is to minimize the average forecasting loss. Specifically, since the attention mechanism has the advantage of detecting important features from inputs, to capture the temporal features and improve the prediction accuracy, the long short-term memory-utilized sequence to sequence model with the attention mechanism (LSTM-Seq2Seq-att) in FL setting is employed in each local edge server to train the global model collaboratively. The evaluation results clarify the effectiveness of the proposed method.",L. Zou; C. M. Thwal; S. -B. Park; C. S. Hong,Multi-step energy demand prediction;EVSE-enabled prosumer;attention mechanism;LSTM-based Seq2Seq model;federated learning,2023,edge assisted attention based federated learning for multi step evse enabled prosumer energy demand prediction,1
478,Monthly energy consumption forecast: A deep learning approach,978-1-5090-6182-2,10.1109/IJCNN.2017.7966398,2017 International Joint Conference on Neural Networks (IJCNN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966398,"Every year, energy consumption grows world widely. Therefore, power companies need to investigate models to better forecast and plan the energy use. One approach to address this problem is the estimation of energy consumption in the customer level. Energy consumption forecasting problem is a time series regression task. It consists of predicting the energy consumption for the next month given a finite history of a customer. Machine learning techniques have shown promising results in a variety of problems including time series and regression problems. Part of these promising results are attributed to deep neural networks. Although investigated in other domains, deep architectures have not been used to address the energy consumption prediction problem. In this work, we propose a system to predict monthly energy consumption using deep learning techniques. Three deep learning models were studied: Deep Fully Connected, Convolutional and Long Short-Term Memory Neural Networks. Due to the sensitivity of these models to the input range, normalization techniques were also investigated. The proposed system was validated with real data of almost a million customers (resulting in over 9 million samples). Results showed that our system can predict monthly energy consumption with an absolute error of 31.83 kWh and a relative error of 17.29%.",R. F. Berriel; A. T. Lopes; A. Rodrigues; F. M. Varejão; T. Oliveira-Santos,,2017,monthly energy consumption forecast a deep learning approach,1
480,Using Deep Learning and Knowledge Transfer to Disaggregate Energy Consumption,978-1-6654-6611-0,10.1109/ICWAPR54887.2021.9736149,2021 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736149,"NILM or Non-Intrusive Load Monitoring is the task of disag-gregating the energy consumed by a building in the energy con-sumed by its constituent appliances. With the increase in energy demand, governments started searching for solutions to reduce energy wastage on the demand side, and the deployment of smart meters was one of them. Their purpose was to give users information about the aggregated energy consumed in a given household at any given time. Since the smart meters collect the aggregated readings, the interest in NILM grew, as researchers could focus their attention on the disaggregation algorithm. Regarding the disaggre-gation algorithms, deep learning models have shown remarkable results surpassing the previous state-of-the-art models. With this in mind, this paper proposes three different deep learning models: a convolutional neural network with residual blocks, a recurrent neural network, and a multilayer perceptron that uses discrete wavelet transform as features. These models are trained on the UK-DALE and REFIT datasets and compared with the state-of-the-art models present in NILMTK-Contrib. The models are evaluated on their generalization and transfer learning ability, as these are two critical factors for a broad NILM deployment. Our models have shown competitive results compared to the state-of-the-art, achieving lower errors than 2 out of the three models used, getting closer to the performance of the third. The main advantage of our models is the ability to do real-time disaggregation, while the best model has a 30 min delay.",R. Teixeira; M. Antunes; D. Gomes,NILM;NIALM;CNN;RNN;MLP;Transfer Learning,2021,using deep learning and knowledge transfer to disaggregate energy consumption,1
482,Machine Learning with Sensitivity Analysis to Determine Key Factors Contributing to Energy Consumption in Cloud Data Centers,978-1-5090-3951-7,10.1109/ICCCRI.2016.24,2016 International Conference on Cloud Computing Research and Innovations (ICCCRI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600185,"Machine learning (ML) approach to modeling and predicting real-world dynamic system behaviours has received widespread research interest. While ML capability in approximating any nonlinear or complex system is promising, it is often a black-box approach, which lacks the physical meanings of the actual system structure and its parameters, as well as their impacts on the system. This paper establishes a model to provide explanation on how system parameters affect its output(s), as such knowledge would lead to potential useful, interesting and novel information. The paper builds on our previous work in ML, and also combines an evolutionary artificial neural networks with sensitivity analysis to extract and validate key factors affecting the cloud data center energy performance. This provides an opportunity for software analysts to design and develop energy-aware applications and for Hadoop administrator to optimize the Hadoop infrastructure by having Big Data partitioned in bigger chunks and shortening the time to complete MapReduce jobs.",Y. W. Foo; C. Goh; Y. Li,machine learning;artificial neural networks;sensitivity analysis;cloud computing;energy efficiency;genetic algorithm,2016,machine learning with sensitivity analysis to determine key factors contributing to energy consumption in cloud data centers,1
484,Energy Consumption Optimization for CSMA/CA Protocol Employing Machine Learning,978-1-7281-5207-3,10.1109/VTC2020-Spring48590.2020.9128450,2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128450,"The algorithms commonly used for energy control in systems with Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) protocol involve optimization functions with considerable computational complexity and need rigorous control of the test environment. These restrictions create a gap among design, theoretical analysis, real-time processing of network devices and the dependence on human support for parameters setting. In this paper, we propose a novel approach to reach energy saving based on machine learning which considers the input and output of a power consumption control algorithm in CSMA networks, taking into account multiple physical (PHY) layer variables. The results show that the proposed approach obtained a better performance regarding processing time, computational cost and self-adaptation of the parameters currently defined by greedy search energy control algorithms.",P. F. C. Barbosa; B. A. d. Silva; C. Zanchettin; R. M. de Moraes,CSMA;energy control;machine learning,2020,energy consumption optimization for csma ca protocol employing machine learning,1
486,Reduced Energy Consumption in Cloud Data Center Using Machine Learning Algorithm Load Balancing,979-8-3503-9826-7,10.1109/IC3I56241.2022.10072497,2022 5th International Conference on Contemporary Computing and Informatics (IC3I),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10072497,"Cloud computing has made it possible for users to spend only for the volume of a service that they consume rather than purchasing a predetermined amount. Cloud computing and virtualization, when coupled, make it possible to access and share information technology resources whenever and wherever they are needed. When it comes to cloud computing, a dependable data centre infrastructure is unrivalled by anything else. In the context of this discussion, the term “infrastructure” refers to the collection of computers, wiring, and power sources that together serve as a host for an organization’s information and store it. When it comes to cloud computing, great overall performance has always been the most important factor, but this has resulted in an increase in the amount of energy that is required. The major objective is to achieve as low a level of power consumption as possible while maintaining as high a level of performance and quality of service as possible inside the carrier network. Our strategy calls for an in-depth study of the patterns of energy consumption exhibited by cloud-based systems. Authors perform an analysis of energy use and show how suitable optimization methods based on our models of energy consumption can assist cloud data centres in saving even more electricity. These methods are informed by our analysis of energy consumption. Because of capsule optimization, this system is able to generate more accurate projections of the costs that will be incurred in the future. The accuracy rate for the forecasting component is 97%.",T. Suneetha; S. Singh; B. Neeraja; S. W. Tufa; N. Thiyagarajan; A. K. Rao,Cloud computing;Machine Learning;Power consumption prediction;and Virtual Machine.,2022,reduced energy consumption in cloud data center using machine learning algorithm load balancing,1
488,Detection and Analysis of Digital Display Board Energy Consumption using IoT and Machine Learning Techniques,978-1-6654-6047-7,10.1109/STCR55312.2022.10009610,"2022 Smart Technologies, Communication and Robotics (STCR)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009610,"Nowadays Digital Display Boards (DDB) are used to post information in a variety of locations, including public spaces, hospitals, general stores, institutions, and colleges. Earlier, for displaying large data, the message needs to be changed for every instance. As of now digital displays are more preferred to static and attract the attention of viewers. The microcontroller present in the DDB write the information to the showing device. DDBs are connecting to the controller to continually scroll the message on the screen. The research article proposes the DDB system in office environments. The proposed system is fully designed and analyzed by IoT and Machine learning Techniques. The device will identify the DDB usage rate and reduce the wastage of DDB energy in unoccupied places and also forecasting future energy usage requirement. The proposed work applies a prediction system to detect and analyze the one Month energy consumption of DDB in the office environment and evaluates the existing model with the ARIMA algorithm for generating time-series based prediction models. To find out the precision of the proposed system, DDB along with sensor devices were installed in the office environment, which consist of current sensors, microcontrollers with cloud database connectivity. The set of data has been obtained from the database being utilized to evaluate and test the proposed models. according to the results of the prediction and analysis proposed DDB outperformed the ARIMA Model, with good accuracy. Based on the proposed method, the predicted accuracy value is 97.8% and R-squared for the model is 0.89. The Proposed DDB Energy Consumption system helps to monitor and detect the energy usage in office environments.",R. Ramesh; A. Bazila Banu,Digital Display Boards;office environments;unoccupied places;prediction models,2022,detection and analysis of digital display board energy consumption using iot and machine learning techniques,1
490,Sustainability of Machine Learning Models: An Energy Consumption Centric Evaluation,979-8-3503-4536-0,10.1109/ECCE57851.2023.10101532,"2023 International Conference on Electrical, Computer and Communication Engineering (ECCE)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10101532,"Machine Learning (ML) algorithms have become prevalent in today's digital world. However, training, testing and deployment of ML models consume a lot of energy, particularly when the datasets are huge. Consequently, this would have a direct and adverse impact on the environment due to its Scope 2 emissions. Thus, it will be beneficial we explore the environment impact of ICT usage within an organisation. Additionally, it is vital to adopt energy consumption as a metric for the evaluation of existing and future ML models. Our research goal is to evaluate the energy consumption of a set of widely used ML classifier algorithms- Logistic Regression, Gaussian Naive Bayes (GNB), Support vector, K Neighbors (KNN), Decision Tree (DT), Random Forest, Multi-Layer Perceptron, AdaBoost, Gradient Boosting, Light GBM and CatBoost classifiers. The findings will provide evidence-based recommendation for sustainable and energy-efficient ML algorithms. The experiment findings shows that GNB classifer consumes only 63 J/S energy, which is the lowest among all models whereas widely used KNN and DT classifiers consume 3 to 10 times more than the rest.",M. S. Islam; S. N. Zisad; A. -L. Kor; M. H. Hasan,Machine learning;Energy consumption;Classification models;Green AI;Carbon footprint;Microsoft Joulemeter,2023,sustainability of machine learning models an energy consumption centric evaluation,1
491,A method for reduction of energy consumption in Wireless Sensor Network with using Neural Networks,978-89-88678-55-8,,2011 6th International Conference on Computer Sciences and Convergence Information Technology (ICCIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6316662,"The main concern in Wireless Sensor Networks is how to handle with their limited energy resources. The performance of Wireless Sensor Networks strongly depends on their lifetime. As a result, Dynamic Power Management approaches with the purpose of reduction of energy consumption in sensor nodes, after deployment and designing of the network. Recently, there have been a strong interest to use intelligent tools especially Neural Networks in energy efficient approaches of Wireless Sensor Networks, due to their simple parallel distributed computation, distributed storage, data robustness, autoclassification of sensor nodes and sensor reading. This paper presents a new centralized adaptive Energy Based Clustering protocol through the application of Self organizing map neural networks (called EBC-S) which can cluster sensor nodes, based on multi parameters; energy level and coordinates of sensor nodes. We applied some maximum energy nodes as weights of SOM map units; so that the nodes with higher energy attract the nearest nodes with lower energy levels. Therefore, formed clusters may not necessarily contain adjacent nodes. The new algorithm enables us to form energy balanced clusters and equally distribute energy consumption. Simulation results and comparison with previous protocols(LEACH and LEA2C) prove that our new algorithm is able to extend the lifetime of the network.",M. A. A. Kashani; H. Ziafat,Energy Based Clustering;Self Organizing Map Neural Networks;Wireless Sensor Networks,2011,a method for reduction of energy consumption in wireless sensor network with using neural networks,1
492,Energy Consumption of Neural Networks on NVIDIA Edge Boards: an Empirical Model,978-3-903176-49-2,10.23919/WiOpt56218.2022.9930584,"2022 20th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930584,"Recently, there has been a trend of shifting the execution of deep learning inference tasks toward the edge of the network, closer to the user, to reduce latency and preserve data privacy. At the same time, growing interest is being devoted to the energetic sustainability of machine learning. At the intersection of these trends, in this paper we focus on the energetic characterization of machine learning at the edge, which is attracting increasing attention. Unfortunately, calculating the energy consumption of a given neural network during inference is complicated by the heterogeneity of the possible underlying hardware implementation. In this work, we aim at profiling the energetic consumption of inference tasks for some modern edge nodes by deriving simple but accurate models. To this end, we performed a large number of experiments to collect the energy consumption of fully connected and convolutional layers on two well-known edge boards by NVIDIA, namely, Jetson TX2 and Xavier. From these experimental measurements, we have then distilled a simple and practical model that can provide an estimate of the energy consumption of a certain inference task on these edge computers. We believe that this model can prove useful in many contexts as, for instance, to guide the search for efficient neural network architectures, as a heuristic in neural network pruning, to find energy-efficient offloading strategies in a split computing context, or to evaluate and compare the energy performance of deep neural network architectures.",S. Lahmer; A. Khoshsirat; M. Rossi; A. Zanella,Energy consumption;Deep Neural Networks;Edge Computing;Inference,2022,energy consumption of neural networks on nvidia edge boards an empirical model,1
493,PEFS: AI-Driven Prediction Based Energy-Aware Fault-Tolerant Scheduling Scheme for Cloud Data Center,,10.1109/TSUSC.2020.3015559,IEEE Transactions on Sustainable Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165232,"Cloud data centers (CDCs) have become increasingly popular and widespread in recent years with the growing popularity of cloud computing and high-performance computing. Due to the multi-step computation of data streams and heterogeneous task dependencies, task failure frequently occurs, resulting in poor user experience and additional energy consumption. To reduce task execution failure as well as energy consumption, we propose a novel AI-driven energy-aware proactive fault-tolerant scheduling scheme for CDCs in this paper. First, a prediction model based on the machine learning approach is trained to classify the arriving tasks into “failure-prone tasks” and “non-failure-prone tasks” according to the predicted failure rate. Then, two efficient scheduling mechanisms are proposed to allocate two types of tasks to the most appropriate hosts in a CDC. The vector reconstruction method is developed to construct super tasks from failure-prone tasks and separately schedule these super tasks and non-failure-prone tasks to the most suitable physical host. All the tasks are scheduled in an earliest-deadline-first manner. Our evaluation results show that the proposed scheme can intelligently predict task failure and achieves better fault tolerance and reduces total energy consumption better than the existing schemes.",A. Marahatta; Q. Xin; C. Chi; F. Zhang; Z. Liu,Cloud computing;cloud data center;scheduling;fault-tolerance;energy-efficiency;task failure;prediction;deep neural network,2021,pefs ai driven prediction based energy aware fault tolerant scheduling scheme for cloud data center,1
495,Joint Optimization of Energy Consumption and Latency in Mobile Edge Computing for Internet of Things,,10.1109/JIOT.2018.2869226,IEEE Internet of Things Journal,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457190,"With wide adoption of Internet of Things (IoT) across the world, the IoT devices are facing more and more intensive computation task nowadays. However, the IoT devices are usually limited by their computing capability and battery lifetime. Mobile edge computing provides new opportunities for developments of IoT, since edge computing servers which are close to devices can provide more powerful computing resources. The IoT devices can offload the intensive computing tasks to edge computing servers, while saving their own computing resources and reducing energy consumption. However, the benefits come at the cost of higher latency, mainly due to additional transmission time, and it may be unacceptable for many IoT applications. In this paper, we try to find a tradeoff between the energy consumption and latency, in order to satisfy user demands of various IoT applications. We formalize the problem into a constrained multiobjective optimization problem and find the optimal solutions by a modified fast and elitist nondominated sorting genetic algorithm (NSGA-II). To improve the performance of the algorithm, we propose a novel problem-specific encoding scheme and genetic operators in the proposed modified NSGA-II. We also conduct extensive simulation experiments to evaluate the proposed algorithm and its sensitivity under certain major parameters. The experimental results show that the proposed algorithm can find a large number of optimal solutions to adjust the corresponding offloading decision according to the real-world situation.",L. Cui; C. Xu; S. Yang; J. Z. Huang; J. Li; X. Wang; Z. Ming; N. Lu,Computation offloading;constrained multiobjective optimization (CMOP);Internet of Things (IoT);mobile edge computing (MEC),2019,joint optimization of energy consumption and latency in mobile edge computing for internet of things,1
496,Profiling Energy Consumption of VMs for Green Cloud Computing,978-1-4673-0006-3,10.1109/DASC.2011.131,"2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118905,"The Green Clouds project in the Netherlands investigates a system-level approach towards greening High-Performance Computing (HPC) infrastructures and clouds. In this paper we present our initial results in profiling virtual machines with respect to three power metrics, i.e. power, power efficiency and energy, under different high performance computing workloads. We built a linear power model that represents the behavior of a single work node and includes the contribution from individual components, i.e. CPU, memory and HDD, to the total power consumption of a single work node. Our results could be part of a power characterization module integrated into clusters' monitoring systems, future Green Clouds energy-savvy scheduler would use this monitoring system to support system-level optimization.",Q. Chen; P. Grosso; K. v. d. Veldt; C. d. Laat; R. Hofman; H. Bal,Green Clouds;Energy-efficient computing;Power benchmark;Virtualization;Cloud Computing;Kernel-based Virtual Machine (KVM),2011,profiling energy consumption of vms for green cloud computing,1
497,A hybrid neural network model and encoding technique for enhanced classification of energy consumption data,978-1-4577-1002-5,10.1109/PES.2011.6039050,2011 IEEE Power and Energy Society General Meeting,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6039050,"Total losses in transmission and distribution (T&D) of electrical energy including nontechnical losses (NTL) are huge and are affecting the good interest of utility company and its customers. In this context, importance of customer load profile evaluation for detection of illegal consumers is explained in this paper. Classification of the customers based on load profile evaluation using SVMLIB requires us to choose training function and related parameters. Selecting these parameters would consume a lot of time and is not suggestible evaluation of real time electricity consumption patterns, as, the suspicious profiles are to be predicted instantly. In light of this issue, this paper implements a neural network (NN) model and suggests a hierarchical model for enhanced estimation of the classification efficiency, if that data was classified using support vector machines (SVM). In addition, this paper proposes an encoding technique that can identify illegal consumers with better efficiency and faster classification of data.",S. S. S. R. Depuru; L. Wang; V. Devabhaktuni; P. Nelapati,Data classification;electricity theft;encoding;neural networks;power consumption patterns and support vector machines,2011,a hybrid neural network model and encoding technique for enhanced classification of energy consumption data,1
501,An energy consumption model and analysis tool for Cloud computing environments,978-1-4673-1832-7,10.1109/GREENS.2012.6224255,2012 First International Workshop on Green and Sustainable Software (GREENS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6224255,"Cloud computing delivers computing as a utility to users worldwide. A consequence of this model is that cloud data centres have high deployment and operational costs, as well as significant carbon footprints for the environment. We need to develop Green Cloud Computing (GCC) solutions that reduce these deployment and operational costs and thus save energy and reduce adverse environmental impacts. In order to achieve this objective, a thorough understanding of the energy consumption patterns in complex Cloud environments is needed. We present a new energy consumption model and associated analysis tool for Cloud computing environments. We measure energy consumption in Cloud environments based on different runtime tasks. Empirical analysis of the correlation of energy consumption and Cloud data and computational tasks, as well as system performance, will be investigated based on our energy consumption model and analysis tool. Our research results can be integrated into Cloud systems to monitor energy consumption and support static or dynamic system-level optimisation.",F. Chen; J. -G. Schneider; Y. Yang; J. Grundy; Q. He,green computing;Cloud computing;energy consumption;performance analysis,2012,an energy consumption model and analysis tool for cloud computing environments,1
502,Reducing Energy Consumption With Cost Budget Using Available Budget Preassignment in Heterogeneous Cloud Computing Systems,,10.1109/ACCESS.2018.2825648,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335291,"Energy consumption and cost are the important factors in executing applications in grid or cloud computing systems, because they directly affect resource consumption and economic benefits. This paper solves the problem of reducing energy consumption of a cost budgeted directed acyclic graph (DAG) application in heterogeneous computing systems. The state-of-the-art work has studied the cost budgeted scheduling for a DAG application in the heterogeneous computing systems by proposing the budget levelbased preassignment method; however, this paper is merely to reduce the schedule length without involving energy consumption, and its preassignment method is still pessimistic although it improves the existing method. In this paper, we first propose an available budget preassignment method to further improve it. We then introduce the available budget preassignment method to reduce the energy consumption. We propose minimizing energy consumption using the available budget preassignment (MECABP) algorithm based on the two steps. Experiments on three types of DAG applications with different parallelism degrees confirm the effectiveness of the proposed MECABP algorithm compared with existing algorithms.",Y. Chen; G. Xie; R. Li,Cost budget;budget preassignment;heterogeneous cloud computing systems,2018,reducing energy consumption with cost budget using available budget preassignment in heterogeneous cloud computing systems,1
503,Modeling of energy consumption and effluent quality using density peaks-based adaptive fuzzy neural network,,10.1109/JAS.2018.7511168,IEEE/CAA Journal of Automatica Sinica,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405350,"Modeling of energy consumption (EC) and effluent quality (EQ) are very essential problems that need to be solved for the multiobjective optimal control in the wastewater treatment process (WWTP). To address this issue, a density peaks-based adaptive fuzzy neural network (DP-AFNN) is proposed in this study. To obtain suitable fuzzy rules, a DP-based clustering method is applied to fit the cluster centers to process nonlinearity. The parameters of the extracted fuzzy rules are fine-tuned based on the improved Levenberg-Marquardt algorithm during the training process. Furthermore, the analysis of convergence is performed to guarantee the successful application of the DPAFNN. Finally, the proposed DP-AFNN is utilized to develop the models of EC and EQ in the WWTP. The experimental results show that the proposed DP-AFNN can achieve fast convergence speed and high prediction accuracy in comparison with some existing methods.",J. Qiao; H. Zhou,,2018,modeling of energy consumption and effluent quality using density peaks based adaptive fuzzy neural network,1
504,An Analysis Framework for Investigating the Trade-Offs between System Performance and Energy Consumption in a Heterogeneous Computing Environment,978-0-7695-4979-8,10.1109/IPDPSW.2013.142,"2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6650868,"Rising costs of energy consumption and an ongoing effort for increases in computing performance are leading to a significant need for energy-efficient computing. Before systems such as supercomputers, servers, and datacenters can begin operating in an energy-efficient manner, the energy consumption and performance characteristics of the system must be analyzed. In this paper, we provide an analysis framework that will allow a system administrator to investigate the tradeoffs between system energy consumption and utility earned by a system (as a measure of system performance). We model these trade-offs as a bi-objective resource allocation problem. We use a popular multi-objective genetic algorithm to construct Pareto fronts to illustrate how different resource allocations can cause a system to consume significantly different amounts of energy and earn different amounts of utility. We demonstrate our analysis framework using real data collected from online benchmarks, and further provide a method to create larger data sets that exhibit similar heterogeneity characteristics to real data sets. This analysis framework can provide system administrators with insight to make intelligent scheduling decisions based on the energy and utility needs of their systems.",R. Friese; B. Khemka; A. A. Maciejewski; H. J. Siegel; G. A. Koenig; S. Powers; M. Hilton; J. Rambharos; G. Okonski; S. W. Poole,bi-objective optimization;energy-aware computing;heterogeneous computing;resource allocation;data creation,2013,an analysis framework for investigating the trade offs between system performance and energy consumption in a heterogeneous computing environment,1
506,Towards Energy Consumption Measurement in a Cloud Computing Wireless Testbed,978-1-4577-1667-6,10.1109/NCCA.2011.22,2011 First International Symposium on Network Cloud Computing and Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123444,"The evolution of the Next Generation Networks, especially the wireless broadband access technologies such as Long Term Evolution (LTE) and Worldwide Interoperability for Microwave Access (WiMAX), have increased the number of ""all-IP"" networks across the world. The enhanced capabilities of these access networks has spearheaded the cloud computing paradigm, where the end-users aim at having the services accessible anytime and anywhere. The services availability is also related with the end-user device, where one of the major constraints is the battery lifetime. Therefore, it is necessary to assess and minimize the energy consumed by the end-user devices, given its significance for the user perceived quality of the cloud computing services. In this paper, an empirical methodology to measure network interfaces energy consumption is proposed. By employing this methodology, an experimental evaluation of energy consumption in three different cloud computing access scenarios (including WiMAX) were performed. The empirical results obtained show the impact of accurate network interface states management and application network level design in the energy consumption. Additionally, the achieved outcomes can be used in further software-based models to optimized energy consumption, and increase the Quality of Experience (QoE) perceived by the end-users.",V. Bernardo; M. Curado; T. Staub; T. Braun,Cloud Computing;Energy;Measurement;Testbed;Wireless;4G networks,2011,towards energy consumption measurement in a cloud computing wireless testbed,1
507,Characterizing system level energy consumption in mobile computing platforms,0-7803-9305-8,10.1109/WIRLES.2005.1549573,"2005 International Conference on Wireless Networks, Communications and Mobile Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1549573,"This paper approaches energy consumption characterization in mobile computing platforms by assessing energy consumption of ""basic"" application-level tasks, such as processing, input/output (disk, display, etc.), communication (transmission and reception over the network), and combinations thereof. Besides providing information on the energy consumption behavior of typical tasks performed by mobile computers, task-level energy characterization enables power management decisions, such as whether, in a distributed computation, the task at hand can be executed locally or should be assigned to a different machine (given the machine's current energy budget, the energy cost of executing the task locally, and the cost of sending the required information over the network to a peer). We employ a task-level energy consumption characterization benchmark that accounts for basic tasks such as processing, disk access (including reads and writes), terminal usage, and communication (transmission and reception). Using the benchmark, we perform an energy characterization case study using the Dell Latitude C600 running two versions of the Linux operating system.",C. B. Margi; K. Obraczka; R. Manduchi,,2005,characterizing system level energy consumption in mobile computing platforms,1
508,Minimizing computing-plus-communication energy consumptions in virtualized networked data centers,978-1-5090-0679-3,10.1109/ISCC.2016.7543890,2016 IEEE Symposium on Computers and Communication (ISCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7543890,"In this paper, we propose a dynamic resource provisioning scheduler to maximize the application throughput and minimize the computing-plus-communication energy consumption in virtualized networked data centers. The goal is to maximize the energy-efficiency, while meeting hard QoS requirements on processing delay. The resulting optimal resource scheduler is adaptive, and jointly performs: i) admission control of the input traffic offered by the cloud provider; ii) adaptive balanced control and dispatching of the admitted traffic; iii) dynamic reconfiguration and consolidation of the Dynamic Voltage and Frequency Scaling (DVFS)-enabled virtual machines instantiated onto the virtualized data center. The proposed scheduler can manage changes of the workload without requiring server estimation and prediction of its future trend. Furthermore, it takes into account the most advanced mechanisms for power reduction in servers, such as DVFS and reduced power states. Performance of the proposed scheduler is numerically tested and compared against the corresponding ones of some state-of-the-art schedulers, under both synthetically generated and measured real-world workload traces. The results confirm the delay-vs.-energy good performance of the proposed scheduler.",M. Shojafar; C. Canali; R. Lancellotti; E. Baccarelli,Virtualized Data Centers;Cloud Computing;Resource Allocation;Energy-efficiency;Lyapunov Optimization,2016,minimizing computing plus communication energy consumptions in virtualized networked data centers,1
509,Performance and Energy Consumption of Lossless Compression/Decompression Utilities on Mobile Computing Platforms,978-0-7695-5102-9,10.1109/MASCOTS.2013.33,"2013 IEEE 21st International Symposium on Modelling, Analysis and Simulation of Computer and Telecommunication Systems",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6730768,"Data compression and decompression utilities can be critical in increasing communication throughput, reducing communication latencies, achieving energy-efficient communication, and making effective use of available storage. This paper experimentally evaluates several such utilities for multiple compression levels on systems that represent current mobile platforms. We characterize each utility in terms of its compression ratio, compression and decompression through-put, and energy efficiency. We consider different use cases that are typical for modern mobile environments. We find a wide variety of energy costs associated with data compression and decompression and provide practical guidelines for selecting the most energy efficient configurations for each use case. The best performing configurations provide 6-fold and 4-fold improvements in energy efficiency for compressed uploads and downloads over WLAN, respectively, when compared to uncompressed data transfers.",A. Milenkovic; A. Dzhagaryan; M. Burtscher,mobile computing;measurement techniques;data compression;energy-aware systems,2013,performance and energy consumption of lossless compression decompression utilities on mobile computing platforms,1
510,GPU Energy Consumption Optimization With a Global-Based Neural Network Method,,10.1109/ACCESS.2019.2915380,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708170,"With the widespread use of smart technologies, graphics processing unit (GPU) power-optimization issues are becoming increasingly important. Many researchers have tried to use dynamic voltage and frequency scaling (DVFS) technology to optimize a GPU's internal energy consumption. However, DVFS energy management often has difficulty balancing GPU performance and energy efficiency. This paper aims to implement a DVFS energy management strategy. We constructed a new type of neural network to a GPU-based energy management scheme, implemented the global-based DVFS model, and explored its implementation details. Using a master-slave model, we built a global energy control solution strategy. This strategy performs global collaborative DVFS adjustments on the GPU's energy consumption module based on task characteristics. Through the software construction and implementation of the global-based DVFS model, we proved that the strategy improves the GPU performance while improving the GPU's energy efficiency. We conducted performance and energy tests on three GPUs on the Tesla, Fermi, and Kepler platforms. The experiments showed that this strategy improved the performance and power consumption of GPUs based on each of the platforms.",Y. Huang; B. Guo; Y. Shen,Collaborative control;DVFS method;global-based energy optimization;task feature,2019,gpu energy consumption optimization with a global based neural network method,1
511,Minimizing Energy Consumption Scheduling Algorithm of Workflows With Cost Budget Constraint on Heterogeneous Cloud Computing Systems,,10.1109/ACCESS.2020.3037205,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253551,"Cloud computing is a promising platform to conduct large-scale workflow applications according to the pay-per-use model. Minimizing the energy consumption of precedence constrained workflows with cost budget constraints has become one of the popular topics in cloud data centers. Most existing scheduling algorithms mainly consider execution time or cost of a given workflow application under a budget constraint; however, these algorithms do not adequately consider energy saving. A reducing energy consumption strategy using a critical task remapping (RMREC) algorithm is proposed in this study. This algorithm is decomposed into two phases: energy consumption reduction and critical task remapping. In the first phase, the adjustable cost budget and spare cost are determined on the basis of cost budget, critical task path, and adjustable budget factor. All workflow tasks are further allocated to virtual machines (VMs) with the lowest energy consumption to achieve preliminary mapping between tasks and VMs while satisfying the adjustable cost budget constraint. In the second phase, critical tasks are remapped to VMs according to spare cost to decrease energy consumption caused by task migration. Experiments on two types of workflow applications with different scales demonstrate that the presented RMREC algorithm effectively reduces energy consumption without violating cost budget constraints compared with existing algorithms.",L. Zhang; L. Wang; Z. Wen; M. Xiao; J. Man,Cost budget constraint;energy consumption;heterogeneous cloud computing systems;workflow application,2020,minimizing energy consumption scheduling algorithm of workflows with cost budget constraint on heterogeneous cloud computing systems,1
512,Trace-Driven Simulation for Energy Consumption in High Throughput Computing Systems,978-1-4799-6144-3,10.1109/DS-RT.2014.12,2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957173,"High Throughput Computing (HTC) is a powerful paradigm allowing vast quantities of independent work to be performed simultaneously. However, until recently little evaluation has been performed on the energy impact of HTC. Many organisations now seek to minimise energy consumption across their IT infrastructure though it is unclear how this will affect the usability of HTC systems. We present here HTC-Sim, a simulation system which allows the evaluation of different energy reduction policies across an HTC system comprising a collection of computational resources dedicated to HTC work and resources provided through cycle scavenging -- a Desktop Grid. We demonstrate that our simulation software scales linearly with increasing HTC workload.",M. Forshaw; N. Thomas; A. S. McGough,,2014,trace driven simulation for energy consumption in high throughput computing systems,1
514,Evolutionary Algorithms in Cloud Computing from the Perspective of Energy Consumption: A Review,978-1-5386-8143-5,10.1109/ICET.2018.8603582,2018 14th International Conference on Emerging Technologies (ICET),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8603582,"Cloud Computing provides utility-based IT services. The services are available as pay per use. Cloud gives advantage to organizations in setting up fundamental hardware and software requirements i.e. instead of purchasing hardware or software cloud services can be used. The availability of cloud services any time and anywhere makes it a feasible solution for many applications. cloud services are constrained by some parameters such as Quality of Service (QoS), efficient utilization of cloud resources, user budget, user deadlines, energy consumption etc. In this article, we present a comprehensive review of techniques or algorithms designed to reduce energy consumption in cloud data centers. The review covers Evolutionary Algorithms (EA) such as Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO) and Genetic Algorithms (GA). We discuss each technique with strengths and weaknesses. Target objectives of each algorithm are also compared. The article is concluded with future research directions.",K. Maryam; M. Sardaraz; M. Tahir,PSO;ACO;GA;Energy,2018,evolutionary algorithms in cloud computing from the perspective of energy consumption a review,1
516,A Shallow Deep Neural Network for Selection of Migration Candidate Virtual Machines to Reduce Energy Consumption,978-1-6654-0426-6,10.1109/ICWR51868.2021.9443133,2021 7th International Conference on Web Research (ICWR),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443133,"In recent years, the widespread growth of cloud computing has surprisingly increased the energy consumption in data centers. In this regard, employing energy reduction techniques is changed to one of the prominent challenges for cloud service providers and includes both dynamic and static techniques. Although by utilizing static techniques along with creating data centers energy consumption is relatively reduced, the rapid growth of cloud computing due to the increasing demands of users for these resources has changed energy consumption to a potential challenge. Utilizing dynamic energy reduction techniques which can be possible through the integration of the virtual machine into at least one physical server can be considered as an effective solution to this problem. This is done through live virtual machine migration and selecting the migration candidate virtual machine is a key step in this technique. In this paper, the combination of Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) is used to choose the appropriate migration candidate virtual machine which leads to the diagnosis of whether a virtual machine is sensitive to latency or not. The proposed model was validated on the workload of Microsoft Azure virtual machines as a dataset. According to the empirical results, the proposed model has higher classification accuracy compared to other existing models for selecting the migration candidate virtual machines.",Z. Khodaverdian; H. Sadr; S. A. Edalatpanah,Resource allocation;Energy consumption;Cloud data centers;Virtual machine;CNN;GRU,2021,a shallow deep neural network for selection of migration candidate virtual machines to reduce energy consumption,1
517,3D-Sorter: 3D Design of a Resource-Aware Hardware Sorter for Edge Computing Platforms Under Area and Energy Consumption Constraints,978-1-7281-5775-7,10.1109/ISVLSI49217.2020.00018,2020 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155021,"In this paper, we proposed a 3-dimensional hardware sorting architecture (3D-Sorter), based on MultiDimensional Sorting Algorithm (MDSA). the proposed architecture transforms a sequence of input records into a 3-dimensional matrix. Records of every dimension are sorted in several MDSA phases, using partial sorting methods. Our synthesis results, provided by Xilinx Vivado indicate that the 3D-Sorter design decreases the number of Look-Up Tables (LUT) and registers by 54% and 42.7%, compared to the state-of-the-art hardware sorter. Also, the power consumption is reduced by 48.15% on average. The results show that the proposed architecture is a remarkable power/area saving for edge components.",A. Norollah; Z. Kazemi; D. Hely,Hardware accelerator;multi-dimensional sorting algorithm;sorting network;parallel sorting;FPGA,2020,d sorter d design of a resource aware hardware sorter for edge computing platforms under area and energy consumption constraints,1
518,Energy Consumption and Quality of Service Optimization in Containerized Cloud Computing,978-1-7281-1275-6,10.1109/ISPRAS.2018.00014,2018 Ivannikov Ispras Open Conference (ISPRAS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675157,"Lightweight virtualization technology has emerged as an alternative to traditional hypervisor-based virtualization. Containers based on an operating system level virtualization have shown superior performance and more flexibility than virtual machines. Both factors encourage their fast adoption and wide use in cloud environments. Container technology guarantees efficient interaction with hardware through system calls and isolation of tasks execution. The portability and ease of deployment enable containers to execute a variety of jobs. Several techniques have been used to address the problem of job allocation on containers. In this paper, a set of allocation strategies is proposed to distribute the workload to multiple OS containers that are running on several servers. We address two objective scheduling problem: minimizing energy and a number of SLA violations. We propose seventy-two strategies and analyze their performance by comprehensive simulation. We demonstrate that proposed techniques outperform previous works in terms of both the energy savings and QoS.",R. Canosa; A. Tchernykh; J. M. Cortés-Mendoza; R. Rivera-Rodriguez; J. L. Rizk; A. Avetisyan; Z. Du; G. Radchenko; E. R. Concepción Morales,"cloud computing, containers, scheduling strategies",2018,energy consumption and quality of service optimization in containerized cloud computing,1
519,Exploiting Hybrid SPM-Cache Architectures to Reduce Energy Consumption for Embedded Computing,978-1-4799-6123-8,10.1109/HPCC.2014.59,"2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056763,"Scratch-Pad Memories (SPMs) have been increasingly used in embedded systems due to their time predictability and better energy efficiency as compared to caches. However, the SPM is typically controlled by software, which is less adaptive to runtime instruction/data access patterns that are dependent on the input data and hence may lead to performance degradation. In this paper, we study the energy dissipation of a number of hybrid on-chip memory architectures by combining both caches and SPMs without increasing the total on-chip memory size. In the hybrid SPM-cache architectures, the instructions/data in the SPMs can be accessed more energy-efficiently, while other instructions/data not stored into the SPMs can exploit the cache to take advantage of runtime locality for reducing energy consumption. Our experimental results indicate that with the equivalent total on-chip memory size, several hybrid SPM-cache architectures are more energy-efficient than either pure software-controlled SPMs or pure hardware-controlled caches. In particular, using the hybrid SPM-cache to store both instructions and data can achieve the best energy efficiency.",W. Zhang; L. Wu,,2014,exploiting hybrid spm cache architectures to reduce energy consumption for embedded computing,1
520,Energy Consumption Minimization using Data Compression in Mobile Edge Computing,978-1-7281-7327-6,10.1109/ICCC49849.2020.9238837,2020 IEEE/CIC International Conference on Communications in China (ICCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238837,"In recent years, many researchers have done a lot of work on mobile edge computing (MEC). However, existing works on energy minimization of MEC systems mainly focus on comparing energy consumption between accomplishing tasks locally and computing tasks on MEC server, failing to explore energy optimal solutions for computing tasks on MEC server. In this paper, we consider a single-user-single-server MEC system, working under latency constraint. In order to reduce the energy consumption of mobile device and meet the latency constraint, we use computation offloading to accomplish large tasks. However, energy consumed by mobile devices (MD) for the transmitting process could be decreased further by compressing data transmitted from MD to mobile-edge server (MEC server). But energy consumed when compressing data on MD increases while the compression rate decreases. Therefore, we develop a solution to figure out the optimal compression rate to minimize the total energy for MD to accomplish one simple task and to meet the latency constraint at the same time. With the optimal compression rate, energy consumption for task-process could be reduced by 38.37% to 60.49% when the latency constraint varies from 0.1s to 0.8s.",B. Wang; Y. Liu; G. Shou; Y. Hu,MEC;computation offloading;data compression;energy optimal problem,2020,energy consumption minimization using data compression in mobile edge computing,1
522,A Delay and Energy Consumption Efficient Offloading Algorithm in Mobile Edge Computing System,978-1-7281-2184-0,10.1109/ICCSN.2019.8905398,2019 IEEE 11th International Conference on Communication Software and Networks (ICCSN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8905398,"With the rapid development of mobile Internet and increasing numbers of mobile devices, mobile edge computing (MEC) which offers computational capability within radio access network has become the key technology to enhance users' experience. In this paper, we investigate the computing offloading problem considering delay and energy consumption of mobile devices jointly in wireless access network. Then, the optimization problem minimizing the delay and energy consumption of mobile devices is formulated and transformed into convex optimization. To solve the optimization, a delay and energy consumption efficient offloading algorithm (DEOA) based on alternating direction method of multipliers (ADMM) is proposed. The simulation results show that the proposed algorithm significantly reduces delay and energy consumption compared to stochastic allocation. Meanwhile, compared with joint delay and energy efficient offloading scheme (JCDE) proposed in another paper, the consumption is reduced while the average speed of solution is increased by about 65% under various system parameters.",Z. Hao; Y. Sun; Y. Zhang,mobile edge computing;delay and energy consumption efficient offloading algorithm;alternating direction method of multipliers;wireless network;global consensus optimization,2019,a delay and energy consumption efficient offloading algorithm in mobile edge computing system,1
523,Mobile-Computing Based Rationalization for Energy Consumption,978-1-5386-2269-8,10.1109/ICPET.2017.12,2017 International Conference on Promising Electronic Technologies (ICPET),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109034,"This contribution shows how rationalized energy consumption can be achieved using user-oriented mobile application. It is undoubtable that energy efficiency improvement is one of the most important targets to be achieved on every society as a whole and in power system in particular. With the advent of smart grids, residential end users are expected to shift from their passive role as consumers of electricity to an active contributor role, referred to as co-provider, a term that reflects the consumer ability to reduce electricity usage, shift usage from on-peak to off-peak periods, generate and trade excess electricity. Based on different environmental behavior change models from behavior science, as well as a user study with prospective users, a hybrid energy consumption behavioral change model was proposed, and a set of well-defined requirements were identified and guided us through the design and development of a mobile cloud application called Mobile Cloud for Smart Grid Metering. This paper will describe the architecture, design and implementation of the proposed prototype, in addition to presenting and discussing the evaluations of usability results.",S. Odeh; D. Voskergian,cloud computing;design criteria;behavioral changemodel;rationalized energy consumption,2017,mobile computing based rationalization for energy consumption,1
524,Energy consumption reduction by integrating Wireless Sensors and Actuators Networks Supervisory Controller with the Cloud Computing,978-1-5090-3474-1,10.1109/IECON.2016.7793863,IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7793863,"In this paper we present a new framework for energy consumption conservation in green smart building. We propose an energy efficient smart wireless control system that integrates Wireless Sensors Actuators Networks (WSAN), Machine Learning and Cloud Computing. Moving WSANs Supervisory controlled by Petri nets system to the cloud have many advantages such as scalability, and availability. The first component of our proposed framework is Petri Nets supervisory controller which is implemented to monitor and control the entire system. Moreover, fault-tolerant algorithms could be developed and deployed with the supervisory system. The second component of our framework is the machine learning scheme that is responsible of processing and manipulating users preferences based on Spiking Neural Networks. This is very crucial as it considers behavioral preferences of tenants of building called user preferences. Finally integrating all components of the framework and deploy it on the cloud environment gives WSAN the benefits of using cloud resources and make the system highly available, scalable and fault-tolerant.",K. E. Bouazza; W. A. Deabes; H. H. Amin; G. A. Elsayed,wireless sensor networks;Petri Nets;Spiking Neural Networks;Cloud computing;Energy saving,2016,energy consumption reduction by integrating wireless sensors and actuators networks supervisory controller with the cloud computing,1
525,Energy consumption in mobile computing,978-1-4673-6155-2,10.1109/CONIELECOMP.2013.6525773,"CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525773,"Mobile devices users have risen in recent years, by convergence of functionality and technology on it. Mobile devices also appear in market as interactive devices where users expects short-time response, usability and functionality. That convergence of digital entertainment, mobile communication technologies, and a set of new capabilities, becomes requirements for mobile application developers and hardware architects, thus both professionals have the dilemma of offer low power consumption and high performance on it. However, both concepts are opposite each other. That means, if I get a great performance, probably have attached high power consumption. Programmers have found in parallel computing, multithreading programming, and process scheduling, the way to achieve more efficiency in their programs. Moreover, hardware architects have found in multicore processors the way to achieve better performance and low-power consumption. This work wants to join both solutions and check if we can achieve less response time in applications and processes, and get a balance between performance and energy consumption.",R. I. Ramírez; E. H. Rubio; A. M. Viveros,Energy Consumption;Mobile Computing;Parallel Computing;Multithreading;Systems-On-Chip,2013,energy consumption in mobile computing,1
526,Effective task offloading heuristics for minimizing energy consumption in edge computing,978-1-6654-5417-9,10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics55523.2022.00069,"2022 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903203,"Mobile edge computing (MEC) allows user devices to offload computing tasks to edge servers, which are deployed close to users, for fast execution, short delay and energy saving. As a result, user devices save energy, but edge servers consume tremendous amount of energy. Accordingly, besides regarding the amount of energy consumed by user devices, it is also necessary to take into account that of energy consumed by edge servers. In this paper, we propose effective heuristics for offloading tasks from multi-user devices to multi-core edge servers with the objective of minimizing the total amount of energy consumption under the deadline constraint. The proposed heuristics start from initial task sequences that are generated by the well-known long and short task first rules, respectively. Then, tasks from the initial task sequences are scheduled in a greedy manner so that the considered total amount of energy consumption can be minimized without the violation of the deadline constraint. Simulation experimental results show that the proposed algorithms significantly outperform the compared baseline RoundRobin, indicating the good effectiveness of our heuristics.",G. Yin; R. Chen; Y. Zhang,edge computing;task offloading;heuristic;energy efficiency,2022,effective task offloading heuristics for minimizing energy consumption in edge computing,1
527,Energy Consumption Analysis of Scheduling Algorithms for Cloud Computing Systems,978-1-7281-3783-4,10.1109/CCWC47524.2020.9031113,2020 10th Annual Computing and Communication Workshop and Conference (CCWC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031113,"With more and more data and service moved to different cloud computing systems, progress in the area of energy consumption and environmentally friendly practices must be made so these advancements do not plateau. The goal of this study is to provide exceptional insight regarding which scheduling algorithms will yield environmentally sustainable, commonly referred to as ‘green,’ practices for energy efficiency. This will be achieved by tracking the similarities and differences of multiple scheduling algorithms, considering various datacenter topologies and their task sizes (MIPS). Trace files produced by the simulator will be used to create a visual representation of the observed data and analyze the energy consumption of the servers and switches (core, aggregation, and access).",P. Hovsepian; Y. Tian,algorithms;cloud computing;consumption;data center;energy;green;scheduling;simulation;task;topologies,2020,energy consumption analysis of scheduling algorithms for cloud computing systems,1
528,A new multifunctional neural network with high performance and low energy consumption,978-1-5090-3846-6,10.1109/ICCI-CC.2016.7862082,2016 IEEE 15th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862082,"A common artificial neural network (ANN) uses the same activation function for all hidden and output neurons. Therefore, it has an optimization limitation for complex big data analysis due to its single mathematical functionality. In addition, an ANN with a complicated activation function uses a very long training time and consumes a lot of energy. To address these issues, this paper presents a new energy-efficient “Multifunctional Neural Network” (MNN) that uses a variety of different activation functions to effectively improve performance and significantly reduce energy consumption. A generic training algorithm is designed to optimize the weights, biases, and function selections for improving performance while still achieving relatively fast computational time and reducing energy usage. A novel general learning algorithm is developed to train the new energy-efficient MNN. For performance analysis, a new “Genetic Deep Multifunctional Neural Network” (GDMNN) uses genetic algorithms to optimize the weights and biases, and selects the set of best-performing energy-efficient activation functions for all neurons. The results from sufficient simulations indicate that this optimized GDMNN can perform better than other GDMNNs in terms of achieving high performance (prediction accuracy), low energy consumption, and fast training time. Future works include (1) developing more effective energy-efficient learning algorithms for the MNN for data mining application problems, and (2) using parallel cloud computing methods to significantly speed up training the MNN.",L. M. Zhang,Neural networks;deep learning;energy-efficient computing;data mining;activation functions;genetic algorithms,2016,a new multifunctional neural network with high performance and low energy consumption,1
529,Improvement of Energy Consumption in Cloud Computing,978-1-7281-9111-9,10.1109/ICCCEEE49695.2021.9429615,"2020 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429615,"For small to large scale cloud computing data centers, the power consumption of physical and virtual machines is a major challenge. Two states of the virtual machine, active state if selected by cloudlet and idle state if not selected. Two types of works are applied which are existing work and proposed work. In existing work non-power aware data center, the power consumption used time-shared data center that discarded cloudlet file size to selected VMs. To performance-enhanced of power consumption in existing work applied power-aware data center in proposed work used the intelligent distribution of cloudlets that according to cloudlet file size organized cloudlet on five range to selected VMs. The result shows in existing work that five VMs selected by five cloudlets, which consumed all power of the host. VM1 difference in existing work to proposed work by selected cloudlet1 with file size 300 to consumed 1000 second in existing work and selected three cloudlets which are cloudlet1 with file size 300, cloudlet2 with file size 400 and cloudlet3 with file size 500 to consumed 2999.99 seconds in proposed work, so there is a positive relationship of VM execution time and number of cloudlets that selected by VM. That positive relationship affected positively the power consumption of VM, but at the same time, the VM2 and VM3 not selected by cloudlet stayed in the idle state near to zero power consumption and zero execution time in proposed work to the reduced power consumption of host from 7.134 KW to 6.562 kW with difference 0.572 kW. VM4 and VM5 were selected by cloudlet4 and cloudlet5 in two work there is no change similar to VM2 and VM3. Performance enhancement of VMs power consumption reduced the cost to increased lifetime and reduced carbon footprints to make environment-friendly.",H. A. F. Almula; M. E. Hamza; M. E. A. Kanona,power consumption;virtual machines;cloudlet;performance,2021,improvement of energy consumption in cloud computing,1
530,Minimizing Terminal Energy Consumption of Task Offloading via Resource Allocation in Mobile Edge Computing,978-1-6654-0527-0,10.1109/CSCWD54268.2022.9776100,2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776100,"Mobile Edge Computing (MEC) is considered a promising technology that can support Internet of Things (IoT) devices to deploy their applications on edge servers to reduce IoT devices’ computing and energy consumption. However, the sustainability of IoT devices will not be guaranteed when an edge server needs to serve excessive computing tasks concurrently without a reasonable offloading strategy and efficient resources allocation. Therefore, this paper effectively allocates resources to obtain an offloading strategy with high perceived service quality. To tackle this challenge, we formally model the computational offloading problem for the minimum energy consumption of IoT devices under the constraints of latency and communication interference. We propose a collaborative genetic particle swarm algorithm with reverse learning (RL-GPSO) and have extensively evaluated this method through many experiments. Experimental results prove that RL-GPSO can obtain excellent performance.",W. Tan; K. Ding; X. Zhang; Z. Liang; J. Liu,mobile edge computing;task offload;particle swarm optimization;reverse learning;genetic algorithm,2022,minimizing terminal energy consumption of task offloading via resource allocation in mobile edge computing,1
535,LEMAX: Learning-based Energy Consumption Minimization in Approximate Computing with Quality Guarantee,978-1-5386-4114-9,10.1109/DAC.2018.8465881,2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465881,"Approximate computing aims to trade accuracy for energy efficiency. Various approximate methods have been proposed in the literature that demonstrate the effectiveness of relaxing accuracy requirements in a specific unit. This provides a basis for exploring simultaneous use of multiple approximate units to improve efficiency under guarantees on quality of results. In this paper, we explore the effect of combining multiple approximate units on the energy consumption and identify the best setting that minimizes energy consumption under a quality constraint. Our approach also enables changes in unit configurations throughout the program. To do this effectively, we need a method to examine the combined impact of multiple approximate units on the output quality, and configure individual units accordingly. To solve this problem, we propose LEMAX that uses gradient descent approach to identify the best configuration of the individual approximate units for a given program. We evaluate the efficacy of LEMAX in minimizing the energy consumption of several machine learning applications with varying size (i.e., number of operations) under different quality constraints. Our evaluation shows that the configuration provided by LEMAX for a system with multiple approximate units improves the energy consumption by on average, 97.7%, 83.12%, and 73.95% for quality loss of 5%, 2% and 0.5%, respectively, compared to configurations obtained for a system with a single approximate resource.",V. Akhlaghi; S. Gao; R. K. Gupta,Approximate computing;Design Automation;Machine Learning,2018,lemax learning based energy consumption minimization in approximate computing with quality guarantee,1
536,Profiling Software for Energy Consumption,978-1-4673-5146-1,10.1109/GreenCom.2012.86,2012 IEEE International Conference on Green Computing and Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6468359,"The amount of energy consumed by computer systems can be lowered through the use of more efficient algorithms and software. Unfortunately, software developers lack the tools to pinpoint energy-hungry sections in their code and therefore have to rely on their intuition when trying to optimize their code for energy consumption. We have developed eprof, a profiler that relates energy consumption to code locations, it attributes both the synchronously consumed energy in the CPU and the asynchronously consumed energy in peripheral devices like hard drives, network cards, etc. Eprof requires minimal changes to the kernel (tens of lines of code) and does not require special hardware to energy-profile software. Therefore eprof can be widely used to help developers make energy-aware decisions.",S. Schubert; D. Kostic; W. Zwaenepoel; K. G. Shin,Energy consumption by software;energy profiling,2012,profiling software for energy consumption,1
537,GreenAdvisor: A tool for analyzing the impact of software evolution on energy consumption,978-1-4673-7532-0,10.1109/ICSM.2015.7332477,2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332477,"Change-impact analysis, namely “identifying the potential consequences of a change” is an important and well studied problem in software evolution. Any change may potentially affect an application's behaviour, performance, and energy consumption profile. Our previous work demonstrated that changes to the system-call profile of an application correlated with changes to the application's energy-consumption profile. This paper evaluates and describes GreenAdvisor, a first of its kind tool that systematically records and analyzes an application's system calls to predict whether the energy-consumption profile of an application has changed. The GreenAdvisor tool was distributed to numerous software teams, whose members were surveyed about their experience using GreenAdvisor while developing Android applications to examine the energy-consumption impact of selected commits from the teams' projects. GreenAdvisor was evaluated against commits of these teams' projects. The two studies confirm the usefulness of our tool in assisting developers analyze and understand the energy-consumption profile changes of a new version. Based on our study findings, we constructed an improved prediction model to forecast the direction of the change, when a change in the energy-consumption profile is anticipated. This work can potentially be extremely useful to developers who currently have no similar tools.",K. Aggarwal; A. Hindle; E. Stroulia,Software energy consumption;energy efficiency;software tools;application software,2015,greenadvisor a tool for analyzing the impact of software evolution on energy consumption,1
538,Deep Green: Modelling Time-Series of Software Energy Consumption,978-1-5386-0992-7,10.1109/ICSME.2017.79,2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094428,"Inefficient mobile software kills battery life. Yet, developers lack the tools necessary to detect and solve energy bugs in software. In addition, developers are usually tasked with the creation of software features and triaging existing bugs. This means that most developers do not have the time or resources to research, build, or employ energy debugging tools. We present a new method for predicting software energy consumption to help debug software energy issues. Our approach enables developers to align traces of software behavior with traces of software energy consumption. This allows developers to match run-time energy hot spots to the corresponding execution. We accomplish this by applying recent neural network models to predict time series of energy consumption given a software's behavior. We compare our time series models to prior state-of-the-art models that only predict total software energy consumption. We found that machine learning based time series based models, and LSTM based time series based models, can often be more accurate at predicting instantaneous power use and total energy consumption.",S. Romansky; N. C. Borle; S. Chowdhury; A. Hindle; R. Greiner,energy;software engineering;online model;profiling;green mining;modelling,2017,deep green modelling time series of software energy consumption,1
539,A system-call based model of software energy consumption without hardware instrumentation,978-1-5090-0172-9,10.1109/IGCC.2015.7393719,2015 Sixth International Green and Sustainable Computing Conference (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393719,"The first challenge to develop an energy efficient application is to measure the application's energy consumption, which requires sophisticated hardware infrastructure and significant amounts of developers' time. Models and tools that estimate software energy consumption can save developers time, as application profiling is much easier and more widely available than hardware instrumentation for measuring software energy consumption. Our work focuses on modelling software energy consumption by using system calls and machine learning techniques. This system call based model is validated against actual energy measurements from five different Android applications. These results demonstrate that system call counts can successfully model software energy consumption if the idle energy consumption of an application is estimated or known. In the absence of any knowledge of an application's idle energy consumption, our system call based approach is still useful to compare the energy consumption among different versions of the same application.",S. A. Chowdhury; L. N. Kumar; M. T. Imam; M. S. M. Jabbar; V. Sapra; K. Aggarwal; A. Hindle; R. Greiner,,2015,a system call based model of software energy consumption without hardware instrumentation,1
540,Awakening Awareness on Energy Consumption in Software Engineering,978-1-5386-2673-3,10.1109/ICSE-SEIS.2017.10,2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Society Track (ICSE-SEIS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961670,"Software producing organizations have the ability to address the energy impact of their ICT solutions during the development process. However, while industry is convinced of the energy impact of hardware, the role of software has mostly been acknowledged by researchers in software engineering. Strengthened by the limited practical knowledge to reduce the energy consumption, organizations have less control over the energy impact of their products and lose the contribution of software towards energy related strategies. Consequently, industry risks not being able to meet customer requirements or even fulfillcorporate sustainability goals. In this paper we perform an exploratory case study on how to create and maintain awareness on an energy consumption perspective for software among stakeholders involved with the development of software products. During the study, we followed the development process of two commercial software products and provided direct feedback to the stakeholders on the effects of their development efforts, specifically concerning energy consumption and performance, using an energy dashboard. Multiple awareness measurements allowed us to keep track of changes over time on specific aspects affecting software development. Our results show that, despite a mixed sentiment towards the dashboard, changed awareness has triggered discussion on the energy consumption of software.",E. Jagroep; J. Broekman; J. M. E. M. van der Werf; P. Lago; S. Brinkkemper; L. Blom; R. van Vliet,Energy consumption perspective;Awareness;Software energy consumption;Software engineering,2017,awakening awareness on energy consumption in software engineering,1
541,A software tool to efficiently manage the energy consumption of HPC clusters,978-1-4673-7428-6,10.1109/FUZZ-IEEE.2015.7338079,2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338079,"Today, High Performance Computing clusters (HPC) are an essential tool owing to they are an excellent platform for solving a wide range of problems through parallel and distributed applications. Nonetheless, HPC clusters consume large amounts of energy, which combined with notably increasing electricity prices are having an important economical impact, forcing owners to reduce operation costs. In this work we propose a software, named EECluster, to reduce the high energy consumption of HPC clusters. EECluster works with both OGE/SGE and PBS/TORQUE resource management systems and automatically tunes its decision-making mechanism based on a machine learning approach. The quality of the obtained results using this software are evaluated by means of experiments made using actual workloads from the Scientific Modelling Cluster at Oviedo University and the academic-cluster used by the Oviedo University for teaching high performance computing subjects.",A. Cocaña-Fernández; L. Sánchez; J. Ranilla,,2015,a software tool to efficiently manage the energy consumption of hpc clusters,1
542,Semidefinite programming based resource allocation for energy consumption minimization in software defined wireless sensor networks,978-1-5090-3254-9,10.1109/PIMRC.2016.7794902,"2016 IEEE 27th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7794902,"In this paper, one centralized resource allocation algorithm is proposed to minimize energy consumption in software defined wireless sensor networks (SD-WSNs). The energy consumption problem is formulated as an optimization problem, given quality-of-service (QoS) constraint defined as Signal-to-Interference-plus-Noise Ratio (SINR). Then, the nonconvex optimization problem is relaxed into a semidefinite programming (SDP), which serves as a lower bound. To analyze the tightness of the lower bound, two special cases are introduced. Besides, one distributed approach is also developed to provide a performance benchmark. Furthermore, simulation results are revealed that the proposed centralized algorithm performances better with respect to the energy consumption and bandwidth utilization.",Y. Zhang; Y. Zhu; F. Yan; Z. Li; L. Shen,resource allocation;software defined wireless sensor networks (SD-WSNs);semidefinite programming (SDP),2016,semidefinite programming based resource allocation for energy consumption minimization in software defined wireless sensor networks,1
543,Software-Directed Data Access Scheduling for Reducing Disk Energy Consumption,978-1-4577-0295-2,10.1109/ICDCS.2012.12,2012 IEEE 32nd International Conference on Distributed Computing Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6258032,"Most existing research in disk power management has focused on exploiting idle periods of disks. Both hardware power-saving mechanisms (such as spin-down disks and multi-speed disks) and complementary software strategies (such as code and data layout transformations to increase the length of idle periods) have been explored. However, while hardware power-saving mechanisms cannot handle short idle periods of high-performance parallel applications, prior code/data reorganization strategies typically require extensive code modifications. In this paper, we propose and evaluate a compiler-directed data access (I/O call) scheduling framework for saving disk energy, which groups as many data requests as possible in a shorter period, thus creating longer disk idle periods for improving the effectiveness of hardware power-saving mechanisms. As compared to prior software based efforts, it requires no code or data restructuring. We evaluate our approach using six application programs in a cluster-based simulation environment. The experimental results show that it improves the effectiveness of both spin-down disks and multi-speed disks with doubled power savings on average.",Y. Zhang; J. Liu; M. Kandemir,disk power management;spin-down disk;multi-speed disk;compiler-directed data access scheduling;I/O call scheduling,2012,software directed data access scheduling for reducing disk energy consumption,1
544,A Methodology for Relating Software Structure with Energy Consumption,978-1-5386-3238-3,10.1109/SCAM.2017.18,2017 IEEE 17th International Working Conference on Source Code Analysis and Manipulation (SCAM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8090144,"With the widespread use of mobile devices relying on limited battery power, the burden of optimizing applications for energy has shifted towards the application developers. In their quest to develop energy efficient applications, developers face the hurdle of measuring the effect of software change on energy consumption. A naive solution to this problem would be to have an exhaustive suite of test cases that are executed upon every change to measure their effect on energy consumption. This method is inefficient and also suffers from environment dependent inconsistencies. A more generalized method would be to relate software structural metrics with its energy consumption behavior. Previous attempts to relate change in objectoriented metrics to their effects on energy consumption have been inconclusive. We observe that structural information is global and executed tests are rarely comprehensive in their coverage, this approach is prone to errors. In this paper, we present a methodology to relate software energy consumption with software structural metrics considering the test case execution traces. Furthermore, we demonstrate that software structural metrics can be reliably related to energy consumption behavior of programs using several versions of three open-source iteratively developed android applications. We discover that by using our approach we are able to identify strong correlations between several software metrics and energy consumption behavior.",A. A. Bangash; H. Sahar; M. O. Beg,energy;energy consumption;mining software repositories;software metrics;sustainable-software;static-analysis,2017,a methodology for relating software structure with energy consumption,1
545,Practices of Energy Consumption for Sustainable Software Engineering,978-1-5386-7466-6,10.1109/IGCC.2018.8752151,2018 Ninth International Green and Sustainable Computing Conference (IGSC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752151,"Sustainable Software Engineering, also known as “Green IN Software”, focuses on the production of sustainable software. The traditional software engineering process causes negative influences on the environment, economy and to society. For instance, the energy consumption during the software processing is considered as a first order impact because it directly leads to high costs on energy bills and consequently on the environment. Moreover, the optimization of a process implementation and software development can lead to second order impacts, also referred to as indirect impacts. Finally, the third other impact considers the user's behaviors and consciousness regarding the concept of sustainability. In order to mitigate these negative impacts, the purpose of this research is to identify, via systematic literature review, the practices of sustainable software engineering reported by the academy applied in the industry. Through the systematic literature review, it was possible to discover 170 practices in which 70 were related to practices of energy consumption that could be adopted during the software development. Our results indicate that those practices emerged from the grounded theory, which are part of SWEBOK areas and are applicable in the industry.",A. C. Moises; A. Malucelli; S. Reinehr,energy consumption;sustainable software engineering;software engineering;sustainability,2018,practices of energy consumption for sustainable software engineering,1
546,Energy consumption in software defined networks to provide service for mobile users,978-1-5090-4372-9,10.1109/IWCMC.2017.7986498,2017 13th International Wireless Communications and Mobile Computing Conference (IWCMC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7986498,"Nowadays, new technologies are focused on providing ubiquity and the possibility of accessing services from everywhere while reducing power consumption and the CO2 emissions in networking. Furthermore, the process of network virtualization is more and more used. However, both concepts are not currently treated as a set. For this reason, this paper presents a practical evaluation where the power consumption in a virtualized network is measured. To do it, we have developed a topology composed by several virtual routers that emulates the core of a network through which we have sent several data flows. Measurements have been performed by using http and video streaming traffic while running Open Shortest Path First (OSPF) and Routing Information Protocol version 2 (RIPv2) as routing protocols. Result shows that both protocols present similar behavior when streaming traffic is sent while RIPv2 demands more CPU usage when http traffic is sent. Finally, the energy consumption in http traffic is always bigger.",D. Sarabia-Jácome; A. Rego; S. Sendra; J. Lloret,Virtual Routers;Power consumption;virtualization;users' mobility;software Defined Network (SDN);content delivery,2017,energy consumption in software defined networks to provide service for mobile users,1
547,Energy Consumption Analysis Method of CPS Software Based on Architecture Modeling,978-1-4673-9295-2,10.1109/FCST.2015.47,2015 Ninth International Conference on Frontier of Computer Science and Technology,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314646,"CPS is kinds of networked embedded systems that combine calculating system and physical environment. Because software is the main component of CPS, its energy consumption will directly affect the trustworthiness of CPS. Software architecture can provide design model and guidance for constructing software structure, behavior and key attributes in design phase. So modeling, analyzing and evaluating the software architecture energy consumption of the CPS software can help find the energy consumption design defects, which will effectively reduce the cost and improve development efficiency. Time state transition matrix (TSTM), designed for modeling embedded software behavior, is a table-based state machine modeling language with time semantic in which the front-end is expressed in the table form and the back-end has strict formalized definition. By introducing energy consumption indicators and constraints for TSTM, form energy consumption TSTM (ETSTM), make it be suitable to the software architecture modeling of energy consumption. On this basis, the energy consumption analysis method with multiple attributes restriction based on bounded model checking technology (BMC) is provided. At last, the effectiveness of the proposed method is validated by modeling and verifying certain type train control software.",H. Gang; B. Yinfeng; Z. Kuanjiu; W. Jie; L. Mingchu; L. Zihao,energy consumption modeling;cyber physical systems;time state transition matrix;software architecture;bounded model checking,2015,energy consumption analysis method of cps software based on architecture modeling,1
548,Managing Energy Consumption of Wireless Multipath TCP Connections Using Software-Defined Networking: A Review,978-1-7281-8301-5,10.1109/ICREGA50506.2021.9388293,2021 6th International Conference on Renewable Energy: Generation and Applications (ICREGA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388293,"Multipath transmission control protocol (MPTCP) has been established as an extension to the standard TCP to achieve efficient and uninterrupted communication simultaneously through multiple paths. It outperforms traditional TCP in terms of performance and reliability. On the other hand, the emergence of software-defined networking (SDN) has made a momentous change in traditional network management and control. It makes the networks programmable via a controller that manages the entire network. However, energy consumption represents a significant issue when using multihomed devices since most of the wireless devices used in emerging technologies such as Internet-of-things and fog computing are battery-powered. This paper aims to answer the question of whether the current literature addresses controlling the energy consumption of MPTCP connections using SDN. Thus, the paper reviews the current research works that target MPTCP energy consumption for wireless connections and the usage of SDN to manage those connections. Our review finds that energy efficiency remains an open research challenge while controlling it in multipath devices effectively by using SDN is not well explored in the literature.",R. Shams; A. Abdrabou,Multipath TCP;heterogeneous wireless networks;software-defined networking;Internet of things;fog computing;5G;energy consumption,2021,managing energy consumption of wireless multipath tcp connections using software defined networking a review,1
549,Reducing Memory-Bus Energy Consumption of GPUs via Software-Based Bit-Flip Minimization,978-1-6654-7282-1,10.1109/MCHPC56545.2022.00008,2022 IEEE/ACM Workshop on Memory Centric High Performance Computing (MCHPC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024054,"Energy consumption is a major concern in high-performance computing. One important contributing factor is the number of times the wires are charged and discharged, i.e., how often they switch from ‘0’ to ‘1’ and vice versa. We describe a software technique to minimize this switching activity in GPUs, thereby lowering the energy usage. Our technique targets the memory bus, which comprises many high-capacitance wires that are frequently used. Our approach is to strategically change data values in the source code such that loading and storing them yields fewer bit flips. The new values are guaranteed to produce the same control flow and program output. Measurements on GPUs from two generations show that our technique allows programmers to save up to 9.3% of the whole-GPU energy consumption and 1.2% on average across eight graph-analytics CUDA codes without impacting performance.",A. Fallin; M. Burtscher,bit flips;energy consumption;memory;GPUs,2022,reducing memory bus energy consumption of gpus via software based bit flip minimization,1
550,Developing Low Energy Consumption Software Defined Radio Using Internet Of Things,978-1-7281-9090-7,10.1109/ISMSIT50672.2020.9255197,2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9255197,"The advent of the Internet of Things (IoT) could present swarms with unintentional or intentional interference with which they must contend in future energy problems. In light of this, a solution which offers robust and reliable low energy consumption SDR radiometer in spite of the increased electromagnetic spectrum congestion is needed. One promising genetic algorithm (GA) that could form the basis of a potential solution is the Software-Defined Radio (SDR). The core of an SDR's functionality is implemented in MATLAB R2019b software, allowing the system to alter its functionality while it is operating. Further, SDRs enable fully cognitive radios which have an Internet of Things (IoT) back-end to allow them to autonomously react and adapt to their transmission environment with no user interaction. A real-time engine is one that executes while the network is running and periodically updates operating parameters to tune the network's performance to its current environment. The maximum energy voltage recorded at 77.18 volts in maximum time of 4900 seconds recorded through simulation using SDR based radiometer with noisy signals as well as standard deviation. The voltage increased recorded at 276.88 volts however voltage reduction recorded at 17.69 volts in constraint to see the positive effect of SDR based radiometer. Total power output at 0.25W with respect to bandwidth of signals processed for measured and theoretical outputs with 10 MHz. The genetic algorithm used for the initialization of recombination with software defined radiometer simulation for low energy consumption.",L. M. Hasan; S. A. Nayyef; A. A. Ibrahim,internet of thing (IOT);Software-Defined Radio (SDR);Genetic Algorithm;energy,2020,developing low energy consumption software defined radio using internet of things,1
551,Energy Consumption on Software Transactional Memories,978-1-4673-4468-5,10.1109/WSCAD-SSC.2012.26,2012 13th Symposium on Computer Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391782,"With the spreading of multicore architectures, new challenges have been added to software development. Among those, efficiently avoiding race conditions through synchronization is one of the greatest difficulties in concurrent programming. Transactional memories have been proposed to reduce the issues and limitations found on previous synchronization techniques based in locks, such as mutexes, semaphores, and monitors. The use of transactions allows for a higher abstraction on writing code, leaving for the compiler or library the determination of which variables can be accessed concurrently. The runtime system is responsible for detecting conflicts during execution, and solving them in a way that the desired semantics is preserved. In this context, this paper analyzes energy consumption and performance of three Software Transactional Memory implementations, TL2, TinySTM, and Swiss TM, using the STAMP benchmarks. Different from previous works, the workloads are not simulated but executed in a computer. The results show that TinySTM and Swiss TM have very similar performance, even more when the number of threads is increased. On the other hand, TL2 presents worse performance for all benchmarks but Genome. Energy consumption closely follows the same trend, as no specific power management is employed, hence execution time is the main variable determining power.",T. M. Rico; M. L. Pilla; A. R. Du Bois,software transactional memories;green computing;parallel processing,2012,energy consumption on software transactional memories,1
553,Deep learning-based power consumption and generation forecasting for demand side management,978-1-6654-2867-5,10.1109/ICESC51422.2021.9532707,2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532707,"With the evolution of smart grid, the demand side management involving integration of renewable energy source and load management can be achieved by analyzing the data generated by monitoring devices. The objective of the work is to forecast the power consumption and generation for demand side management using deep learning techniques modelled in python. The deep learning models including recurrent neural network, three univariant models of long short-term memory and gate recurrent unit are used to forecast the power consumption, and, solar and wind energy generation and performance comparison is done. The error metrics such as mean absolute, mean square, root mean square and mean absolute percentage values are analyzed for all models and the one with least error values is selected as the best model. Stacked long short-term memory gave best results for prediction of power consumption and solar energy-based generation with a mean absolute error of 0.017 and 0.018, root mean square error of 0.24 and 0.25 and mean absolute percentage error of 1.39 and 1.91 respectively. Similarly for wind energy-based generation recurrent neural network turned out to be the best model with mean absolute error of 0.072, root mean square error of 0.38 and mean absolute percentage error of 2.68. For this work Pennsylvania-New Jersey-Maryland interconnection hourly power consumption dataset, solar power generation data and wind generation data from international renewable energy agency and entsoe dataset were used for training and testing of the models.",S. Thejus; S. P,Deep learning;Demand side management;Forecast accuracy metrics;Gated neural network;Long short-term memory;Recurrent neural network;Renewable energy,2021,deep learning based power consumption and generation forecasting for demand side management,1
554,Estimating Energy Impact of Software Releases and Deployment Strategies: The KPMG Case Study,978-1-5090-4039-1,10.1109/ESEM.2017.39,2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170112,"Background. Often motivated by optimization objectives, software products are characterized by different subsequent releases and deployed through different strategies. The impact of these two aspects of software on energy consumption has still to be completely understood and can be improved by carrying out ad-hoc analyses for specific software products. Aims. In this research we report on an industrial collaboration aiming at assessing the different impact that releases and deployment strategies of a software product can have on the energy consumption of its underlying hardware infrastructure. Method. We designed and performed an empirical experiment in a controlled environment. Deployment strategies, releases and use case scenarios of an industrial third-party software product were adopted as experimental factors. The use case scenarios were used as a blocking factor and adopted to dynamically load-test the software product. Power consumption and execution time were selected as response variables to measure the energy consumption. Results. We observed that both deployment strategies and software releases significantly influence the energy consumption of the hardware infrastructure. A strong interaction between the two factors was identified. The impact of such interaction highly varied depending on which use case scenario was considered, making the identification of the most frequently adopted use case scenario critical for energy optimisation. The collaboration between industry and academia has been productive for both parties, even if some practitioners manifested low interest/awareness on software energy efficiency. Conclusions. For the software product considered there is no absolute preferable release or deployment strategy with respect to energy efficiency, as the interaction of these factors has to be considered. The number of machines involved in a software deployment strategy does not simply constitute an additive effect of the energy consumption of the underlying hardware infrastructure.",R. Verdecchia; G. Procaccianti; I. Malavolta; P. Lago; J. Koedijk,Energy;Software Releases;Deployment,2017,estimating energy impact of software releases and deployment strategies the kpmg case study,1
555,Energy awareness through software optimisation as a performance estimate case study of the MC68HC908GP32 microcontroller,0-7695-2045-6,10.1109/MTV.2003.1250271,Proceedings. 4th International Workshop on Microprocessor Test and Verification - Common Challenges and Solutions,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1250271,"We treat the topic of the energy consumption for a typical controller involved in smart sensor applications. Since in practice a common situation involves using off-the-shelf processors, in our case a Motorola HC908 family microcontroller, we concentrate on techniques leading to an optimisation at software level for low power requirements. The aim we envisage is to lower the energy consumption by means of due instruction selection and reordering, cycle and branch optimisation, and memory use such that without changing the original task a program performs, the energy consumed while executing it should decrease.",J. Oliver; O. Mocanu; C. Ferrer,,2003,energy awareness through software optimisation as a performance estimate case study of the mc hc gp microcontroller,1
556,Detecting Presence From a WiFi Router’s Electric Power Consumption by Machine Learning,,10.1109/ACCESS.2018.2797881,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269255,"Presence and occupancy detection in residential and office environments is used to predict movement of people, detect intruders, and manage electric power consumption. Specifically, we are developing methods to improve demand side electrical power management by reducing electrical power waste in unoccupied spaces. In this paper, we conduct an extensive analysis on the applicability of using a WiFi router's electrical power consumption in different types of environments to determinate the number or people present in a space. We show the importance of a moving average filter for electrical load time series data, confirm the correlation between control packets and increased minimal router power consumption, and present our results on the accuracy of our approach. We conclude that a WiFi router's power consumption can improve presence detection in home environments and occupancy estimation in office environments, and where possible, should be analysed separately from the aggregated power consumption.",T. Petrovic; K. Echigo; H. Morikawa,Power system management;sensor systems and applications;machine learning,2018,detecting presence from a wifi router s electric power consumption by machine learning,1
557,Machine Learning and Analytical Power Consumption Models for 5G Base Stations,,10.1109/MCOM.001.2200023,IEEE Communications Magazine,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928089,"The energy consumption of the fifth generation (5G) of mobile networks is one of the major concerns of the telecom industry. However, there is not currently an accurate and tractable approach to evaluate 5G base stations' (BSs') power consumption. In this article, we propose a novel model for a realistic characterization of the power consumption of 5G multi-carrier BSs, which builds on a large data collection campaign. At first, we define a machine learning architecture that allows modeling multiple 5G BS products. Then we exploit the knowledge gathered by this framework to derive a realistic and analytically tractable power consumption model, which can help driving both theoretical analyses as well as feature standardization, development, and optimization frameworks. Notably, we demonstrate that this model has high precision, and it is able to capture the benefits of energy saving mechanisms. We believe this analytical model represents a fundamental tool for understanding 5G BSs' power consumption and accurately optimizing the network energy efficiency.",N. Piovesan; D. López-Pérez; A. De Domenico; X. Geng; H. Bao; M. Debbah,,2022,machine learning and analytical power consumption models for g base stations,1
558,Integration of Massive MIMO and Machine Learning in the Present and Future of Power Consumption in Wireless Networks: A Review,978-1-6654-9739-8,10.1109/RTSI55261.2022.9905123,2022 IEEE 7th Forum on Research and Technologies for Society and Industry Innovation (RTSI),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9905123,"The steady increase in data traffic rates and systems’ complexity have contributed to the information and communication technologies (ICT) sector’s increased energy consumption and CO2 emissions. These pose a significant challenge to the telecommunication industry and the environment. This challenge has necessitated considering energy efficiency as a critical design pillar in 5G and future wireless networks. As a result, current research efforts for future wireless networks focus on minimising energy usage and improving efficiency. This work investigates several energy optimisation techniques in the present and future wireless networks, their contributions, advantages, and limitations. Based on the review of different techniques, we discuss the architecture of the massive MIMO (mMIMO) technique, including its operation and requirements. We also present the performance evaluation of mMIMO using different precoding algorithms, which is crucial for energy efficiency in future wireless networks. We further review incorporating intelligence using a Machine Learning (ML) approach in switching off underused mMIMO arrays to minimise energy usage. Finally, we discuss several critical open research issues in mMIMO and ML that make future research and implementation possible in next-generation wireless networks.",S. E. Nwachukwu; M. Chepkoech; A. A. Lysko; K. Awodele; J. Mwangama; C. R. Burger,Multiple Input Multiple Output;MIMO;massive MIMO;mMIMO;Advanced Sleeping Mode;ASMs;ML;Small Cells;5G;energy efficiency;power consumption;energy optimisation,2022,integration of massive mimo and machine learning in the present and future of power consumption in wireless networks a review,1
560,Machine Learning Model for Frailty Detectxion using Electric Power Consumption Data from Smart Meter,978-1-6654-2099-0,10.1109/DSAA53316.2021.9564127,2021 IEEE 8th International Conference on Data Science and Advanced Analytics (DSAA),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564127,"With the increase of the number of the elderly, healthcare systems to support the daily life and wellbeing of the elderly attracted attention. Especially, frailty syndrome is one of the most significant challenges faced by many countries because of its high association with mortality and hospitalization. Recently, with the progress of ICT (Information and Communication Technology), many frailty detection models which use sensors were proposed. However, many of them require very high costs caused by the installation and management of sensors. Therefore, the objective of this study is to propose a machine learning-based frailty detection model using only electric power consumption data from smart meter, which uses no other devices such as sensors. Also, we examined the feasibility of our model through a case study, in which we have conducted on 24 elderly people. As a result of a cast study, we could detect frailty with 82% accuracy, 77% precision, 84% recall, and 80% f-score for a 2-class classification problem (frailty or non-frailty). The results of our study show that more elderly people can receive frailty diagnoses through smart meters. Moreover, since frailty is a reversible condition that could be restored to a healthy status with early and appropriate intervention, our model has potential to extend the healthy expectancy of the elderly.",K. Kim; S. Ohsugi; N. Koshizuka,Smart City;Healthcare;Smart Meter;Frailty;Machine Learning,2021,machine learning model for frailty detectxion using electric power consumption data from smart meter,1
561,A neural networks based approach for the real-time scheduling of reconfigurable embedded systems with minimization of power consumption,978-1-5090-0806-3,10.1109/ICIS.2016.7550777,2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550777,"While most embedded systems are designed for real-time applications, they suffer from resource constraints. Many techniques have been proposed for real-time task scheduling to reduce energy consumption. A combination of Dynamic Voltage Scaling (DVS) and feedback scheduling can be used to scale dynamically the frequency by adjusting the operating voltage, and to improve the run-time reliability of embedded systems. We present in this paper a novel hybrid contribution that handles real-time scheduling of embedded systems and low power consumption based on the combination of DVS and Neural Feedback Scheduling NFS with the priority-energy earliest-deadline-first (PEDF) algorithm.",G. Rehaiem; H. Gharsellaoui; S. Ben Ahmed,Optimization;Neural Networks;Real-Time Scheduling;Low-Power Consumption,2016,a neural networks based approach for the real time scheduling of reconfigurable embedded systems with minimization of power consumption,1
562,Enhancing Adversarial Attacks on Single-Layer NVM Crossbar-Based Neural Networks with Power Consumption Information,978-1-6654-5985-3,10.1109/SOCC56010.2022.9908114,2022 IEEE 35th International System-on-Chip Conference (SOCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9908114,"Adversarial attacks on state-of-the-art machine learning models pose a significant threat to the safety and security of mission-critical autonomous systems. This paper considers the additional vulnerability of machine learning models when attackers can measure the power consumption of their underlying hardware platform. In particular, we explore the utility of power consumption information for adversarial attacks on non-volatile memory crossbar-based single-layer neural networks. Our results from experiments with MNIST and CIFAR-10 datasets show that power consumption can reveal important information about the neural network’s weight matrix, such as the 1-norm of its columns. That information can be used to infer the sensitivity of the network’s loss with respect to different inputs. We also find that surrogate-based black box attacks that utilize crossbar power information can lead to improved attack efficiency.",C. Merkel,,2022,enhancing adversarial attacks on single layer nvm crossbar based neural networks with power consumption information,1
563,Hardware loads and power consumption in cloud computing environments,978-1-4673-4569-9,10.1109/ICIT.2013.6505859,2013 IEEE International Conference on Industrial Technology (ICIT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505859,This paper describes an optimised and novel approach to an Autonomous Virtual Server Management System in a `Cloud Computing' environment and it presents a set of preliminary test results. One key advantage of this system is its ability to improve hardware power consumption through autonomously moving virtual servers around a network to balance out hardware loads. This has a potentially important impact on issues of sustainability with respect to both energy efficiency and economic viability. Another key advantage is the improvement of the overall end-user experience for services within the Cloud. This has been investigated through the configuration of a cloud-computing test-bed rig. The key features of this rig and some predictions of what may be achieved with it are described and evaluated.,R. I. Dinita; G. Wilson; A. Winckles; M. Cirstea; A. Jones,,2013,hardware loads and power consumption in cloud computing environments,1
564,The Impact of Vectorization on Erasure Code Computing in Cloud Storages - A Performance and Power Consumption Study,978-1-4673-7287-9,10.1109/CLOUD.2015.108,2015 IEEE 8th International Conference on Cloud Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214118,"Erasure code storage systems are becoming popular choices for cloud storage systems due to cost-effective storage space saving schemes and higher fault-resilience capabilities. Both erasure code encoding and decoding procedures are involving heavy array, matrix, and table-lookup compute intensive operations. Multi-core, many-core, and streaming SIMD extension are implemented in modern CPU designs. In this paper, we study the power consumption and energy efficiency of erasure code computing using traditional Intel x86 platform and Intel Streaming SIMD extension platform. We use a breakdown power consumption analysis approach and conduct power studies of erasure code encoding process on various storage devices. We present the impact of various storage devices on erasure code based storage systems in terms of processing time, power utilization, and energy cost. Finally we conclude our studies and demonstrate the Intel x86's Streaming SIMD extensions computing is a cost-effective and favorable choice for future power efficient HPC cloud storage systems.",H. -B. Chen; G. Grider; J. Inman; Parks; Fields; J. A. Kuehn,Erasure code;Vectorization;Power measurement;Energy cost;Power consumption;SIMD;Cloud storage,2015,the impact of vectorization on erasure code computing in cloud storages a performance and power consumption study,1
565,Using Neural Network for the Evaluation of Power Consumption of Instructions Execution,978-1-4244-1540-3,10.1109/IMTC.2008.4547122,2008 IEEE Instrumentation and Measurement Technology Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4547122,"In this work a method is being proposed for estimating the power consumption of digital processing systems by the use of neural networks. The case study is an ARM7TDMI processor. Real hardware data are already known for this processor and provided for neural network training. Many different attempts for training have been made, by combining different sets of training vectors to the neural network and initial results have been extracted. Results indicate that the proposed approach is good for power consumption estimation, and with a proper selection of training vectors, the neural network can provide results with increased accuracy.",A. Borovyi; V. Konstantakos; V. Kochan; V. Turchenko; A. Sachenko; T. Laopoulos,Power consumption estimation;neural networks;ARM7TDMI,2008,using neural network for the evaluation of power consumption of instructions execution,1
566,A framework for computing power consumption scheduling functions under uncertainty,978-1-4673-8289-2,10.1109/SmartGridComm.2015.7436277,2015 IEEE International Conference on Smart Grid Communications (SmartGridComm),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436277,"One of the goals of this paper is to make a step further towards knowing how an electrical appliance should exploit the available information to schedule its power consumption; mainly, this information corresponds here to an imperfect forecast of the non-controllable (exogenous) load or electricity price. Reaching this goal led us to three key results which can be used for other settings which involve multiple agents with partial information: 1. In terms of modeling, we exploit the principal component analysis to approximate the exogenous load and show its full relevance; 2. Under some reasonable but improvable assumptions, this work provides a full characterization of the set of feasible payoffs which can be reached by a set of appliances having partial information; 3. A distributed algorithm is provided to compute good power consumption scheduling functions. These results are exploited in the numerical analysis, which provides several new insights into the power consumption scheduling problem. We provide first results for the standard cost functions, transformer aging in particular, where we compare our method with iterative water filling algorithm (IWFA). We test our proposed algorithm on real data and show that it is more robust with respect to noise in the signals received. We also observe that our proposed method becomes even more relevant when the proportion of appliances with smart counters increase.",O. Beaude; A. Agrawal; S. Lasaulce,,2015,a framework for computing power consumption scheduling functions under uncertainty,1
567,Resource Management and Computing Offloading to Minimize Power Consumption Cost in Slice-MEC System,978-1-6654-5085-0,10.1109/WCSP55476.2022.10039154,2022 14th International Conference on Wireless Communications and Signal Processing (WCSP),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039154,"With the advancement of 5G technology, user demand grows, resources become scarce and differentiated services place greater requirements on performance in slice-MEC system. However, optimizing works in the vast majority of existing research focus only on slice selection, resource orchestration, utility improvement from the perspective of users, without considering whole system's power consumption cost. Firstly, to get over this dilemma, a two-tier architectural model for slice-MEC system is proposed, which is mainly divided into the slice instance layer and infrastructure layer. Next, we establish the optimization problem of minimizing weighted power consumption cost while guaranteeing requirements of delay and rate, taking into account both communication and computational resources. Moreover, to solve the problem above, the HPCA-based resource management and computing offloading algorithm is designed. Finally, simulation results show that the proposed algorithm in this paper outperforms than benchmark algorithms and we also analyse the performance of the system by varying different parameter conditions.",L. Wang; X. Yao; X. Jiang; J. Cui; B. Zheng,slice-MEC;resource management;computing offloading;power consumption cost,2022,resource management and computing offloading to minimize power consumption cost in slice mec system,1
568,Minimizing Power Consumption by Joint Radio and Computing Resource Allocation in Cloud-Ran,978-1-6654-9792-3,10.1109/ISCC55528.2022.9912943,2022 IEEE Symposium on Computers and Communications (ISCC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912943,"Cloud-RAN is a key 5G-enabler; it consists in centralizing the baseband processing of base stations by executing the baseband functions in a centralized, virtualized, and shared entity known as the Base Band Unit (BBU)-Pool. Cloud-RAN paves the way for joint management of the resources of multiple base stations. This paper aims to analyze the potential reduction in power consumption brought by the joint allocation of the radio and computing resources. We formulate a Mixed Integer Linear Programming (MILP) problem, considering the objective of power consumption minimization. For comparison, we consider the objective of throughput maximization. When the goal is power minimization, the joint allocation can minimize the total power consumption by up to 21.2%, with respect to the case where radio and computing resources in the BBU pool are allocated sequentially.",M. Sharara; S. Hoteit; V. Vèque; F. Bassi,Cloud-RAN;5G;Joint Resource Allocation;Power Minimization,2022,minimizing power consumption by joint radio and computing resource allocation in cloud ran,1
570,Producing Green Computing Images to Optimize Power Consumption in OLED-Based Displays,978-1-7281-2607-4,10.1109/COMPSAC.2019.00081,2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754088,"Energy consumption in Organic Light Emitting Diode (OLED) depends on the displayed contents. The power consumed by an OLED-based display is directly proportional to the luminance of the image pixels. In this paper, a novel idea is proposed to generate energy-efficient images, which consume less power when shown on an OLED-based display. The Blue color component of an image pixel is the most power-hungry i.e. it consumes more power as compared to the Red and Green color components. The main idea is to reduce the intensity of the blue color to the best possible level so that the overall power consumption is reduced while maintaining the perceptual quality of an image. The idea is inspired by the famous ""Land Effect"", which demonstrates that it is possible to generate a full-color image by using only two color components instead of three. experiments are performed on the Kodak image database. The results show that the proposed method is able to reduce the power consumption by 18% on average and the modified images do not lose the perceptual quality. Social media platform, where users scroll over many images, is an ideal application for the proposed method since it will greatly reduce the power consumption in mobile phones during surfing social networking applications.",S. Asnani; M. G. Canu; B. Montrucchio,"OLED Display, Green Computing, Energy Efficient Images, Social Media, Land-Effect, Retinex Filter",2019,producing green computing images to optimize power consumption in oled based displays,1
572,Software management of power consumption in WSN based on duty cycle algorithms,978-1-4673-2232-4,10.1109/EUROCON.2013.6625014,Eurocon 2013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6625014,"In battery-operated nodes of a wireless sensor network, energy is a scarce resource that should not be wasted. During the recent years, energy efficient algorithms and protocols to maximize network lifetime have attracted the attention of many researchers. As the radio transceiver is one of the elements of the node that has higher power consumption, a typical approach to save energy is to minimize the period of time it is active. That can be achieved by introducing a duty cycle in which the node periodically enables its radio for a short time to later return to an idle state. In this paper, we discuss the importance of the duty cycle window size and present an expression to determine it according to the particularities of the IEEE 802.15.4 specification. But, to obtain a more accurate expression, we show that it is necessary to consider the characteristics of a noisy channel, especially in industrial applications, where interferences cannot be underestimated. The proposed technique tries to minimize electromagnetic pollution in order not to disturb the normal operation of other radio devices in the environment. The results of a real implementation are also presented and its efficiency discussed in terms of boundary conditions.",M. López; J. Sabater; M. Daemitabalvandani; J. Sabater; J. M. Gómez; M. Carmona; A. Herms,Wireless Sensor Networks;Energy saving;Duty Cycle;Software management,2013,software management of power consumption in wsn based on duty cycle algorithms,1
573,Characterizing power consumption and delay of functional/library components for hardware/software co-design of embedded systems,0-7695-2159-2,10.1109/IWRSP.2004.1311094,"Proceedings. 15th IEEE International Workshop on Rapid System Prototyping, 2004.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311094,"This article introduces a library of pre-characterized components to support hardware/software co-design of real-time embedded systems starting from high abstraction levels, e.g. formal description techniques. The library includes hardware components of different types and granularity modelled for power consumption, delay and area. Software components are also modelled. These software components range from the basic instructions set of a processor to a set of optimized library functions and IP cores used in the areas of DSP and image processing. Design tradeoffs enabled by the presence of different types of the same component can be efficiently utilized by the co-synthesis process. The co-synthesis process is refined in this article by an allocation-refinement step for this purpose.",A. Mohsen; R. Hofmann,,2004,characterizing power consumption and delay of functional library components for hardware software co design of embedded systems,1
574,"On the Power Consumption of Massive-MIMO, 5G New Radio with Software-Based PHY Processing",978-1-6654-5975-4,10.1109/GCWkshps56602.2022.10008564,2022 IEEE Globecom Workshops (GC Wkshps),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008564,"The general tendency to deliver Open Radio Access Network (Open-RAN) solutions by means of software-based, or even cloud-native, realizations drives the development community to fully capitalize on software architectures, even for the computationally demanding 5G physical layer (PHY) processing. However, software solutions are typically orders of magnitude less efficient than dedicated hardware in terms of power consumption and processing speed. Consequently, realizing highly-efficient, massive multiple-input multiple-output (mMIMO) solutions in software, while exploiting the wide 5G transmission bandwidths, becomes extremely challenging and requires the massive parallelization of the PHY processing tasks. In this work, for the first time, we show that massively parallel software solutions are capable of meeting the processing requirements of 5G New Radio (NR), still, with a significant increase in the corresponding power consumption. In this context, we quantify this power consumption overhead, both in terms of Watts and carbon emissions, as a function of the concurrently transmitted information streams, of the base-station antennas, and of the utilized bandwidth. We show that the computational power consumption of such PHY processing is no longer negligible and that, for mMIMO solutions supporting a large number of information streams, it can become comparable to the power consumption of the Radio Frequency (RF) chains. Finally, we discuss how a shift towards non-linear PHY processing can significantly boost energy efficiency, and we further highlight the importance of energy-aware digital signal processing design in future PHY processing architectures.",G. N. Katsaros; R. Tafazolli; K. Nikitopoulos,power efficiency;software-based 5G NR;Open RAN;massive MIMO,2022,on the power consumption of massive mimo g new radio with software based phy processing,1
575,Machine Learning-Based Approaches for Energy-Efficiency Prediction and Scheduling in Composite Cores Architectures,978-1-5386-2254-4,10.1109/ICCD.2017.28,2017 IEEE International Conference on Computer Design (ICCD),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119201,"Heterogeneous architectures offer divers computing capabilities. Composite Cores Architecture (CCA) is a class of dynamic heterogeneous architectures that empowers the system to build the most appropriate core at run-time for each application by composing cores together to make larger core or decomposing a large core into multiple smaller cores. While CCA provides more flexibility for the running application to find the best run-time configurations to maximize energy-efficiency, due to the interdependence of various tuning parameters such as the core type, run-time voltage and frequency setting, and number of threads, it makes the scheduling more challenging. In this work, we investigate the scheduling challenges of multithreaded applications on CCA architectures. This paper describes a systematic approach to predict the right configurations for running multithreaded workloads on the composite cores architecture. It achieves this by developing a machine learning-based approach to predict core type, voltage and frequency to maximize the energy-efficiency. Our predictor learns offline from an extensive set of training multithreaded workloads. It is then applied to predict the optimal processor configuration at run-time by considering of the multithreaded application's characteristics and the optimization objective. For this purpose, five well-known machine learning models are implemented for energy-efficiency optimization and precisely compared in terms of accuracy and hardware overhead to guide the scheduling decisions in a CCA. The results show that while complex machine learning models such as MultiLayerPerceptron are achieving higher accuracy, after evaluating their implementation overheads, they perform worst in terms of power, accuracy/area and latency as compared to simpler but slightly less accurate regression-based and tree-based classifiers.",H. Sayadi; N. Patel; A. Sasan; H. Homayoun,energy-efficiency;heterogeneous architecture;composite cores;scheduling;machine learning,2017,machine learning based approaches for energy efficiency prediction and scheduling in composite cores architectures,1
577,Machine Learning for Energy Load Prediction and its Interpretation,978-1-6654-5656-2,10.1109/IS57118.2022.10019658,2022 IEEE 11th International Conference on Intelligent Systems (IS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10019658,"This paper refers to real-life data on energy consumption from three companies, connected to a medium voltage grid. The companies use single-, two-, or three-zone tariffs and the general characteristic of their activity is comparable. The input dataset contains hourly electricity consumption recorded from January 2020 to December 2020. The independent variables used for the study include weather, time-dependent factors, and aggregated energy factors. We perform the prediction of consumption using three methods: naive, multiple regression, and extreme gradient boosting regression. The performance of the methods is compared based on the MSE, RMSE, MAE, and MAPE metrics. The study shows that the scores achieved for the extreme gradient boosting method are higher than for the multiple regression. To gain the interpretability of the energy load forecasting and feature analysis the Shapley additive explanations method is used for the best model. As a result, a ranking of the most important factors is created. It shows the importance of aggregated energy factors and weather conditions while placing daylight and season at the bottom of the ranking.",M. Charytanowicz; A. Olwert; W. Radziszewska; J. Jarnicka; K. Gajowniczek; T. Ząbkowski; J. Brożyna; G. Mentel; G. Matejko,machine learning;regression model;Shapley additive explanations;electricity load forecasting;gradient boosting;feature evaluation,2022,machine learning for energy load prediction and its interpretation,1
578,"Toward energy-efficient cloud computing: Prediction, consolidation, and overcommitment",,10.1109/MNET.2015.7064904,IEEE Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064904,"Energy consumption has become a significant concern for cloud service providers due to financial as well as environmental factors. As a result, cloud service providers are seeking innovative ways that allow them to reduce the amount of energy that their data centers consume. They are calling for the development of new energy-efficient techniques that are suitable for their data centers. The services offered by the cloud computing paradigm have unique characteristics that distinguish them from traditional services, giving rise to new design challenges as well as opportunities when it comes to developing energy-aware resource allocation techniques for cloud computing data centers. In this article we highlight key resource allocation challenges, and present some potential solutions to reduce cloud data center energy consumption. Special focus is given to power management techniques that exploit the virtualization technology to save energy. Several experiments, based on real traces from a Google cluster, are also presented to support some of the claims we make in this article.",M. Dabbagh; B. Hamdaoui; M. Guizani; A. Rayes,,2015,toward energy efficient cloud computing prediction consolidation and overcommitment,1
581,Energy-Efficient Task Distribution Using Neural Network Temperature Prediction in a Data Center,978-1-7281-2927-3,10.1109/INDIN41052.2019.8972035,2019 IEEE 17th International Conference on Industrial Informatics (INDIN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972035,"The growing demand for computing resources leads to a serious problem of excessive energy consumption in data centers. In recent studies, energy consumption of both computing and cooling equipment is drawing attention. For improving the energy efficiency of cooling equipment such as computer room air conditioners (CRACs), it is neccesary to predict temperatures in data centers and to optimize thermal management in data centers. In this study, we propose a temperature prediction method for servers in a data center using a neural network. We used the prediction result for distributing task targeting temperature-based load balancing. First, we conducted an experiment in a real data center to evaluate the prediction accuracy of the proposed method. We then simulated task distribution based on the predicted temperatures and compared the maximum CPU temperature with a non-predictive approach. The results indicated that the proposed method can reduce future CPU temperatures successfully compared to the non-predictive approach, though in exchange for high computational cost.",M. Omori; Y. Nakajo; M. Yoda; Y. Joshi; H. Nishi,data center;load balancing;neural network;temperature prediction;thermal management,2019,energy efficient task distribution using neural network temperature prediction in a data center,1
582,Combined Prediction Energy Model at Software Architecture Level,,10.1109/ACCESS.2020.3041442,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274401,"Accurate prediction of software energy consumption is of great significance for the sustainable development of the environment. In order to overcome the limitations of a single prediction method and further improve the prediction accuracy, a combined prediction energy model of adaboost algorithm and RBF (radial basis function) neural network at software architecture level is proposed. Firstly, three kinds of energy prediction models are established by polynomial regression, support vector machine and neural network respectively. Secondly, the RBF neural network is used to nonlinear combine the predicted values of the above three models. Finally, RBF integrated by adaboost algorithm is used as high-precision prediction of energy consumption. Experimental results show that the prediction accuracy of the combined prediction model is higher than that of the single model.",J. Li; K. Liu; M. Li; D. Li,Green computing;energy consumption prediction;Adaboost algorithm;RBF neural network;combined prediction model,2020,combined prediction energy model at software architecture level,1
583,Workload prediction for adaptive power scaling using deep learning,978-1-4799-2153-9,10.1109/ICICDT.2014.6838580,2014 IEEE International Conference on IC Design & Technology,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838580,"We apply hierarchical sparse coding, a form of deep learning, to model user-driven workloads based on on-chip hardware performance counters. We then predict periods of low instruction throughput, during which frequency and voltage can be scaled to reclaim power. Using a multi-layer coding structure, our method progressively codes counter values in terms of a few prominent features learned from data, and passes them to a Support Vector Machine (SVM) classifier where they act as signatures for predicting future workload states. We show that prediction accuracy and look-ahead range improve significantly over linear regression modeling, giving more time to adjust power management settings. Our method relies on learning and feature extraction algorithms that can discover and exploit hidden statistical invariances specific to workloads. We argue that, in addition to achieving superior prediction performance, our method is fast enough for practical use. To our knowledge, we are the first to use deep learning at the instruction level for workload prediction and on-chip power adaptation.",S. J. Tarsa; A. P. Kumar; H. T. Kung,,2014,workload prediction for adaptive power scaling using deep learning,1
584,Machine Learning Based Uplink Transmission Power Prediction for LTE and Upcoming 5G Networks Using Passive Downlink Indicators,978-1-5386-6358-5,10.1109/VTCFall.2018.8690629,2018 IEEE 88th Vehicular Technology Conference (VTC-Fall),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8690629,"Energy-aware system design is an important optimization task for static and mobile Internet of Things (IoT)-based sensor nodes, especially for highly resource-constrained vehicles such as mobile robotic systems. For 4G/5G-based cellular communication systems, the effective transmission power of uplink data transmissions is of crucial importance for the overall system power consumption. Unfortunately, this information is usually hidden within off-the-shelf modems and mobile handsets and can therefore not be exploited for enabling green communication. Moreover, the dynamic transmission power control behavior of the mobile device is not even explicitly modeled in most of the established simulation frameworks. In this paper, we present a novel machine learning-based approach for forecasting the resulting uplink transmission power used for data transmissions based on the available passive network quality indicators and application-level information. The model is derived from comprehensive field measurements of drive tests performed in a public cellular network and can be parameterized for integrating all measurements a given target platform is able to provide into the prediction process. In a comparison of three different machine learning methods, Random-Forest models thoroughly performed best with a mean average error of 3.166 dB. As the absolute sum of errors converges towards zero and falls below 1 dB after 28 predictions in average, the approach is well-suited for long-term power estimations.",R. Falkenberg; B. Sliwa; N. Piatkowski; C. Wietfeld,,2018,machine learning based uplink transmission power prediction for lte and upcoming g networks using passive downlink indicators,1
585,Machine Learning-based Prediction of Test Power,978-1-7281-1173-5,10.1109/ETS.2019.8791548,2019 IEEE European Test Symposium (ETS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791548,"With the increase in circuit complexity, the gap between circuit development time and analysis time has widened. A large database is required in order to perform essential analysis tasks such as power, thermal, and IR-drop analysis, which, in turn, leads to long run times. This work focuses on test power analysis. Due to the large number of test patterns for modern designs and the excessive power analysis run time for each test, it is not feasible to obtain complete power profiles for all the tests. However, test power-safety is essential to produce reliable manufacturing test results and prevent yield loss and chip damage. Accurate power profiling can typically be done for a small subset of pre-selected tests only. An essential task is therefore to determine those tests, which potentially provide the worst-case scenarios with respect to test power. We propose machine learning-based power prediction for test selection. The prediction is applied in two different ways. First, we predict the activity of a test to identify tests with high power consumption. Second, the switching activity and the power information are related to the layout of the chip to identify local hot spots. Various machine learning-based algorithms are used to evaluate this approach. Additionally, the algorithms are compared against each other. The results indicate high prediction accuracy and effectiveness. This makes these algorithms well suited for worst-case test selection.",H. Dhotre; S. Eggersglüß; K. Chakrabarty; R. Drechsler,,2019,machine learning based prediction of test power,1
588,Power Prediction in Register Files Using Machine Learning,,10.1109/ACCESS.2022.3172287,IEEE Access,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766373,"The advent of computer architecture and processor design in recent years has brought about the need to design larger register files that can hold more instructions and operands to support faster processors. This encouraged designers to design wider and deeper register files with multiple read and write ports to increase their throughput. Nevertheless, larger register files consume higher energy/access, leak more power, and occupy larger areas on the chip. This portrays a significant issue in the field of chip design due to the limited energy resources in mobile devices that dominate today’s market. Therefore, it becomes crucial for chip designers to devise new mechanisms that help them study the effect of increasing the register file capabilities on those characteristics at an early stage during the design process. Artificial Neural Network (ANN) techniques, and with a reasonable degree of success have been used to predict the energy characteristics of a register file based on three parameters: the number of words in the file (D), the number of bits in one word (W) and the total number of Read and Write Ports (P). In this work, and using the same attributes, we attempt to predict the values of energy/access, leakage power, and occupied silicon area in register files using several machine learning algorithms to assess design alternatives and their energy and area tradeoffs. We compare our best algorithm to the ANN-based model reported in the literature using the same dataset. Support Vector Machine (SVM) models were able to achieve a correlation coefficient of 0.991, 0.991, and 0.989 when predicting energy/access, leakage power, and silicon area, respectively. On the other hand, the designed artificial neural network (ANN) achieves correlation coefficients of 0.974, 0.982, and 0.987, while the closest algorithms in performance to SVM achieve 0.917, 0.980, and 0.987, respectively. The results of the conducted experiments prove that SVM produce superior results when compared to ANN and other algorithms while maintaining a reasonable model training time and consuming lesser computational resources in most cases.",M. Elnawawy; A. Sagahyroon; M. Pasquier,Register files;power consumption;leakage power;support vector machine,2022,power prediction in register files using machine learning,1
589,Software energy estimation based on statistical characterization of intermediate compilation code,978-1-61284-660-6,10.1109/ISLPED.2011.5993659,IEEE/ACM International Symposium on Low Power Electronics and Design,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5993659,"Early estimation of embedded software power consumption is a critical issue that can determine the quality and, sometimes, the feasibility of a system. Architecture-specific, cycle-accurate simulators are valuable tools for fine-tuning performance of critical sections of the application but are often too slow for the simulation of entire systems. This paper proposes a fast and statistically accurate methodology to evaluate the energy performance of embedded software and describes the associated toolchain. The methodology is based on a static characterization of the target instruction set to allow estimation on an equivalent, target-independent intermediate code representation.",C. Brandolese; S. Corbetta; W. Fornaciari,,2011,software energy estimation based on statistical characterization of intermediate compilation code,1
590,Power-aware MPI task aggregation prediction for high-end computing systems,978-1-4244-6443-2,10.1109/IPDPS.2010.5470464,2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470464,"Emerging large-scale systems have many nodes with several processors per node and multiple cores per processor. These systems require effective task distribution between cores, processors and nodes to achieve high levels of performance and utilization. Current scheduling strategies distribute tasks between cores according to a count of available cores, b ut ignore the execution time and energy implications of task aggregation (i.e., grouping multiple tasks within the same node or the same multicore processor). Task aggregation can save significant energy while sustaining or even improving performance. However, choosing an effective task aggregation becomes more difficult as the core count and the options available for task placement increase. We present a framework to predict the performance effect of task aggregation in both computation and communication phases and its impact in terms of execution time and energy of MPI programs. Our results for the N PB 3.2 MPI benchmark suite show that our framework provides accurate predictions leading to substantial energy saving through aggregation (64.87% on average and up to 70.03 %) with tolerable performance loss (under 5%).",D. Li; D. S. Nikolopoulos; K. Cameron; B. R. de Supinski; M. Schulz,MPI;performance modeling;power-aware highperformance computing,2010,power aware mpi task aggregation prediction for high end computing systems,1
591,Comparison of Recurrent Neural Network Model for Future Electric Power Prediction,978-1-6654-6941-8,10.1109/I-SMAC55078.2022.9986504,"2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986504,"The increasing demand for electricity can be directly attributed to the exponential rise in both the global population and the sophistication of modern technologies. Because electric power is utilized simultaneously with its generation at the power station, it is crucial to precisely anticipate electric power consumption in advance to ensure a reliable power supply. Estimating future electricity needs is critical to the success of any electricity provider. Having accurate predictions of electricity use has several practical and financial benefits, including ensuring the security and stability of the power grid. This research employs a Recurrent Neural Network (RNN) model based on a Long Short-Term Memory (LSTM) network to anticipate electricity usage, aiming to resolve the discrepancy between the need for precise prediction and the limitations of conventional methods. The model incorporates conventional LSTM and hybrid Convolutional Neural Networks and Long Short-Term Memory (CNN-LSTM). First, we’ll examine the Kaggle data we collected on electricity consumption. Second, we utilize an RNN model to forecast future power consumption as a whole. Finally, we will utilize loss and Mean Square Error (MSE) to qualitatively and statistically assess the performance of the model. According to the research conducted in the experiments, the CNN-LSTM prediction model outperforms traditional LSTM models in terms of reliable prediction.",S. Balasubramaniyan; P. Duraipandy; N. Kalyani; P. Shanmugaraja; D. Shobana; M. Vimala,Electricity;Data Cleaning;RNN model;Time series data;Loss;Forecast,2022,comparison of recurrent neural network model for future electric power prediction,1
592,ML-based Power Estimation of Convolutional Neural Networks on GPGPUs,978-1-6654-9431-1,10.1109/DDECS54261.2022.9770153,2022 25th International Symposium on Design and Diagnostics of Electronic Circuits and Systems (DDECS),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770153,"The increasing application of Machine Learning (ML) techniques on the Internet of Things (IoTs) has led to the leverage of ML accelerators like General Purpose Computing on Graphics Processing Units (GPGPUs) in such devices. However, selecting the most appropriate accelerator for IoT devices is very challenging as they commonly have tight constraints e.g., low power consumption, latency, and cost of the final product. Hence, the design of such application-specific IoT devices becomes a time-consuming and effort-hungry process, that poses the need for accurate and effective automated assisting methods.In this paper, we present a novel approach to estimate the power consumption of CUDA-based Convolutional Neural Networks (CNNs) on GPGPUs in the early design phases. The proposed approach takes advantage of a hybrid technique where static analysis is used for features extraction and the K-Nearest Neighbor (K-NN) regression analysis is utilized for power estimation model generation. Using K-NN analysis, the power estimation model can even be created with small training datasets. Experimental results demonstrate that the proposed approach is able to predict CNNs power consumption up to a Absolute Percentage Error of 0.0003% in comparison to the real hardware.",C. A. Metz; M. Goli; R. Drechsler,,2022,ml based power estimation of convolutional neural networks on gpgpus,1
593,Evaluation of approaches for power estimation in a computing cluster,978-1-4799-6177-1,10.1109/IGCC.2014.7039145,International Green Computing Conference,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039145,"Data centers as a cost-effective infrastructure for hosting Cloud and Grid applications incur tremendous energy cost and C02 emissions in terms of power distribution and cooling. One of the effective approaches for saving energy in a cluster environment is workload consolidation. However, it is challenging to address this schedule problem as it requires the understanding of various cost factors. One of the important factors is the estimation of power consumption. Power models used in most of workload schedule solutions are a linear function of resource features, but we analysed the measurement data from our cluster and found the resource loads, in particular I/O load, had no convincing linear-correlation with power consumption. Based on measurement data sets from our cluster, we propose multiple non-linear machine learning approaches to estimate power consumption of an entire node using OS-reported resource features. We evaluate the accuracy, portability and usability of the linear and non-linear approaches. Our work shows the multiple-variable linear regression approach is more precise than the CPU only linear approach. The neural network approaches have a slight advantage - its mean root mean square error is at most 15% less than that of the multiple-variable linear approach. But the neural network models have worse portability when the models generated on a node are applied on its homogeneous nodes. Gaussian Mixture Model has the highest accuracy on Hadoop nodes but requires the longest training time.",H. Zhu; P. Grosso; X. Liao; C. de Laat,Power Model;Workload Characterization;Energy Monitoring;Machine learning,2014,evaluation of approaches for power estimation in a computing cluster,1
594,Using complete machine simulation for software power estimation: the SoftWatt approach,0-7695-1525-8,10.1109/HPCA.2002.995705,Proceedings Eighth International Symposium on High Performance Computer Architecture,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995705,"Power dissipation has become one of the most critical factors for the continued development of both high-end and low-end computer systems. We present a complete system power simulator, called SoftWatt, that models the CPU, memory hierarchy, and a low-power disk subsystem and quantifies the power behavior of both the application and operating system. This tool, built on top of the SimOS infrastructure, uses validated analytical energy models to identify the power hotspots in the system components, capture relative contributions of the user and kernel code to the system power profile, identify the power-hungry operating system services and characterize the variance in kernel power profile with respect to workload. Our results using Spec JVM98 benchmark suite emphasize the importance of complete system simulation to understand the power impact of architecture and operating system on application execution.",S. Gurumurthi; A. Sivasubramaniam; M. J. Irwin; N. Vijaykrishnan; M. Kandemir,,2002,using complete machine simulation for software power estimation the softwatt approach,1
595,Power and performance analysis of motion estimation based on hardware and software realizations,,10.1109/TC.2005.102,IEEE Transactions on Computers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1461359,"Motion estimation is the most computationally expensive task in MPEG-style video compression. Video compression is starting to be widely used in battery-powered terminals, but surprisingly little is known about the power consumption of modern motion estimation algorithms. This paper describes our effort to analyze the power and performance of realistic motion estimation algorithms in both hardware and software realizations. For custom hardware realizations, this paper presents a general model of VLSI motion estimation architectures. This model allows us to analyze in detail the power consumption of a large class of modern motion estimation engines that can execute the motion estimation algorithms of interest to us. We compare these algorithms in terms of their power consumption and performance. For software realizations, this paper provides the first detailed instruction-level simulation results on motion estimation based on a programmable CPU core. We analyzed various aspects of the selected motion estimation algorithms, such as search speed and power distribution. This paper provides a guideline to two types of machine designs for motion estimation: custom ASIC (application specific integrated circuit) design and custom ASIP (application specific instruction-set processor) designs.",S. Yang; W. Wolf; N. Vijaykrishnan,Motion estimation algorithm;power modeling;performance optimization.,2005,power and performance analysis of motion estimation based on hardware and software realizations,1
596,Tool for Automated Instruction Set Characterization for Software Power Estimation,,10.1109/TIM.2009.2021646,IEEE Transactions on Instrumentation and Measurement,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5175334,"The complexity and functionality of mobile digital devices is continuously growing. This results in a higher energy consumption of such devices. To counteract this trend, it is mandatory to accomplish software power optimizations based on accurate power consumption models characterized for the processor. This paper presents an environment for automated instruction set characterization based on physical power measurements. The generic design of this characterization system enables an easy portability to other architectures. For an accurate current measurement, a high-performance sampling technique has been established, which can be either clock or energy driven. The performance of those techniques is analyzed, and the advantages over the conventional solution of a series resistor are discussed. During the characterization of different processor platforms, it could be shown that the characterization effort can be reduced from three man-months to two man-weeks.",M. Wendt; M. Grumer; C. Steger; R. Weiss; U. Neffe; A. Muehlberger,Automated instruction set characterization;embedded processors;power-aware computing;power measurement;software power estimation;testbench generator,2010,tool for automated instruction set characterization for software power estimation,1
