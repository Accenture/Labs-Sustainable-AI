{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection phase 1: semi-automatic based on identified \"excluding words\"\n",
    "\n",
    "In this notebook, we identify excluding words, i.e.,  words and pairs of words (among the words contained in all titles) that automatically make a title containing one of them off-topic.\n",
    "\n",
    "We look for excluding words using the list of titles from the Google Scholar data source in the fisrt section of this notebook. Then, we use these exclusing words to select titles in the other two data sources: IEEE in Section 2, and ACM in Section 3.\n",
    "\n",
    "***\n",
    "\n",
    "**Importing libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usefull functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_excluding_words(words, titles_df):\n",
    "    \"\"\" To exclude any title containing any elements of the list words\"\"\"\n",
    "\n",
    "    df = titles_df.copy(deep=True)\n",
    "    for i, row in df.iterrows():\n",
    "        if df.loc[i,'keep_title'] == 1:\n",
    "            title_no_punct = \" \".join(re.findall(\"[A-Za-z]+\",df.loc[i,'title']))\n",
    "            # check if any of the 'words' is in the current title\n",
    "            res = any(ele.lower() in title_no_punct.lower().split() for ele in words)\n",
    "            if res:        \n",
    "                df.loc[i, 'keep_title']=0\n",
    "    return(df)\n",
    "\n",
    "def apply_excluding_2_words(twoWords_to_exclude, titles_df):\n",
    "    \"\"\" To exclude any title containing any elements of the list twoWords_to_exclude\"\"\"\n",
    "\n",
    "    df = titles_df.copy(deep=True)\n",
    "    _words = [\" \"+elem+\" \" for elem in twoWords_to_exclude]\n",
    "    for i, row in df.iterrows():\n",
    "        if df.loc[i,'keep_title'] == 1:\n",
    "            title_no_punct = \" \".join(re.findall(\"[A-Za-z]+\",df.loc[i,'title']))\n",
    "            title_no_punct = \" \"+title_no_punct+\" \"\n",
    "            # check if any of the 'words' is in the current title\n",
    "            res = any(ele.lower() in title_no_punct.lower() for ele in _words)\n",
    "            if res:        \n",
    "                df.loc[i, 'keep_title']=0 \n",
    "    return(df)\n",
    "\n",
    "def check_proportions(words, titles_df_new, titles_df_old):\n",
    "    \"\"\" To check that the semi-automatic selection happened as expected\"\"\"\n",
    "\n",
    "    preserved = titles_df_new[titles_df_new['keep_title'] == 1]['title']\n",
    "    removed = titles_df_new[titles_df_new['keep_title'] == 0]['title']\n",
    "    old_removed = titles_df_old[titles_df_old['keep_title'] == 0]['title']\n",
    "    print('Number of words to exclude: ', len(words))\n",
    "    print(\"Number articles removed: \", len(removed))\n",
    "    print(\"Number articles newly removed: \", len(removed) - len(old_removed))\n",
    "    print(\"Number articles preserved: \", len(preserved))\n",
    "    print(\"Check: \", len(removed)+len(preserved), '==', len(titles_df_new['title']))\n",
    "\n",
    "def make_2words_csv(titles_df):\n",
    "    \"\"\"Create csv file with the list of pairs of words contained in all the titles\"\"\"\n",
    "    \n",
    "    #source:\n",
    "    #https://stackoverflow.com/questions/18952894/word-frequency-count-based-on-two-words-using-python#:~:text=%3E%3E%3E%20from%20collections%20import%20Counter%20%3E%3E%3E%20import%20re,makes%27%3A%202%2C%20%27makes%20me%27%3A%202%2C%20%27I%20love%27%3A%202%7D\n",
    "    \n",
    "    preserved = titles_df[titles_df['keep_title'] == 1]['title']\n",
    "    sentence = \" \".join(preserved).lower()\n",
    "    words = re.findall(r'\\w+', sentence)\n",
    "    \n",
    "    two_words = [' '.join(ws) for ws in zip(words, words[1:])]\n",
    "\n",
    "    no_list = ['in', 'of', 'and', 'to', 'for', 'a', 'on', 'the', 'how', 'by', 'an', \\\n",
    "               'at', 'as', 'with', 'using', 'based', 'its', 'towards']\n",
    "    two_words_preserved = []\n",
    "    two_words_removed = []\n",
    "    for elem in two_words:\n",
    "        res = any(e in elem.split() for e in no_list)\n",
    "        if res:\n",
    "            two_words_removed.append(elem)\n",
    "        else:\n",
    "            two_words_preserved.append(elem)\n",
    "\n",
    "    wordscount = {w:f for w, f in Counter(two_words_preserved).most_common() if f > 1}\n",
    "    wordscount_df = pd.DataFrame(wordscount.items(), columns=['TwoWords', 'InstancesNumber'])\n",
    "    str_current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    file_name = \"twoWords_\"+str_current_datetime+\".csv\"\n",
    "    wordscount_df.to_csv(file_name)\n",
    "    \n",
    "def prepare_titles_df(df, my_columns, title_column):\n",
    "    titles_df = df[my_columns].rename(columns={title_column: 'original_title'})\n",
    "\n",
    "    # add columns with lower case titles with letters only\n",
    "    t_list = []\n",
    "    for title in titles_df['original_title'].str.lower():\n",
    "        t_list.append(\" \".join(re.findall(\"[A-Za-z]+\",title)))\n",
    "    titles_df = pd.concat([titles_df.copy(deep=True), pd.DataFrame(t_list, columns=[\"title\"])], axis=1)\n",
    "\n",
    "    # new column 'keep_title'\n",
    "    keep_title_df = pd.DataFrame([1 for i in range(titles_df.shape[0])], columns=['keep_title'])\n",
    "    titles_df = pd.concat([titles_df.copy(deep=True), keep_title_df], axis=1)\n",
    "    \n",
    "    return(titles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Loading the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles:  5822\n"
     ]
    }
   ],
   "source": [
    "_path_scholar_titles=\"../1_initial_search/saved_results_scholar/scholar_results.csv\"\n",
    "df = pd.DataFrame(pd.read_csv(_path_scholar_titles))\n",
    "\n",
    "my_columns = ['title', 'result_id', 'publication_info_summary', 'link']\n",
    "titles_df = prepare_titles_df(df, my_columns, 'title')\n",
    "\n",
    "# just counting the titles\n",
    "titles = [title for title in titles_df['title'].tolist()]\n",
    "titles_nb = len(titles)\n",
    "print(\"Number of titles: \", titles_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Observation titles duplicates\n",
    "\n",
    "We add the column 'count' to the dataframe title_df. This columns contains the number of times the title appears in the results.\n",
    "\n",
    "Here, we just observe what the duplicates look like. Duplicates will be remove later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dict_3 = dict(Counter(titles))\n",
    "title_counts = []\n",
    "for i, row in titles_df.iterrows():\n",
    "    title_counts.append(titles_dict_3[row['title']])\n",
    "\n",
    "count_df = pd.DataFrame(title_counts, columns=['count'])\n",
    "titles_df = pd.concat([titles_df.copy(deep=True), count_df], axis=1)\n",
    "\n",
    "dupl_titles_df = titles_df[titles_df['count'] > 1]\n",
    "dupl_titles_set = set(dupl_titles_df['title'].to_list())\n",
    "\n",
    "\n",
    "for title in dupl_titles_set:\n",
    "    title_df = titles_df[titles_df['title'] == title]\n",
    "\n",
    "    # UNCOMMENT HERE to check duplicates:\n",
    "    # print(\"------------------------------------------\")\n",
    "    # print(title)\n",
    "    # print(title_df[['result_id', 'publication_info_summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in titles_df.iterrows():\n",
    "    if row['count'] > 1:\n",
    "        # All occurences of the same title are stored in df_tmp\n",
    "        df_tmp = titles_df.loc[titles_df['title'] == row['title']]\n",
    "\n",
    "        # UNCOMMENT HERE to check duplicates:\n",
    "        # display(df_tmp[['original_title', 'link', 'publication_info_summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About duplicates\n",
    "titles_dict_2 = dict(Counter(titles))\n",
    "titles_dict_sorted_2 = dict(sorted(titles_dict_2.items(), key=lambda item: item[1], reverse = True))\n",
    "one = False\n",
    "\n",
    "# UNCOMMENT HERE to check duplicates:\n",
    "# for key in titles_dict_sorted_2.keys():\n",
    "#     if titles_dict_sorted_2[key] > 1:\n",
    "#         print(titles_dict_sorted_2[key], key)\n",
    "# print(titles_dict_sorted_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Extract and count titles' words\n",
    "\n",
    "Below, we concatenate all titles, in lower case and without punctuation.\n",
    "\n",
    "Then, we create a dictionnary of all words contained in this concatenation, with the associated number of occurences of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = df['title'].tolist()\n",
    "concat_titles = \" \".join(titles_list).lower()\n",
    "remove_punctutation = re.findall(\"[A-Za-z]+\",concat_titles)\n",
    "titles_dict = dict(Counter(remove_punctutation))\n",
    "titles_dict_sorted = dict(sorted(titles_dict.items(), key=lambda item: item[1], reverse = True))\n",
    "words_df = pd.DataFrame(titles_dict_sorted.items(), columns=['Word', 'InstancesNumber'])\n",
    "\n",
    "# UNCOMMENT HERE to save:\n",
    "# words_df.to_csv(\"file_name.csv\") # to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following step is done manually:** \n",
    "\n",
    "Then, manually we modify the csv file saved in (the last commented line of) the above cell. \n",
    "\n",
    "More precisely, we add a column in which we enter 1 if the word is an excluding word, 999 if we are not sure, an nothing otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Load csv with identified excluding words to apply the selection of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  449\n"
     ]
    }
   ],
   "source": [
    "_path_scholar_titles=\"./0_selected_excluding_words/all_words_2.csv\"\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(_path_scholar_titles, sep=';', usecols = [1, 2, 3]))\n",
    "\n",
    "# Take the list of selected words\n",
    "df_select = df[df[\"Select\"] == 1][[\"Word\", \"InstancesNumber\"]]\n",
    "words_to_exclude = df_select[\"Word\"].to_list()\n",
    "# print(words_to_exclude)\n",
    "print('Number of words to exclude: ', len(words_to_exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Apply the selection based on these excluding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  449\n",
      "Number articles removed:  2545\n",
      "Number articles newly removed:  2545\n",
      "Number articles preserved:  3277\n",
      "Check:  5822 == 5822\n"
     ]
    }
   ],
   "source": [
    "words_1 = words_to_exclude\n",
    "titles_df_1 = apply_excluding_words(words_1, titles_df)\n",
    "check_proportions(words_1, titles_df_1, titles_df) # to check the results of this selection step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next 2 sections, we look for new excluding words in another manner. \n",
    "First, in Section 1.6, we check what 'children words' of the identified excluding words (in ``word_1``) are contained in the titles.\n",
    "Secondly, in Section 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Check what are the words in the current title that have one of the identified 'excluding words' as root\n",
    "\n",
    "Here, we save in the dictionary ``d`` the 'children words' (of excluding words) present in the titles.\n",
    "\n",
    "In this dictionary, keys are the identified excluding words and values are corresponding lists of 'children words'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_words_parent_list = ['plants', 'grid', 'thermal', 'battery', 'water', 'health', \\\n",
    "'industrial', 'wave', 'particle', 'grids', 'home', 'risk', 'protein', 'iran', \\\n",
    "'reactor', 'waste', 'turbine', 'market', 'converter', 'spectral', 'urbanization', 'suburban', \\\n",
    "'failure', 'outage', 'molecular', 'space', 'fluid', 'magnetic', 'province', 'chemical', \\\n",
    "'indoor', 'alloy', 'room', 'india', 'satellite', 'food', 'machinery', 'forest', 'electrons', \\\n",
    "'spectra', 'wood', 'mechanical', 'vibration', 'reservoir', 'kinetic', 'hydro', 'diesel', 'motor', \\\n",
    "'microgrid', 'accident', 'railway', 'pump', 'robot', 'immune', 'pollutant', 'drug', 'house', \\\n",
    "'waves', 'business', 'shower', \\\n",
    "]\n",
    "\n",
    "d = {}\n",
    "\n",
    "cpt = 0\n",
    "\n",
    "# Loop over all titles:\n",
    "for i, row in titles_df.iterrows():\n",
    "# for title in titles:\n",
    "    \n",
    "    title_no_punct = \" \".join(re.findall(\"[A-Za-z]+\",titles_df.loc[i,'title']))\n",
    "    \n",
    "    for ele in words_1:\n",
    "        if cpt == 0:\n",
    "            d[ele] = []\n",
    "        title_words = title_no_punct.lower().split()\n",
    "        for word in title_words:\n",
    "            if ele.lower() in word.lower():\n",
    "                if word.lower() not in d[ele] and word.lower() != ele.lower():\n",
    "                    d[ele].append(word.lower())\n",
    "        ### UNCOMMENT BELOW to make observations on the children of the excluding words:\n",
    "        ### Here, we exclude from this observation ecluding words whose children have been selected in the Section 1.7\n",
    "        ### in order to make observation about other possible children to select.\n",
    "        # if ele not in ['ion', 'us', 'ant', 'cement', 'solid', 'sea', 'oil', 'mine', 'dam', 'city']+new_words_parent_list:\n",
    "        #     if ele in title_no_punct.lower() and ele not in title_no_punct.lower().split():\n",
    "        #         print('----------------------')\n",
    "        #         print(ele)\n",
    "        #         print(title_no_punct.lower())\n",
    "    \n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which keys in d have a lot of \"children\", and choose whether or not to add these children or part of the list of words to be excluded.\n",
    "\n",
    "To add the children of an excluding word, we add `` d['your excluding word']`` to the list ``new_word`` in Section 1.7 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant ['plants', 'implantable', 'powerplants']\n",
      "nuclear ['internuclear']\n",
      "pv ['pvt', 'spv', 'bipv', 'pvusa']\n",
      "plants ['powerplants']\n",
      "grid ['microgrid', 'grids', 'microgrids', 'supergrids']\n",
      "applications []\n",
      "thermal ['geothermal', 'hydrothermal']\n",
      "gas ['fpgas', 'gastric', 'biogas', 'gasbxas', 'gases', 'gasification', 'gasoline', 'gasverbrauchsprognose', 'pegasus']\n",
      "battery ['batteryless']\n",
      "heat ['heated', 'wheat', 'heating', 'heatwave', 'heatwaves', 'reheaters', 'heaters', 'superheater', 'superheated']\n",
      "water ['wastewater', 'groundwater', 'seawater', 'underwater', 'freshwater']\n",
      "health ['healthcare']\n",
      "fog []\n",
      "air ['aircraft', 'pairwise', 'dairy', 'wheelchair', 'flair', 'fairness', 'clairvoyant', 'nucleaires', 'repair', 'impairment', 'airport', 'airfoil', 'airflow', 'paired', 'pairing', 'fair']\n",
      "residential []\n",
      "industrial ['industrialization']\n",
      "fuel ['fuels', 'biofuels', 'fueled']\n",
      "laser ['hilaserion', 'lasers']\n",
      "coal ['charcoal']\n",
      "heating []\n",
      "economic ['socioeconomic', 'macroeconomic', 'economics']\n",
      "household ['householders', 'households', 'ofhousehold']\n",
      "wave ['waveforms', 'mmwave', 'microwave', 'heatwave', 'heatwaves', 'waveform', 'wavelet', 'wavenet', 'waves', 'wavelength', 'wavelets']\n",
      "particle ['nanoparticles', 'particles']\n",
      "industry []\n",
      "oil ['boiling', 'boiler', 'coil', 'boilers', 'coils', 'broiler', 'oilseeds', 'oils', 'soil', 'soiling', 'airfoil', 'broilers', 'soils', 'soiled', 'recoil']\n",
      "grids ['microgrids', 'supergrids']\n",
      "home ['homeostasis', 'homeostatic']\n",
      "mining ['datamining', 'examining', 'determining']\n",
      "uav ['uavs', 'muav']\n",
      "risk ['risks']\n",
      "china []\n",
      "protein ['glycoprotein', 'proteins']\n",
      "iran ['iranian']\n",
      "reactor ['reactors']\n",
      "traffic []\n",
      "waste ['wastewater', 'wastes']\n",
      "manufacturing []\n",
      "turbine ['hydroturbine']\n",
      "acoustic []\n",
      "diagnosis []\n",
      "ship ['shipping', 'relationship', 'shipboard', 'leadership', 'relationships']\n",
      "market ['markets', 'marketing', 'marketers', 'supermarket']\n",
      "financial []\n",
      "materials []\n",
      "converter ['converters', 'measuringconverters']\n",
      "resources []\n",
      "turkey []\n",
      "weather []\n",
      "spectral ['multispectral', 'hyperspectral']\n",
      "ion ['estimation', 'consumption', 'recognition', 'prediction', 'production', 'activation', 'reactions', 'classification', 'emissions', 'dimensional', 'application', 'automation', 'projection', 'fusion', 'convolutional', 'detection', 'applications', 'transmission', 'integration', 'orthogonalization', 'dissipation', 'characterization', 'distribution', 'emission', 'traditional', 'injection', 'correction', 'absorption', 'calculation', 'solutions', 'extraction', 'evaluation', 'optimization', 'lubrication', 'combustion', 'transportation', 'degradation', 'mission', 'intersection', 'generation', 'correlation', 'deposition', 'revisions', 'direction', 'computational', 'interaction', 'conventional', 'equations', 'explorations', 'regression', 'radiation', 'discussion', 'function', 'location', 'conditions', 'solution', 'participation', 'precipitation', 'information', 'segmentation', 'operational', 'selection', 'construction', 'educational', 'institutions', 'implementation', 'randomization', 'validation', 'operations', 'deterioration', 'atomization', 'extrapolation', 'reorganization', 'propulsion', 'adsorption', 'consolidation', 'solvation', 'interactions', 'simulation', 'decision', 'exploration', 'cogeneration', 'contribution', 'combinations', 'predictions', 'conversion', 'formation', 'autocorrelation', 'decomposition', 'observations', 'dissociation', 'ionic', 'restoration', 'stations', 'actions', 'hydration', 'friction', 'conditioner', 'calculations', 'regions', 'stimulation', 'intrusion', 'corrugation', 'motions', 'diffusion', 'concentration', 'aeration', 'ignition', 'station', 'reduction', 'relationship', 'communications', 'ionization', 'electromigration', 'evolution', 'incineration', 'explanations', 'evolutionary', 'precision', 'complication', 'multidimensional', 'adoption', 'simulations', 'excitation', 'collection', 'quantification', 'conditioning', 'expression', 'traction', 'investigation', 'conformation', 'interpretation', 'compensation', 'transformation', 'digestion', 'identification', 'population', 'associations', 'substations', 'combination', 'considerations', 'communication', 'operation', 'adaptation', 'aggregation', 'directional', 'dimensionality', 'recommendations', 'inclusion', 'transition', 'utilization', 'detectxion', 'condition', 'reaction', 'remission', 'situation', 'action', 'oscillations', 'desalination', 'rationing', 'implementations', 'optimisation', 'permeation', 'disaggregation', 'variations', 'locations', 'corruption', 'deviations', 'excursion', 'computation', 'formulation', 'subtraction', 'dimensions', 'assimilation', 'resolution', 'dysfunction', 'deduction', 'relation', 'composition', 'demonstration', 'reionization', 'computationally', 'functions', 'segregation', 'position', 'fragmentation', 'duration', 'vegetation', 'computations', 'approximations', 'organizational', 'proportional', 'practitioners', 'certification', 'conservation', 'vibration', 'vectorization', 'recommendation', 'localization', 'evasion', 'vision', 'illumination', 'acceleration', 'evapotranspiration', 'bidirectional', 'junction', 'calibration', 'allocation', 'confrontation', 'attention', 'regional', 'collision', 'transformations', 'neuroevolution', 'geostationary', 'rotational', 'limitation', 'variation', 'transaction', 'reconstruction', 'featurization', 'functional', 'contamination', 'institution', 'minimization', 'evaporation', 'insolation', 'retraction', 'migration', 'configuration', 'oscillation', 'inspection', 'sectional', 'initiation', 'emotion', 'pollution', 'substation', 'motion', 'verification', 'perception', 'lesions', 'extension', 'accommodation', 'realizations', 'partition', 'gabion', 'introduction', 'violation', 'cooperation', 'reputation', 'virtualization', 'replication', 'instruction', 'compression', 'decompression', 'navigation', 'transmissions', 'execution', 'equation', 'incorporation', 'provisioning', 'termination', 'collaboration', 'modulation', 'transactional', 'rationalization', 'completion', 'provocations', 'miniaturization', 'acquisition', 'constellation', 'redistribution', 'elaboration', 'manipulation', 'trasmission', 'definition', 'separation', 'microlocation', 'fibrillation', 'innovation', 'national', 'institutional', 'hilaserion', 'generations', 'deamidation', 'isomerization', 'informatization', 'visualization', 'digitalization', 'innovations', 'globalization', 'education', 'cointegration', 'urbanization', 'penetration', 'implications', 'organisations', 'installation', 'region', 'emancipation', 'decontamination', 'investigations', 'resuscitation', 'installations', 'corrosion', 'prevention', 'protection', 'functionally', 'interconnections', 'adaption', 'containerization', 'ingestion', 'malnutrition', 'mitigation', 'augmentation', 'discrimination', 'determination', 'refrigeration', 'specifications', 'federation', 'reclamation', 'omnidirectional', 'revolutionizing', 'revolutionize', 'section', 'fraction', 'assumptions', 'preestimation', 'propagation', 'congestion', 'backpropagation', 'sections', 'specification', 'induction', 'desorption', 'emotional', 'radionuclides', 'convolution', 'flotation', 'distributions', 'consideration', 'accretion', 'inception', 'partitioning', 'radionuclide', 'minimisation', 'supervision', 'conditional', 'prognostication', 'decommissioned', 'regulation', 'industrialization', 'methionine', 'purification', 'representations', 'union', 'vibrations', 'retention', 'torsionnet', 'torsional', 'dilution', 'substitution', 'attenuation', 'formulations', 'liquefaction', 'division', 'crystallization', 'gasification', 'instructions', 'opinion', 'international', 'desulfurization', 'conformational', 'predications', 'fluctuation', 'torsion', 'fluctuations', 'initialization', 'multifunctional', 'protonation', 'inflation', 'deviation', 'mechanization', 'simplification', 'orientation', 'explosion', 'stabilization', 'corporation', 'combinational', 'normalization', 'regularization', 'perforation', 'approximation', 'speculation', 'prediccion', 'fractional', 'reconfiguration', 'gravitational', 'revision', 'predistortion', 'counterpropagation', 'auscultation', 'optimalization', 'criterion', 'creation', 'association', 'deception', 'insulation', 'visualisation', 'compaction', 'inversion', 'synchronization', 'transmutation', 'extensions', 'conditioners', 'intuition', 'detonation', 'excursions', 'nation', 'unidirectional', 'violations', 'expansion', 'bifunctional', 'biomagnification', 'quantization', 'salvation', 'ccnsumption', 'humidification', 'oxidation', 'relational', 'concentrations', 'irrigation', 'interruptions', 'satisfaction', 'relations', 'dimension', 'representation', 'fabrication', 'restrictions', 'preconditioner', 'suspension', 'erosion', 'aberrations', 'diffraction', 'aberration', 'limitations', 'disintegration', 'orchestration', 'encryption', 'fission', 'instrumentation', 'decompositions', 'compilation', 'optimizations', 'annotation', 'telecommunications', 'functionality', 'distortion', 'exploitation', 'dispersion', 'addition', 'preparation', 'questions', 'interrelations', 'obfuscation', 'configurations', 'interrelation', 'commissioning', 'foundations', 'connections', 'attestation', 'abstractions', 'rational', 'realization', 'ventilation', 'organizations', 'edition', 'reflection', 'authentication', 'relationships', 'comprehension', 'emulation', 'foundational', 'documentation', 'consommation', 'deforestation', 'foundation', 'mutations', 'regulations', 'produktionsplanung', 'infocomunication', 'summation', 'renegotiation', 'description', 'version', 'dion', 'validacion', 'proportionality', 'transcription', 'preservation', 'positioning', 'utilisation', 'reservations', 'customization']\n",
      "city ['capacity', 'electricity', 'plasticity', 'hydroelectricity', 'velocity', 'ampacity', 'lectricity']\n",
      "harvesting []\n",
      "fusion ['diffusion']\n",
      "urban ['disturbances', 'disturbance', 'urbanization', 'suburban']\n",
      "failure ['failures']\n",
      "enterprise ['enterprises']\n",
      "biomass []\n",
      "outage ['outages']\n",
      "lithium []\n",
      "molecular ['intramolecular']\n",
      "human []\n",
      "wheat []\n",
      "space ['spacecraft', 'spaceborne']\n",
      "fluid ['nanofluid', 'nanofluids', 'fluids', 'fluidized']\n",
      "magnetic ['electromagnetic', 'magnetics']\n",
      "province ['provinces']\n",
      "chemical ['petrochemical', 'electrochemical', 'thermochemical']\n",
      "geothermal []\n",
      "drying []\n",
      "indoor ['indoors']\n",
      "children []\n",
      "combustion []\n",
      "batteries []\n",
      "farms []\n",
      "steel ['steels', 'steelmaking']\n",
      "alloy ['superalloys', 'alloys', 'superalloy']\n",
      "industries []\n",
      "boiler ['boilers']\n",
      "converters ['measuringconverters']\n",
      "room ['rooms', 'mushroom', 'cleanroom']\n",
      "absorption []\n",
      "solid ['consolidation']\n",
      "india ['indian']\n",
      "radiation []\n",
      "satellite ['satellites']\n",
      "fracture []\n",
      "food ['foods']\n",
      "harnessing []\n",
      "machinery ['turbomachinery']\n",
      "agricultural []\n",
      "forest ['forests', 'deforestation']\n",
      "electron ['electronic', 'electronics', 'electrons']\n",
      "spectra ['spectral', 'multispectral', 'hyperspectral']\n",
      "mill ['millimeter', 'milling', 'milles', 'mills']\n",
      "wood ['woodland', 'woodworking']\n",
      "molecules []\n",
      "ocean []\n",
      "mechanical ['thermomechanical', 'geomechanical']\n",
      "dam ['edaml', 'damage', 'overdamped', 'amsterdam', 'fundamental', 'damping']\n",
      "vibration ['vibrations']\n",
      "reservoir ['reservoirs']\n",
      "kinetic ['kinetics']\n",
      "economies []\n",
      "households []\n",
      "hydro ['hydroelectric', 'hydrostatic', 'hydrogen', 'hydropower', 'hydrologic', 'hydrodynamics', 'hydrolase', 'hydroturbine', 'hydrocarbon', 'hydroelectricity', 'hydrodynamic', 'hydrothermal']\n",
      "wastewater []\n",
      "microgrids []\n",
      "hydropower []\n",
      "domestic []\n",
      "thermoelectric []\n",
      "diesel ['biodiesel']\n",
      "plasma []\n",
      "pressure ['pressures']\n",
      "milling []\n",
      "membrane ['membranes']\n",
      "enterprises []\n",
      "paper []\n",
      "vehicular []\n",
      "us ['using', 'heterogeneous', 'industrial', 'fusion', 'robust', 'various', 'muscular', 'combustion', 'useful', 'industry', 'acoustic', 'sustainable', 'discussion', 'bus', 'usage', 'householders', 'versus', 'household', 'use', 'households', 'nanoporous', 'austenitic', 'fused', 'greenhouse', 'squamous', 'intrusion', 'diffusion', 'buses', 'used', 'housing', 'combustible', 'dusts', 'viscous', 'customer', 'sustainability', 'ofhousehold', 'clustering', 'nexus', 'inclusion', 'industries', 'users', 'synchronous', 'causal', 'user', 'customers', 'globallyusing', 'continuous', 'diffusivity', 'house', 'multilocus', 'status', 'intrusive', 'suspicious', 'pmus', 'autonomous', 'houseec', 'clusters', 'busan', 'just', 'aqueous', 'cluster', 'business', 'houses', 'npus', 'simultaneous', 'statuses', 'ubiquitous', 'energyplus', 'apparatus', 'bushehr', 'gaussian', 'plus', 'delicious', 'custom', 'heterogenous', 'reuse', 'homogeneous', 'simultaneously', 'eucalyptus', 'august', 'nonintrusive', 'instantaneous', 'trusted', 'campus', 'caused', 'australia', 'australian', 'fukushima', 'brushless', 'trustworthiness', 'resuscitation', 'exogenous', 'crusher', 'compus', 'focus', 'usages', 'warehouses', 'russian', 'dastous', 'exhaust', 'robustness', 'barkhausen', 'chakusetsu', 'combusting', 'russia', 'geosynchronous', 'frustum', 'industrialization', 'mushroom', 'pvusa', 'focused', 'gauss', 'greenhouses', 'usingartificial', 'asynchronous', 'dust', 'clustered', 'illustrates', 'discusses', 'arus', 'auscultation', 'justifying', 'gpgpus', 'causes', 'adjusted', 'anomalous', 'semiautogeneous', 'causality', 'usability', 'gpus', 'savonius', 'bambusa', 'sinusoid', 'discontinuous', 'pushboat', 'cpus', 'continuously', 'zeus', 'suspension', 'durchflussmengen', 'customized', 'modulus', 'pegasus', 'antivirus', 'obfuscation', 'malicious', 'austria', 'kustannuslaskentaohjelmisto', 'ausbau', 'reusable', 'westinghouse', 'adjustable', 'illustrating', 'businesses', 'push', 'nusantara', 'customization', 'conscious']\n",
      "motor ['motors']\n",
      "robots []\n",
      "hydroelectric ['hydroelectricity']\n",
      "microgrid ['microgrids']\n",
      "hydrogen []\n",
      "pyrolysis []\n",
      "accident ['accidents']\n",
      "warning []\n",
      "grinding []\n",
      "railway ['railways']\n",
      "pump ['pumping', 'pumped', 'pumps']\n",
      "atomic []\n",
      "robot ['robots']\n",
      "mine ['amine', 'determine', 'determined', 'mineral', 'electroluminescense', 'mines', 'greenminer', 'miner']\n",
      "atmospheric []\n",
      "metabolizable []\n",
      "tomography []\n",
      "ligand []\n",
      "moisture []\n",
      "facilities []\n",
      "propulsion []\n",
      "graphene []\n",
      "meteorological []\n",
      "covid []\n",
      "brain []\n",
      "immune ['neuroimmune', 'autoimmune']\n",
      "cells []\n",
      "heart []\n",
      "pollutant ['pollutants']\n",
      "drug ['drugs']\n",
      "matter ['matters']\n",
      "africa ['african']\n",
      "house ['householders', 'household', 'households', 'greenhouse', 'ofhousehold', 'houseec', 'houses', 'warehouses', 'greenhouses', 'westinghouse']\n",
      "healthcare []\n",
      "cognitive []\n",
      "rural []\n",
      "campus []\n",
      "waves ['heatwaves']\n",
      "sky ['leipunsky']\n",
      "corn ['corneal', 'corner']\n",
      "spatiotemporal []\n",
      "mars []\n",
      "sea ['research', 'search', 'searching', 'disease', 'diseases', 'seawater', 'season', 'researchers', 'searches', 'seasonal', 'seam', 'reseau', 'researches', 'researching']\n",
      "factory []\n",
      "ant ['plants', 'plant', 'antenna', 'quantum', 'quantifying', 'significantly', 'quantitative', 'constant', 'quantification', 'important', 'occupant', 'significant', 'mutant', 'pollutant', 'quantity', 'anti', 'quantities', 'merchant', 'quantify', 'grant', 'elephants', 'pantograph', 'coolant', 'advantages', 'instant', 'semantic', 'advantage', 'guarantee', 'clairvoyant', 'pollutants', 'tolerant', 'instantaneous', 'determinants', 'implantable', 'resistant', 'redundant', 'anthropogenic', 'hantei', 'quantile', 'antisymmetric', 'variants', 'manta', 'atlantic', 'anterior', 'buoyant', 'relevant', 'powerplants', 'quantized', 'guaranteed', 'canterbury', 'constants', 'geant', 'quantization', 'anthropomorphic', 'quantifiable', 'antivirus', 'contaminants', 'tenant', 'antara', 'nusantara']\n",
      "cancer []\n",
      "indonesia []\n",
      "tidal []\n",
      "business ['businesses']\n",
      "biological []\n",
      "chinese []\n",
      "june []\n",
      "potato []\n",
      "atlas []\n",
      "diagnostics []\n",
      "asian []\n",
      "cement ['placement', 'displacement', 'reinforcement', 'replacement', 'enhancement', 'advancement', 'advancements']\n",
      "taiwan []\n",
      "seizure []\n",
      "shower ['showers']\n",
      "office ['offices']\n",
      "property []\n",
      "injection []\n",
      "aircraft []\n",
      "pilot []\n",
      "metals []\n",
      "flood []\n",
      "atomistic []\n",
      "steels []\n",
      "sulfur ['desulfurization']\n",
      "lymph []\n",
      "metastasis []\n",
      "groundwater []\n",
      "saudi []\n",
      "arabia []\n",
      "island []\n",
      "oxygen ['oxygenate']\n",
      "hospital ['hospitalised', 'hospitals']\n",
      "automotive []\n",
      "pandemic []\n",
      "population []\n",
      "brazilian []\n",
      "diseases []\n",
      "skiers []\n",
      "trucks []\n",
      "alloys ['superalloys']\n",
      "drone ['drones']\n",
      "orbit ['orbiting']\n",
      "uavs []\n",
      "pollution []\n",
      "wildlife []\n",
      "seismic []\n",
      "rainfall []\n",
      "tehran []\n",
      "trains []\n",
      "neutron ['neutrons', 'neutronics', 'neutronic']\n",
      "forests []\n",
      "particles ['nanoparticles']\n",
      "molecule ['molecules']\n",
      "rotor []\n",
      "mills []\n",
      "zealand []\n",
      "ultrasonic []\n",
      "nitrogen []\n",
      "flight []\n",
      "animal []\n",
      "fire ['fired', 'wildfire', 'firefly']\n",
      "radiative []\n",
      "bone ['backbone']\n",
      "photovoltaics []\n",
      "korea ['korean']\n",
      "atomization []\n",
      "metaheuristic ['metaheuristics']\n",
      "polymer ['polymeric']\n",
      "socioeconomic []\n",
      "enthalpy []\n",
      "communities []\n",
      "nanoflakes []\n",
      "crop ['microprocessor', 'microprocessors', 'microphone']\n",
      "storm ['rainstorm', 'sandstorm']\n",
      "sri []\n",
      "lanka []\n",
      "humidity []\n",
      "outdoor []\n",
      "vessel ['vessels']\n",
      "leakage []\n",
      "housing []\n",
      "flame []\n",
      "japan []\n",
      "condenser []\n",
      "vacuum []\n",
      "malware []\n",
      "chamber ['chambers']\n",
      "petrochemical []\n",
      "absorptiometry []\n",
      "car ['carbon', 'cart', 'carbonyls', 'carcinoma', 'care', 'cardiovascular', 'carrier', 'cardiopulmonary', 'myocardial', 'carlo', 'hydrocarbon', 'cars', 'healthcare', 'carbontracker', 'adenocarcinoma', 'carry', 'cardiac', 'carrying', 'carrot', 'carcass', 'cargo', 'cards', 'carbef', 'cardiomyopathy', 'scorecard', 'card']\n",
      "metropolitan []\n",
      "seawater []\n",
      "atom ['atomization', 'atomistic', 'atomic', 'atoms', 'tsniiatominform', 'atomeroemuevi']\n",
      "centrifugal []\n",
      "crystals []\n",
      "indian []\n",
      "diagnosing []\n",
      "shipboard []\n",
      "telescope []\n",
      "flying []\n",
      "drones []\n",
      "corneal []\n",
      "houses ['warehouses', 'greenhouses']\n",
      "photonic []\n",
      "electrochemical []\n",
      "pollutants []\n",
      "cardiac []\n",
      "laboratory []\n",
      "disaster ['disasters']\n",
      "hotel ['datahotels']\n",
      "electromagnetic []\n",
      "agriculture []\n",
      "netherlands []\n",
      "morocco []\n",
      "poultry []\n",
      "emergency []\n",
      "biomedical []\n",
      "pumps []\n",
      "epileptic []\n",
      "russia ['russian']\n",
      "daylighting []\n",
      "electrolysis []\n",
      "meal []\n",
      "liquefaction []\n",
      "screw []\n",
      "metallurgical []\n",
      "cucumber []\n",
      "broilers []\n",
      "aerial []\n",
      "diagnostic ['diagnostics']\n",
      "neuronal ['neuronalen']\n",
      "digestible []\n",
      "erosion []\n",
      "frozen []\n",
      "cryptographic []\n",
      "languages []\n",
      "catalytic []\n",
      "stereolithography []\n",
      "climatic []\n",
      "postal []\n",
      "scooter []\n",
      "scanner []\n",
      "polystyrene []\n",
      "qatar []\n",
      "fuels ['biofuels']\n",
      "aquifers []\n",
      "maritime []\n",
      "thermomechanical []\n",
      "ecological []\n",
      "chemistry []\n",
      "ionic []\n",
      "cervical []\n",
      "coastal []\n",
      "drugs []\n",
      "spacecraft []\n",
      "amino []\n",
      "acids []\n",
      "thermoplastic []\n",
      "ionization ['reionization']\n",
      "malaysia ['malaysian']\n",
      "biodiesel []\n",
      "glucose []\n",
      "heatwaves []\n",
      "cardiovascular []\n",
      "disease ['diseases']\n",
      "ice ['office', 'devices', 'service', 'device', 'prices', 'indices', 'multicell', 'lattice', 'price', 'fyzice', 'licensee', 'voice', 'advice', 'services', 'practice', 'slices', 'priced', 'choice', 'slice', 'microservice', 'appendices', 'rice', 'voices', 'choices', 'practices', 'offices']\n",
      "plasticity []\n",
      "carrier []\n",
      "poverty []\n",
      "hydraulic []\n",
      "canadian []\n",
      "enzyme []\n",
      "myocardial []\n",
      "moroccan []\n",
      "greek []\n",
      "permeation []\n",
      "sequencing []\n",
      "hip ['ship', 'shipping', 'relationship', 'chip', 'shipboard', 'multichip', 'leadership', 'chips', 'relationships']\n",
      "adolescents []\n",
      "clinical ['subclinical', 'paraclinical']\n",
      "romania []\n",
      "intraocular []\n",
      "land ['landscapes', 'island', 'flanders', 'poland', 'drylands', 'finland', 'netherlands', 'balandin', 'landslide', 'woodland', 'inland', 'zealand', 'landscape', 'rangeland']\n",
      "fleet ['fleets']\n",
      "solvents []\n",
      "bimetallic []\n",
      "arena []\n",
      "companies []\n",
      "wheelchair []\n",
      "cars []\n",
      "german ['germany', 'germanium']\n",
      "african []\n",
      "insulators []\n",
      "conveyor []\n",
      "spectroscopy []\n",
      "therapy ['immunotherapy', 'radiotherapy']\n",
      "photoplethysmography []\n",
      "evapotranspiration []\n",
      "skating []\n",
      "adults []\n",
      "respiratory []\n",
      "plethysmography ['photoplethysmography']\n",
      "swimming []\n",
      "geostationary []\n",
      "lung ['kuehlung', 'bremsstrahlung', 'lungmen']\n",
      "school ['schools', 'summerschool']\n",
      "proteins []\n",
      "wildfire []\n",
      "mountain []\n",
      "lyapunov []\n",
      "refactoring ['refactorings']\n",
      "multiphysics []\n",
      "driver ['drivers']\n",
      "satellites []\n",
      "art ['smart', 'cart', 'artificial', 'part', 'participation', 'apartment', 'nanoparticles', 'parts', 'martensitic', 'departure', 'heart', 'particle', 'arthritis', 'partially', 'article', 'smartphone', 'partial', 'department', 'apartments', 'dart', 'partition', 'smartphones', 'farthings', 'aspartate', 'start', 'smarter', 'partitioning', 'earthwork', 'particles', 'earthen', 'usingartificial', 'quarter', 'artifical', 'artifician', 'artificiais', 'charts', 'flowcharts', 'marte', 'party', 'artifact', 'smartest', 'arts', 'spinsmart', 'starting']\n",
      "orbiting []\n",
      "garbage []\n",
      "spintronics []\n",
      "dosimetric []\n",
      "fibrillation []\n",
      "iranian []\n",
      "tourism []\n",
      "residences []\n",
      "germany []\n",
      "amsterdam []\n",
      "commuter []\n",
      "railways []\n",
      "medical ['biomedical']\n",
      "ultrasound []\n",
      "psychological []\n",
      "sugarcane []\n",
      "biofuels []\n",
      "voltaic ['photovoltaics']\n",
      "microalgae []\n",
      "myopia []\n",
      "gases []\n",
      "flue ['influencing', 'influenced', 'effluent', 'fluence', 'influence', 'influenta', 'influent', 'influences']\n",
      "bankruptcy []\n",
      "harvester ['harvesters']\n",
      "overvoltages []\n",
      "chips []\n",
      "lamb []\n",
      "milk []\n",
      "meat ['permeation']\n",
      "ontology []\n",
      "calorimeter ['calorimeters']\n",
      "nanofluids []\n",
      "magnet ['magnetron', 'magnetometer', 'magnetic', 'electromagnetic', 'magnetocrystalline', 'magnetics']\n",
      "sugar ['sugarcane']\n",
      "plane ['planetary']\n",
      "wastes []\n",
      "underwater []\n",
      "geosynchronous []\n",
      "tractors []\n",
      "copper []\n",
      "dryer []\n",
      "broiler ['broilers']\n",
      "dietary []\n",
      "methionine []\n",
      "chromatography []\n",
      "beijing []\n",
      "river ['driver', 'drivers']\n",
      "dust ['industrial', 'industry', 'dusts', 'industries', 'industrialization']\n",
      "tractor ['tractors', 'attractor']\n",
      "tyre ['polystyrene']\n",
      "powerplants []\n",
      "genetically []\n",
      "petroleum []\n",
      "gasoline []\n",
      "gravitational []\n",
      "woodworking []\n",
      "diagnose []\n",
      "ecosystems []\n",
      "genes ['monocytogenes']\n",
      "portuguese []\n",
      "species []\n",
      "prognosis []\n",
      "prognostic ['prognostication']\n",
      "cyclotron []\n",
      "hydrodynamic ['hydrodynamics']\n",
      "cargo []\n",
      "economics []\n",
      "congress []\n"
     ]
    }
   ],
   "source": [
    "for key in d.keys():\n",
    "    print(key, d[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. New exclusions based on the children words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new words to exclude (1):  127\n"
     ]
    }
   ],
   "source": [
    "new_words = d['plants'] + d['grid'] + d['thermal'] + d['battery'] + d['water'] + d['health'] + \\\n",
    "             d['industrial'] + d['wave'] + d['particle'] + d['grids'] + d['home'] + d['risk'] + d['protein'] + d['iran'] + \\\n",
    "             d['reactor'] + d['waste'] + d['turbine'] + d['market'] + d['converter'] + d['spectral'] + ['urbanization', 'suburban'] + \\\n",
    "             d['failure'] + d['outage'] + d['molecular'] + d['space'] + d['fluid'] + d['magnetic'] + d['province'] + d['chemical'] + \\\n",
    "             d['indoor'] + d['alloy'] + d['room'] + d['india'] + d['satellite'] + d['food'] + d['machinery'] + d['forest'] + ['electrons'] + \\\n",
    "             d['spectra'] + d['wood'] + d['mechanical'] + d['vibration'] + d['reservoir'] + d['kinetic'] + d['hydro'] + d['diesel'] + \\\n",
    "             d['motor'] + d['microgrid'] + d['accident'] + d['railway'] + d['pump'] + d['robot'] + d['immune'] + d['pollutant'] + d['drug'] + \\\n",
    "             d['house'] + d['waves'] + d['business'] + d['shower']\n",
    "\n",
    "print('Number of new words to exclude (1): ', len(new_words))\n",
    "\n",
    "# We use the above words to create new_words_parent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new words to exclude (2):  67\n"
     ]
    }
   ],
   "source": [
    "new_words_2 = ['householders', 'household', 'households', 'houses', 'warehouses'] + d['steel'] + ['fuels', 'biofuels'] + \\\n",
    "['carbonyls', 'carcinoma', 'cardiovascular', 'carrier', 'cardiopulmonary', 'myocardial', 'hydrocarbon', 'cars', \\\n",
    "'healthcare', 'adenocarcinoma', 'cardiac', 'carcass', 'cargo', 'cardiomyopathy'] + d['molecule'] + d['africa'] + \\\n",
    "d['economic'] + d['membrane'] + ['gases', 'gasification', 'gasoline', 'gastric', 'biogas'] + d['drone'] + \\\n",
    "['mills'] + ['corneal'] + d['uav'] + ['wildfire', 'firefly'] + ['urbanization', 'suburban'] + d['orbit'] + ['converters'] + \\\n",
    "d['neutron'] + d['hydroelectric'] + ['atomization', 'atomistic', 'atomic', 'atoms'] + d['hospital'] + ['electrons'] + \\\n",
    "d['boiler'] + d['vessel'] + d['sulfur'] + d['oxygen'] + d['nuclear'] + d['chamber'] + d['coal'] + d['pv']\n",
    "\n",
    "print('Number of new words to exclude (2): ', len(new_words_2))\n",
    "\n",
    "# new_words_parent_list_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  194\n",
      "Number articles removed:  2638\n",
      "Number articles newly removed:  93\n",
      "Number articles preserved:  3184\n",
      "Check:  5822 == 5822\n",
      "5729\n"
     ]
    }
   ],
   "source": [
    "# update of the exclusion procedure:\n",
    "\n",
    "words_2 = new_words + new_words_2\n",
    "titles_df_2 = apply_excluding_words(words_2, titles_df_1)\n",
    "check_proportions(words_2, titles_df_2, titles_df_1)\n",
    "\n",
    "check = 0\n",
    "for i, row in titles_df_2.iterrows():\n",
    "    check += int(titles_df_2.loc[i, 'keep_title'] == titles_df_1.loc[i, 'keep_title'])\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. New exclusions based on analysis of remaining titles\n",
    "\n",
    "Here, we manually look for more excluding words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  8\n",
      "Number articles removed:  2762\n",
      "Number articles newly removed:  124\n",
      "Number articles preserved:  3060\n",
      "Check:  5822 == 5822\n"
     ]
    }
   ],
   "source": [
    "words_3 = ['state estimation', 'power line', 'distribution line', 'transmission line', 'anomaly detection',\\\n",
    "              'fraud detection', 'fault detection', 'fault prediction']\n",
    "titles_df_3 = apply_excluding_2_words(words_3, titles_df_2)\n",
    "check_proportions(words_3, titles_df_3, titles_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  10\n",
      "Number articles removed:  2828\n",
      "Number articles newly removed:  66\n",
      "Number articles preserved:  2994\n",
      "Check:  5822 == 5822\n"
     ]
    }
   ],
   "source": [
    "words_4 = ['shear walls', 'aircraft', 'metal forming processes', 'energy system', 'energy systems', \\\n",
    "                'energy harvesting', 'renewable energy', 'energy storage', 'energy expanditure' \\\n",
    "                'free energy estimation', 'hybrid energy']\n",
    "titles_df_4 = apply_excluding_2_words(words_4, titles_df_3)\n",
    "check_proportions(words_4, titles_df_4, titles_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT HERE to create a csv file of pair of words from the remaining titles:\n",
    "# make_2words_csv(titles_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  27\n",
      "Number articles removed:  3233\n",
      "Number articles newly removed:  405\n",
      "Number articles preserved:  2589\n",
      "Check:  5822 == 5822\n"
     ]
    }
   ],
   "source": [
    "_path=\".\\\\0_selected_excluding_words\\\\twoWords_20230705-115941.csv\"\n",
    "df = pd.DataFrame(pd.read_csv(_path, sep=';', usecols = [1, 2, 3]))\n",
    "\n",
    "# Take the list of selected words\n",
    "df_select = df[df[\"Select\"] == 1][[\"TwoWords\", \"InstancesNumber\"]]\n",
    "words_5 = df_select[\"TwoWords\"].to_list() + [\"power distribution system\", \"power distribution network\"]\n",
    "\n",
    "titles_df_5 = apply_excluding_2_words(words_5, titles_df_4)\n",
    "check_proportions(words_5, titles_df_5, titles_df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment HERE to create a csv file of pair of words from the remaining titles:\n",
    "# make_2words_csv(titles_df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserved = titles_df_5[titles_df_5['keep_title'] == 1]['title']\n",
    "\n",
    "# Uncomment HERE to print the preserved titles:\n",
    "# for title in preserved:\n",
    "#     print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Saving the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_name = \"scholar_keep_\"+str_current_datetime+\".csv\"\n",
    "# Uncomment HERE to save the results:\n",
    "# titles_df_5[titles_df_5['keep_title'] == 1].to_csv(file_name) # to save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remaining titles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining titles: 2589\n",
      "0       Estimation of energy consumption in machine le...\n",
      "1       GPGPU performance and power estimation using m...\n",
      "2       Mlee: Method level energy estimation—a machine...\n",
      "3       How to measure energy consumption in machine l...\n",
      "5       Machine Learning Based Power Estimation for CM...\n",
      "                              ...                        \n",
      "5809    Power consumption prediction model and method ...\n",
      "5813    Scheduling Algorithms for Federated Learning w...\n",
      "5815    Resource Optimization and Device Scheduling fo...\n",
      "5816    Balanced energy consumption based on historica...\n",
      "5820    Energy-efficient in-situ monitoring using on-d...\n",
      "Name: original_title, Length: 2589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remaining_titles = titles_df_5[titles_df_5['keep_title'] == 1]['original_title']\n",
    "nb_remaining_titles = len(remaining_titles)\n",
    "print(\"Number of remaining titles:\", nb_remaining_titles)\n",
    "print(remaining_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**\n",
    "\n",
    "Here we try removing all excluding words and pair of words at once for google scholar. We observe that we obtain the same resulst as before (with the step by step process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  688\n",
      "Number articles removed:  3233\n",
      "Number articles newly removed:  3233\n",
      "Number articles preserved:  2589\n",
      "Check:  5822 == 5822\n"
     ]
    }
   ],
   "source": [
    "words = words_1 + words_2 + words_3 + words_4 + words_5\n",
    "titles_df_test = apply_excluding_2_words(words, titles_df)\n",
    "check_proportions(words, titles_df_test, titles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IEEE\n",
    "\n",
    "### 2.1. Applying the excluding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  688\n",
      "Number articles removed:  176\n",
      "Number articles newly removed:  176\n",
      "Number articles preserved:  421\n",
      "Check:  597 == 597\n"
     ]
    }
   ],
   "source": [
    "# create smaller df as for scholar - keep DOI as ID\n",
    "_path_ieee=\"../1_initial_search/saved_results_other_datasources/ieee/export2023.06.12-11.30.07.csv\"\n",
    "df = pd.DataFrame(pd.read_csv(_path_ieee))\n",
    "\n",
    "my_columns = ['Document Title', 'ISBNs', 'DOI', 'Publication Title', 'PDF Link', 'Abstract', \\\n",
    "              'Authors', 'Author Keywords', 'Publication Year']\n",
    "titles_df_ieee = prepare_titles_df(df, my_columns, 'Document Title')\n",
    "\n",
    "# Apply excluding words:\n",
    "words = words_1 + words_2 + words_3 + words_4 + words_5\n",
    "titles_df_ieee_selected = apply_excluding_2_words(words, titles_df_ieee)\n",
    "check_proportions(words, titles_df_ieee_selected, titles_df_ieee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Importing the results into Zotero (reference managing software)\n",
    "\n",
    "We use DOIs and ISBNs to import IEEE results into zotero. DOIs and ISNBs should be imported separately. In the DOIs list one of the articles appears two times with two different DOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x ---------------------------- x\n",
      "978-3-8396-0439-7, 978-1-905824-26-7, 978-1-4503-4186-8, 978-1-4244-6747-1, 978-989-758-234-9, 978-1-4244-4165-5, 978-1-889335-42-1, 978-1-4503-5732-6, 978-3-901882-46-3, 978-89-88678-55-8\n",
      "x ---------------------------- x\n",
      "10.1109/EFEA56675.2022.10063818, 10.1109/NBiS.2016.88, 10.1109/ICAAIC53929.2022.9793147, 10.1109/ICELIE.2006.347212, 10.1109/WAINA.2015.127, 10.1109/BWCCA.2015.79, 10.1109/IECON.2006.348098, 10.1109/ICECIE52348.2021.9664681, 10.1109/ITOEC53115.2022.9734517, 10.1109/VLHCC.2014.6883045, 10.1109/CSO.2009.451, 10.1109/HONET.2016.7753443, 10.1109/MySEC.2015.7475216, 10.1109/ELTECH.2019.8839589, 10.1109/ICPADS.2016.0101, 10.1109/ICOECS50468.2020.9278506, 10.1109/ICE.2017.8279878, 10.1109/ICCASIT55263.2022.9986683, 10.1109/ICEIC51217.2021.9369725, 10.1109/ISCID.2018.10169, 10.1109/ICCNC.2019.8685588, 10.1109/UralCon54942.2022.9906691, 10.1109/ICACTE55855.2022.9943608, 10.1109/CISIS.2015.18, 10.1109/ICACCE.2015.148, 10.1109/ACSSC.2017.8335698, 10.1109/ICDMAI.2017.8073480, 10.1109/NBiS.2015.10, 10.1109/92.805757, 10.1109/SIMSYM.2003.1192820, 10.1109/CMPSAC.2004.1342677, 10.1109/ICEAC.2012.6471005, 10.1109/CADSM.2015.7230795, 10.1109/icABCD49160.2020.9183851, 10.1109/JETCAS.2018.2865006, 10.1109/WICSA.2008.28, 10.1109/3CA.2010.5533780, 10.1109/EPEC.2016.7771702, 10.1109/Cybermatics_2018.2018.00106, 10.1109/ICCE.2010.5418970, 10.1109/VLSI-SATA.2016.7593041, 10.1109/ICICCSP53532.2022.9862353, 10.1109/SEGE52446.2021.9534987, 10.1109/ICMIT47780.2020.9046987, 10.23919/CISTI49556.2020.9140864, 10.1109/ICNC.2015.7377962, 10.1109/SBAC-PADW.2015.11, 10.1109/NEUREL.2010.5644049, 10.1109/ICCRD.2011.5763864, 10.1109/ICOIN50884.2021.9333968, 10.1109/SSD54932.2022.9955883, 10.1109/ICNSC48988.2020.9238073, 10.1109/APAP47170.2019.9224637, 10.1109/MITP.2012.39, 10.1109/ICPC.2016.7503726, 10.1109/ECAI46879.2019.9042121, 10.1109/FPL.2010.41, 10.1109/DSD.2010.115, 10.1109/AISP53593.2022.9760542, 10.1109/BWCCA.2011.66, 10.1109/SMACD.2017.7981598, 10.1109/NORCHIP.2015.7364397, 10.1109/HPCC.2014.102, 10.1109/ICESS.2016.35, 10.1109/ICME.2007.4285083, 10.1109/BIGCOMP.2016.7425924, 10.1109/ICOS.2011.6079244, 10.1109/CVPRW.2016.113, 10.1109/IGCC.2015.7393702, 10.23919/ChiCC.2017.8027651, 10.23919/AEIT.2017.8240544, 10.1109/IMTC.2002.1007205, 10.1109/GCCE.2017.8229436, 10.1109/CANDAR.2017.56, 10.1109/ICIEAM.2016.7910995, 10.1109/ITiME.2011.6130840, 10.1109/FPT.2017.8280149, 10.1109/EUSIPCO.2016.7760327, 10.1049/icp.2022.0242, 10.1109/LASCAS51355.2021.9459177, 10.1109/SIELA49118.2020.9167069, 10.1109/COMSNETS.2012.6151371, 10.1109/AINA.2011.22, 10.1109/ISCAS.2018.8351398, 10.1109/IE54923.2022.9826760, 10.1109/IWCMC.2019.8766542, 10.1109/ICSCCC51823.2021.9478089, 10.1109/ICACCM56405.2022.10009565, 10.23919/ICACT53585.2022.9728798, 10.23919/ICACT51234.2021.9370393, 10.1109/IPFA49335.2020.9260780, 10.23919/DATE.2017.7927039, 10.1364/ECEOC.2012.We.1.G.4, 10.1109/CMC.2011.62, 10.1109/UIC-ATC-ScalCom.2014.26, 10.1109/IC2E55432.2022.00011, 10.1109/FMEC.2019.8795328, 10.1109/ICIT.2012.6209940, 10.1109/NCA.2012.42, 10.1109/CLUSTER.2017.103, 10.1109/PTC.2013.6652466, 10.1109/ICACCI.2014.6968620, 10.1109/EI252483.2021.9713131, 10.1109/DDECS.2008.4538772, 10.1109/ISCID.2014.28, 10.1109/EDOCW.2009.5332010, 10.1109/CISPSSE49931.2020.9212200, 10.23919/CISTI54924.2022.9820078, 10.1109/ICONAT57137.2023.10080476, 10.1109/IPRECON52453.2021.9640748, 10.1109/IoTaIS47347.2019.8980380, 10.1109/IMCEC55388.2022.10019957, 10.1109/NBiS.2010.80, 10.1109/NBiS.2014.41, 10.1109/NBiS.2009.101, 10.1109/NBiS.2011.64, 10.23919/JCN.2021.000040, 10.1109/CCECE.2015.7129334, 10.1109/ICEIE.2010.5559691, 10.1109/ITHERM.2017.7992574, 10.1109/MASCOTS.2012.68, 10.1109/IIH-MSP.2014.168, 10.1109/SMART55829.2022.10046762, 10.1109/ISOCC50952.2020.9332945, 10.1109/ISTEL.2012.6483058, 10.1109/AUTEEE56487.2022.9994319, 10.1109/BigComp51126.2021.00039, 10.1109/ICAIIC48513.2020.9065016, 10.1109/USSEC53120.2021.9655724, 10.1109/ICTC49870.2020.9289575, 10.1109/ACIT53391.2021.9677130, 10.1109/IGSC51522.2020.9290876, 10.1109/ICDS50568.2020.9268733, 10.1109/SIN56466.2022.9970552, 10.1109/CCGrid.2015.130, 10.1109/GreenCom-iThings-CPSCom.2013.63, 10.1109/ISEEE.2017.8170657, 10.1109/SAS.2019.8705992, 10.1109/SAI.2016.7556035, 10.1109/ICCE46568.2020.9043049, 10.1109/CSCWD.2017.8066724, 10.1109/ICOIN.2013.6496385, 10.1109/PDGC.2014.7030770, 10.1109/IC2EW.2016.31, 10.1109/IINTEC48298.2019.9112111, 10.1109/WSCAR.2014.6916810, 10.1109/INFOTEH51037.2021.9400658, 10.23919/JCC.2022.04.020, 10.1109/SSCI51031.2022.10022120, 10.1109/IAECST57965.2022.10062173, 10.1109/ISCID.2014.147, 10.1109/ICCPC55978.2022.10072146, 10.1109/ICIRCA54612.2022.9985689, 10.1109/CIS.2014.171, 10.1109/IEEM.2017.8290152, 10.1109/MS.2015.83, 10.1109/MEES.2019.8896654, 10.1109/EM-COM.2009.5402965, 10.1109/RTUCON.2015.7343139, 10.1109/ELNANO.2017.7939795, 10.1109/SECON.2016.7506640, 10.1109/CompComm.2018.8780885, 10.1109/NCA.2016.7778625, 10.1109/LASCAS.2017.7948097, 10.1109/ASEW52652.2021.00057, 10.1109/NAS.2011.23, 10.1109/GLOCOM.2017.8254209, 10.1109/MDAT.2020.3021029, 10.23919/eMDC/ISSM48219.2019.9052110, 10.1109/CCNC51644.2023.10060678, 10.1109/LASCAS.2018.8399980, 10.1109/ICASSP.2018.8461624, 10.1109/CTSYS.2017.8109548, 10.1109/WSCAR.2016.24, 10.1109/LASCAS45839.2020.9069011, 10.1109/CANDAR.2017.44, 10.1109/IC3.2013.6612165, 10.1109/ICECS.2018.8618062, 10.1109/ICACCCT.2012.6320770, 10.1109/NBiS.2012.38, 10.1109/INFOCOMWKSHPS50562.2020.9162883, 10.1109/ICISCAE48440.2019.221685, 10.1109/ICACCI.2017.8125827, 10.1109/ICNC.2011.53, 10.1109/ICMTMA52658.2021.00012, 10.1109/LED.2023.3234690, 10.1109/SCSET55041.2022.00083, 10.1109/IFOST.2016.7884239, 10.1109/ICoICT.2019.8835371, 10.1109/IMTC.2003.1207899, 10.1109/CloudNet.2014.6969031, 10.1109/ICNC.2013.6818273, 10.1109/NEWCAS.2009.5290480, 10.1109/WAINA.2015.95, 10.1109/CSCS.2015.75, 10.1109/CCECE.2011.6030577, 10.1109/ICON.2007.4444133, 10.1109/JIOT.2019.2939874, 10.1109/TCNS.2019.2913563, 10.1109/SNPD.2015.7176219, 10.1109/GLOCOM.2018.8647732, 10.1109/SiPS.2014.6986056, 10.1109/ACCESS.2022.3151389, 10.1109/ACCESS.2020.3010571, 10.1109/ISSREW.2016.31, 10.1109/MC.2021.3120048, 10.1109/ICCE-ASIA.2018.8552101, 10.1109/IECON.2018.8592763, 10.1109/SMCIA.1999.782713, 10.1109/CCDC55256.2022.10033866, 10.1109/ICICT4SD50815.2021.9396928, 10.1109/CISIS.2011.41, 10.1109/CISIS.2016.82, 10.1109/MCSoC57363.2022.00041, 10.1109/ICPPW.2012.21, 10.1109/IGCC.2015.7393699, 10.1109/TSUSC.2019.2910129, 10.1109/TCC.2019.2922379, 10.1109/GreenCom-iThings-CPSCom.2013.40, 10.1109/ICDCS.2017.201, 10.1109/ITNEC.2019.8729195, 10.1109/LISAT.2016.7494148, 10.1109/ITNEC.2016.7560335, 10.1109/IAEAC54830.2022.9929778, 10.1109/APCC55198.2022.9943609, 10.1109/IGCC.2015.7393698, 10.23919/ANNSIM55834.2022.9859413, 10.1109/WiSEE.2019.8920332, 10.1109/TPDS.2013.183, 10.1109/ASAP52443.2021.00037, 10.1109/ISPASS.2017.7975264, 10.1109/FCCM53951.2022.9786072, 10.1109/ICCSP48568.2020.9182214, 10.1109/SDS.2017.7939151, 10.1109/WSCAD.2018.00020, 10.1109/ICSSA54161.2022.9870959, 10.1109/TCC.2015.2440238, 10.1109/CISIS.2012.29, 10.1109/ACCESS.2019.2949030, 10.1109/ICIIS53135.2021.9660662, 10.1109/ACCESS.2020.3034101, 10.1109/ICEET53442.2021.9659738, 10.1109/SIST54437.2022.9945776, 10.1109/ACCESS.2023.3268531, 10.1109/ISPASS51385.2021.00042, 10.1109/IDAACS.2003.1249508, 10.1109/ICCCRI.2015.17, 10.1109/ACCESS.2019.2955691, 10.1109/ISGT-Asia.2018.8467982, 10.1109/ACCESS.2020.2986078, 10.1109/UIC-ATC.2017.8397441, 10.1109/ICEAC.2010.5702284, 10.1109/ICECS202256217.2022.9970952, 10.1109/ISCON57294.2023.10112019, 10.1109/CloudCom.2015.49, 10.1109/ACCESS.2017.2778309, 10.1109/UKRCON.2019.8879787, 10.1109/ACCESS.2018.2872750, 10.1109/ISGTEurope.2017.8260289, 10.1109/ICICIS.2010.5534739, 10.1109/PSGEC54663.2022.9881195, 10.1109/ISWC.2005.52, 10.1109/ICBDACI.2017.8070811, 10.1109/SMICND.2011.6095842, 10.1109/CLUSTR.2009.5289179, 10.1109/CANDAR.2016.0105, 10.1109/SEAA.2015.34, 10.1109/NAS.2015.7255220, 10.1109/DSD53832.2021.00073, 10.4108/icst.iniscom.2015.258322, 10.1109/CCNC46108.2020.9045177, 10.1109/ISQED51717.2021.9424343, 10.1109/AIIoT52608.2021.9454222, 10.1145/2351676.2351699, 10.1109/GHTC55712.2022.9911022, 10.1109/DFT.2017.8244435, 10.1109/GreenCom-iThings-CPSCom.2013.50, 10.1109/ELECOM54934.2022.9965261, 10.1109/GLOBECOM38437.2019.9013647, 10.1109/SMC.2018.00244, 10.1109/TCSI.2018.2880363, 10.1109/IGCC.2012.6322289, 10.1109/TC.2019.2936018, 10.1109/INTERA.2003.1192356, 10.1109/CCGRID.2017.27, 10.1109/ICDCS.2017.235, 10.1109/HPCSim.2014.6903785, 10.1109/ACCESS.2019.2920010, 10.1109/ACCESS.2022.3194514, 10.23919/DATE54114.2022.9774589, 10.1109/SKIMA.2015.7400034, 10.1109/CloudCom.2012.6427493, 10.1109/ACCESS.2021.3094089, 10.1109/TPDS.2023.3240833, 10.1109/ISQED.2017.7918343, 10.1109/ACCESS.2017.2732458, 10.1109/JSAC.2015.2481198, 10.1109/GreenCom.2011.6082511, 10.1109/CloudTech.2017.8284743, 10.1109/ChinaGrid.2013.20, 10.1109/MED.2018.8442890, 10.1109/WCSP55476.2022.10039283, 10.1109/VLSI-SoC.2013.6673261, 10.1109/ICKECS56523.2022.10060481, 10.1109/TSC.2017.2648791, 10.1109/CLOUD.2015.104, 10.1109/NAS55553.2022.9925528, 10.1109/MC.2003.1250884, 10.1109/CLOUD.2012.31, 10.1109/CLOUD.2012.30, 10.1109/TCYB.2017.2703941, 10.1109/BWCCA.2015.67, 10.1109/TMC.2018.2857809, 10.1109/MASCOTS.2017.17, 10.1109/ICCP.2011.6047916, 10.1109/UCC.2015.50, 10.1109/NBiS.2013.6, 10.1109/CISIS.2013.23, 10.1109/L-CA.2013.24, 10.1109/ICOIN56518.2023.10048987, 10.1109/IJCNN.2017.7966398, 10.1109/ICWAPR54887.2021.9736149, 10.1109/ICCCRI.2016.24, 10.1109/VTC2020-Spring48590.2020.9128450, 10.1109/IC3I56241.2022.10072497, 10.1109/STCR55312.2022.10009610, 10.1109/ECCE57851.2023.10101532, 10.23919/WiOpt56218.2022.9930584, 10.1109/TSUSC.2020.3015559, 10.1109/JIOT.2018.2869226, 10.1109/DASC.2011.131, 10.1109/PES.2011.6039050, 10.1109/GREENS.2012.6224255, 10.1109/ACCESS.2018.2825648, 10.1109/JAS.2018.7511168, 10.1109/IPDPSW.2013.142, 10.1109/NCCA.2011.22, 10.1109/WIRLES.2005.1549573, 10.1109/ISCC.2016.7543890, 10.1109/MASCOTS.2013.33, 10.1109/ACCESS.2019.2915380, 10.1109/ACCESS.2020.3037205, 10.1109/DS-RT.2014.12, 10.1109/ICET.2018.8603582, 10.1109/ICWR51868.2021.9443133, 10.1109/ISVLSI49217.2020.00018, 10.1109/ISPRAS.2018.00014, 10.1109/HPCC.2014.59, 10.1109/ICCC49849.2020.9238837, 10.1109/ICCSN.2019.8905398, 10.1109/ICPET.2017.12, 10.1109/IECON.2016.7793863, 10.1109/CONIELECOMP.2013.6525773, 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics55523.2022.00069, 10.1109/CCWC47524.2020.9031113, 10.1109/ICCI-CC.2016.7862082, 10.1109/ICCCEEE49695.2021.9429615, 10.1109/CSCWD54268.2022.9776100, 10.1109/DAC.2018.8465881, 10.1109/GreenCom.2012.86, 10.1109/ICSM.2015.7332477, 10.1109/ICSME.2017.79, 10.1109/IGCC.2015.7393719, 10.1109/ICSE-SEIS.2017.10, 10.1109/FUZZ-IEEE.2015.7338079, 10.1109/PIMRC.2016.7794902, 10.1109/ICDCS.2012.12, 10.1109/SCAM.2017.18, 10.1109/IGCC.2018.8752151, 10.1109/IWCMC.2017.7986498, 10.1109/FCST.2015.47, 10.1109/ICREGA50506.2021.9388293, 10.1109/MCHPC56545.2022.00008, 10.1109/ISMSIT50672.2020.9255197, 10.1109/WSCAD-SSC.2012.26, 10.1109/ICESC51422.2021.9532707, 10.1109/ESEM.2017.39, 10.1109/MTV.2003.1250271, 10.1109/ACCESS.2018.2797881, 10.1109/MCOM.001.2200023, 10.1109/RTSI55261.2022.9905123, 10.1109/DSAA53316.2021.9564127, 10.1109/ICIS.2016.7550777, 10.1109/SOCC56010.2022.9908114, 10.1109/ICIT.2013.6505859, 10.1109/CLOUD.2015.108, 10.1109/IMTC.2008.4547122, 10.1109/SmartGridComm.2015.7436277, 10.1109/WCSP55476.2022.10039154, 10.1109/ISCC55528.2022.9912943, 10.1109/COMPSAC.2019.00081, 10.1109/EUROCON.2013.6625014, 10.1109/IWRSP.2004.1311094, 10.1109/GCWkshps56602.2022.10008564, 10.1109/ICCD.2017.28, 10.1109/IS57118.2022.10019658, 10.1109/MNET.2015.7064904, 10.1109/INDIN41052.2019.8972035, 10.1109/ACCESS.2020.3041442, 10.1109/ICICDT.2014.6838580, 10.1109/VTCFall.2018.8690629, 10.1109/ETS.2019.8791548, 10.1109/ACCESS.2022.3172287, 10.1109/ISLPED.2011.5993659, 10.1109/IPDPS.2010.5470464, 10.1109/I-SMAC55078.2022.9986504, 10.1109/DDECS54261.2022.9770153, 10.1109/IGCC.2014.7039145, 10.1109/HPCA.2002.995705, 10.1109/TC.2005.102, 10.1109/TIM.2009.2021646\n",
      "x ---------------------------- x\n",
      "411\n",
      "10\n",
      "421\n",
      "research on a virtual machine mode transfer method supporting energy consumption optimization\n"
     ]
    }
   ],
   "source": [
    "# import into zotero first_pool folder:\n",
    "ieee_df = titles_df_ieee_selected[titles_df_ieee_selected['keep_title']==1]\n",
    "\n",
    "str_current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_name = \"ieee_df_\"+str_current_datetime+\".csv\"\n",
    "# Uncomment HERE to save the results:\n",
    "# ieee_df.to_csv(file_name) \n",
    "\n",
    "ISBNs = ieee_df[ieee_df['DOI'].isnull().values]['ISBNs'].to_list()\n",
    "DOIs = ieee_df[ieee_df['DOI'].isnull().values == False]['DOI'].tolist()\n",
    "\n",
    "print(\"x ---------------------------- x\")\n",
    "print(\", \".join(ISBNs))\n",
    "print(\"x ---------------------------- x\")\n",
    "print(\", \".join(DOIs))\n",
    "print(\"x ---------------------------- x\")\n",
    "print(len(DOIs))\n",
    "print(len(ISBNs))\n",
    "print(len(DOIs + ISBNs))\n",
    "\n",
    "#look for duplicates with different DOIs:\n",
    "test = ieee_df['title'].tolist()\n",
    "test_dict = dict(Counter(test))\n",
    "for key in test_dict.keys():\n",
    "    if test_dict[key]>1:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to exclude:  688\n",
      "Number articles removed:  56\n",
      "Number articles newly removed:  56\n",
      "Number articles preserved:  137\n",
      "Check:  193 == 193\n"
     ]
    }
   ],
   "source": [
    "_path_acm=\"../1_initial_search/saved_results_other_datasources/acm/first_pool_acm.csv\"\n",
    "df = pd.DataFrame(pd.read_csv(_path_acm, encoding = 'unicode_escape', sep = ';'))\n",
    "\n",
    "my_columns = ['Title', 'ISBN', 'ISSN', 'DOI', 'URLs', 'Proceedings title', 'Abstract', 'Authors', \\\n",
    "              'Journal', 'Publication year', 'Date published', 'URLs']\n",
    "titles_df_acm = prepare_titles_df(df, my_columns, 'Title')\n",
    "\n",
    "# Apply excluding words:\n",
    "words = words_1 + words_2 + words_3 + words_4 + words_5\n",
    "titles_df_acm_selected = apply_excluding_2_words(words, titles_df_acm)\n",
    "check_proportions(words, titles_df_acm_selected, titles_df_acm)\n",
    "\n",
    "str_current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_name = \"acm_df_\"+str_current_datetime+\".csv\"\n",
    "acm_df = titles_df_acm_selected[titles_df_acm_selected['keep_title']==1]\n",
    "# Uncomment HERE to save the results:\n",
    "# acm_df.to_csv(file_name) \n",
    "\n",
    "acm_df_removed = titles_df_acm_selected[titles_df_acm_selected['keep_title']==0]\n",
    "acm_df_removed.to_csv('acm_removed.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not all element have an identifier (doi, isbn, issn). So we rather work with bib file to import in zotero.\n",
    "\n",
    "# acm_df = titles_df_acm_selected[titles_df_acm_selected['keep_title']==1]\n",
    "# DOIs = acm_df[acm_df['DOI'].isnull().values == False]['DOI'].to_list()\n",
    "# acm_df_no_doi = acm_df[acm_df['DOI'].isnull().values]\n",
    "# ISBNs = acm_df_no_doi[acm_df_no_doi['ISBN'].isnull().values == False]['ISBN'].tolist()\n",
    "# acm_df_no_doi_or_isbn = acm_df_no_doi[acm_df_no_doi['ISBN'].isnull().values]\n",
    "# # ISSNs = acm_df_no_doi_or_isbn[acm_df_no_doi_or_isbn['ISSN'].isnull().values == False]\n",
    "\n",
    "# # print(ISSNs)\n",
    "\n",
    "# print(\"x ---------------------------- x\")\n",
    "# print(\", \".join(ISBNs))\n",
    "# print(\"x ---------------------------- x\")\n",
    "# print(\", \".join(DOIs))\n",
    "# print(\"x ---------------------------- x\")\n",
    "# print(len(DOIs))\n",
    "# print(len(ISBNs))\n",
    "# print(\"check: \", acm_df.shape[0], \" == \", len(DOIs + ISBNs))\n",
    "# # print(len(ISSNs))\n",
    "# # print(len(DOIs + ISBNs + ISSNs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** We notice that Zotero has created some duplicates. Compared with the bib file directly downloaded from ACM, the csv file generated by zootero contains more results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "with open(\"../1_initial_search/saved_results_other_datasources/acm/first_pool_acm.bib\", \"r\") as f:\n",
    "    text = f.read()\n",
    "bib_list = text.split('\\n@')\n",
    "bib_reconstr = '\\n@'.join(bib_list)\n",
    "bib_dict = {}\n",
    "for elem in bib_list:\n",
    "    if elem[0]!='@':\n",
    "        elem = '@'+elem\n",
    "    title_match = re.search(r'title = {([^}]*)}', elem)\n",
    "    title = title_match.group(1)\n",
    "    bib_dict[title] = elem\n",
    "\n",
    "# print(bib_dict)\n",
    "\n",
    "print(len(bib_dict))\n",
    "\n",
    "bib_list_keep = []\n",
    "for key in bib_dict.keys():\n",
    "    row = titles_df_acm_selected[titles_df_acm_selected['original_title'] == key]\n",
    "#     print(key)\n",
    "    if row['keep_title'].values[0] == 1:\n",
    "        bib_list_keep.append(bib_dict[key])\n",
    "\n",
    "print(len(bib_list_keep))\n",
    "\n",
    "bib_reconstr_keep = '\\n'.join(bib_list_keep)\n",
    "    \n",
    "# Uncomment HERE to save:\n",
    "# with open(\"...\\\\1_initial_search\\\\saved_results_other_datasources\\\\acm\\\\test.bib\", \"w\") as f:\n",
    "#     f.write(bib_reconstr_keep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_SLR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
