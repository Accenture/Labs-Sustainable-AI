,original_title,ISBN,ISSN,DOI,URLs,Proceedings title,Abstract,Authors,Journal,Publication year,Date published,URLs,title,keep_title
2,A High-Frequency Monitoring Method for Urban Carbon Emissions Based on Vertical Federated Deep Learning and Multi-Source Heterogeneous Data Fusion Methods,"9,78145E+12",,10.1145/3582935.3582972,https://doi.org/10.1145/3582935.3582972;http://dx.doi.org/10.1145/3582935.3582972,Proceedings of the 5th International Conference on Information Technologies and Electrical Engineering,"Carbon emissions are the main culprit of global warming. Accurate carbon emission forecasting helps government departments formulate effective carbon emission reduction policies and helps the carbon emission market develop orderly. Implementing an accurate and effective carbon emission monitoring model requires the collaboration of many parties because carbon emission-related data involves many sectors and industries. However, for the relevant characteristics of carbon emission monitoring, due to the different collection and storage standards of various departments, poor maintenance environment, lack of data, data loss, and abnormal severe, resulting in high frequency and high precision carbon emission monitoring. As privacy protection and data security issues are gradually taken seriously by government departments and related enterprises, the inability or unwillingness to share carbon emission-related data among enterprises or even among various departments within enterprises has created an increasingly severe data silo phenomenon. In addition, how effectively breaking the data barriers between various sectors is an urgent problem in grasping carbon emission change changes accurately. Therefore, this paper proposes a carbon emission monitoring model for key urban sectors based on vertical federated deep learning and multi-source heterogeneous data fusion and sharing. The experimental results show that the model accurately predicts carbon emission change trends in various application scenarios under the data availability and invisibility of each participant.","Gao Y,Yan D,Liu N,Luo S,Zhou Z,Wang Y,Chen Y,Gao B",,2023,2023,https://doi.org/10.1145/3582935.3582972;http://dx.doi.org/10.1145/3582935.3582972,a high frequency monitoring method for urban carbon emissions based on vertical federated deep learning and multi source heterogeneous data fusion methods,0
5,Energy Expenditure Estimation Based on Artificial Intelligence and Microservice Architecture,"9,78145E+12",,10.1145/3380688.3380715,https://doi.org/10.1145/3380688.3380715;http://dx.doi.org/10.1145/3380688.3380715,Proceedings of the 4th International Conference on Machine Learning and Soft Computing,"Nutritional status plays an important role in not only pregnancy outcomes but also neonatal health. One of efficient techniques to control the nutritional status is to estimate the energy expenditure. There are some approaches for estimating energy expenditure. However, they have limitations including high cost, relative complexity, trained personnel requirements, or locality. This study investigates in a system for data collection and analysis (IoH-Internet of Health) developing based on microservice architecture, and its application for energy expenditure estimation. The proposed system has a good ability to scale and integrate with other systems; the energy expenditure estimation is performed by using artificial intelligence. The experimental results have shown the promising results of the proposed system.","Huynh HT,Quan HD",,2020,2020,https://doi.org/10.1145/3380688.3380715;http://dx.doi.org/10.1145/3380688.3380715,energy expenditure estimation based on artificial intelligence and microservice architecture,0
9,Chaos Prediction of Power Systems by Using Deep Learning,"9,78145E+12",,10.1145/3529836.3529843,https://doi.org/10.1145/3529836.3529843;http://dx.doi.org/10.1145/3529836.3529843,2022 14th International Conference on Machine Learning and Computing (ICMLC),"Ensuring the stability of power systems is an important issue that should be considered in order to ensure the social and economic development of a country. Therefore, predicting the chaotic behavior of power systems in order to develop protection measures and keep power systems stable is vital. In this paper, a deep learning algorithm was proposed to predict the chaotic behavior of power systems by using deep long short-term memory (DLSTM) networks, which have two forms: deep long short-term memory with static scenario (DLSTM-s) and deep long-term memory with dynamic scenario (DLSTM-d). The genetic algorithm was used to optimize the hyperparameters of the networks. Then, taking interconnected power systems as an example, the effectiveness of the proposed DLSTM network was verified via numerical simulation. Finally, the experimental results of the DLSTM network were compared with those of the echo state network, multi-recurrent neural network, deep gated recurrent unit, and long short-term memory. Experimental results illustrated that a trained DLSTM network can predict the chaotic behavior of power systems by using the time series data of a single state variable. Moreover, the DLSTM-s network proposed in this paper can achieve competitive prediction performance compared with other baseline methods.","Lu Y,Wei D",,2022,2022,https://doi.org/10.1145/3529836.3529843;http://dx.doi.org/10.1145/3529836.3529843,chaos prediction of power systems by using deep learning,0
12,GPU Power Prediction via Ensemble Machine Learning for DVFS Space Exploration,"9,78145E+12",,10.1145/3203217.3203273,https://doi.org/10.1145/3203217.3203273;http://dx.doi.org/10.1145/3203217.3203273,Proceedings of the 15th ACM International Conference on Computing Frontiers,"A software-based approach to achieve high performance within a power budget often involves dynamic voltage and frequency scaling (DVFS). Thus, accurately predicting the power consumption of an application at different DVFS levels (or more generally, different processor configurations) is paramount for the energy-efficient functioning of a high-performance computing (HPC) system. The increasing prevalence of graphics processing units (GPUs) in HPC systems presents new challenges in power management, and machine learning presents an unique way to improve the software-based power management of these systems. As such, we explore the problem of GPU power prediction at different DVFS states via machine learning. Specifically, we propose a new ensemble technique that incorporates three machine-learning techniques --- sequential minimal optimization regression, simple linear regression, and decision tree --- to reduce the mean absolute error (MAE) to 3.5%.","Dutta B,Adhinarayanan V,Feng WC",,2018,2018,https://doi.org/10.1145/3203217.3203273;http://dx.doi.org/10.1145/3203217.3203273,gpu power prediction via ensemble machine learning for dvfs space exploration,0
13,Power System Voltage Instability Monitoring with Artificial Neural Networks,"9,78288E+12",,,,Proceedings of the 7th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems,,Jeyasurya B,,1994,1994,,power system voltage instability monitoring with artificial neural networks,0
14,An Online Power System Dynamics Prediction Based on Deep Neural Network,"9,78145E+12",,10.1145/3277453.3277464,https://doi.org/10.1145/3277453.3277464;http://dx.doi.org/10.1145/3277453.3277464,Proceedings of the 2018 International Conference on Electronics and Electrical Engineering Technology,"Building Power analysis has drawn more and more attention in recent years. In this paper, we present a system for online power prediction for the public building. It is based on a 4-layers Deep Neural Network that use architectural metrics of the physical machines collected dynamically by our system to predict the physical machine power consumption. A real implementation of our system shows that the prediction accuracy could reach 76.50%.","Zhang B,Han J,Ren Y,Wen H,Song Z,Gan Q,Wei R,Dang X,Zhou B",,2018,2018,https://doi.org/10.1145/3277453.3277464;http://dx.doi.org/10.1145/3277453.3277464,an online power system dynamics prediction based on deep neural network,0
16,Machine Learning-Powered Mobile App for Predicting Used Car Prices,"9,78145E+12",,10.1145/3502300.3502307,https://doi.org/10.1145/3502300.3502307;http://dx.doi.org/10.1145/3502300.3502307,Proceedings of the 2021 3rd International Conference on Big-Data Service and Intelligent Computation,"Buying and selling used cars is a common practice in all countries. When looking to sell a car, the seller decides the price of their car after monitoring the prices of similar cars in the advertisements. When someone is looking to buy a car, they watch advertisements for similar cars to get an idea of the price of the car they want to purchase. Despite the availability of blue books that provide an estimate of automotive pricing, real market prices vary depending on demand and supply. In this paper, we applied cutting-edge machine learning techniques to automate this process. The training data set is up-to-date and it was collected from an active commercial website. We created semi-automated rule-based scripts to clean and prepare the data for machine learning. Several machine learning algorithms were explored to generate an approximate value for the car pricing, including Artificial Neural Network, Support Vector Machine, K-Nearest Neighbors, Random Forest, and Gradient Boosted Decision Tree. To determine the features that most affect the price, extensive data analysis and cleaning were undertaken. Our findings indicate that the testing accuracy is 90%. Finally, a mobile application was created that provides an estimated price of a given car's properties, guiding a user in determining the price of their car. The complete code and the data used to obtain these results can be accessed on GitHub at [1] [19].","Shanti N,Assi A,Shakhshir H,Salman A",,2022,2022,https://doi.org/10.1145/3502300.3502307;http://dx.doi.org/10.1145/3502300.3502307,machine learning powered mobile app for predicting used car prices,0
17,Application of Data Mining Based on Machine Learning in Automobile Power Prediction,"9,78145E+12",,10.1145/3501409.3501532,https://doi.org/10.1145/3501409.3501532;http://dx.doi.org/10.1145/3501409.3501532,Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering,"Automobile power prediction is the key to the automobile industry. Only by reasonably predicting the automobile power can we produce cars that meet the needs of consumers. Compared with traditional methods, machine learning model improves the accuracy of classification in power. Machine learning models include BP neural network, random forest and KNN algorithm. In order to select the optimal vehicle power prediction model, this paper compares the advantages and disadvantages of these three machine learning models through design experiments.",Zhang K,,2022,2022,https://doi.org/10.1145/3501409.3501532;http://dx.doi.org/10.1145/3501409.3501532,application of data mining based on machine learning in automobile power prediction,0
22,"Output PV Power Prediction Using an Artificial Neural Network in Casablanca, Morocco","9,78145E+12",,10.1145/3368756.3369084,https://doi.org/10.1145/3368756.3369084;http://dx.doi.org/10.1145/3368756.3369084,Proceedings of the 4th International Conference on Smart City Applications,"Optimal use of renewable energy requires its characterization and prediction to size detectors or estimate the potential of power plants [20-21]. In terms of prediction, electricity suppliers are interested in different horizons to manage power plants and predict their production [1-2]. This paper proposes a model for predicting the output power in photovoltaic (PV) panels installed on the rooftop of the Ben m'sik faculty at Hassan II University, Casablanca, Morocco, and this model is based on a multilayer perceptron (MLP) model. In this work, different combinations of weather variables were used to develop this model and for validate the proposed model results different practical measurement methods are used, such as mean square error (MSE), mean absolute error (MAE), correlation (R) and coefficient of determination (R2). The determination coefficient of the proposed model is 0.98501 with an RMSE value of 30.663. The proposed model was tested on new data, the results showed that the model works with a good preferment and that the prediction quality depends on the time of year with a determination coefficient of 0.9972, 0.9856, 0.9487 and 0.9942 for summer, autumn, winter and spring respectively.","Karami E,Rafi M,Ridah A",,2019,2019,https://doi.org/10.1145/3368756.3369084;http://dx.doi.org/10.1145/3368756.3369084,output pv power prediction using an artificial neural network in casablanca morocco,0
23,Worst-Case Dynamic Power Distribution Network Noise Prediction Using Convolutional Neural Network,"9,78145E+12",,10.1145/3489517.3530600,https://doi.org/10.1145/3489517.3530600;http://dx.doi.org/10.1145/3489517.3530600,Proceedings of the 59th ACM/IEEE Design Automation Conference,"Worst-case dynamic PDN noise analysis is an essential step in PDN sign-off to ensure the performance and reliability of chips. However, with the growing PDN size and increasing scenarios to be validated, it becomes very time- and resource-consuming to conduct full-stack PDN simulation to check the worst-case noise for different test vectors. Recently, various works have proposed machine learning based methods for supply noise prediction, many of which still suffer from large training overhead, inefficiency, or non-scalability. Thus, this paper proposed an efficient and scalable framework for the worst-case dynamic PDN noise prediction. The framework first reduces the spatial and temporal redundancy in the PDN and input current vector, and then employs efficient feature extraction as well as a novel convolutional neural network architecture to predict the worst-case dynamic PDN noise. Experimental results show that the proposed framework consistently outperforms the commercial tool and the state-of-the-art machine learning method with only 0.63--1.02% mean relative error and 25--69× speedup.","Dong X,Chen Y,Yin X,Zhuo C",,2022,2022,https://doi.org/10.1145/3489517.3530600;http://dx.doi.org/10.1145/3489517.3530600,worst case dynamic power distribution network noise prediction using convolutional neural network,0
30,DeepMMSE: A Deep Learning Approach to MMSE-Based Noise Power Spectral Density Estimation,,2329-9290,10.1109/TASLP.2020.2987441,https://doi.org/10.1109/TASLP.2020.2987441;http://dx.doi.org/10.1109/TASLP.2020.2987441,,"An accurate noise power spectral density (PSD) tracker is an indispensable component of a single-channel speech enhancement system. Bayesian-motivated minimum mean-square error (MMSE)-based noise PSD estimators have been the most prominent in recent time. However, they lack the ability to track highly non-stationary noise sources due to current methods of a priori signal-to-noise (SNR) estimation. This is caused by the underlying assumption that the noise signal changes at a slower rate than the speech signal. As a result, MMSE-based noise PSD trackers exhibit a large tracking delay and produce noise PSD estimates that require bias compensation. Motivated by this, we propose an MMSE-based noise PSD tracker that employs a temporal convolutional network (TCN) a priori SNR estimator. The proposed noise PSD tracker, called DeepMMSE makes no assumptions about the characteristics of the noise or the speech, exhibits no tracking delay, and produces an accurate estimate that requires no bias correction. Our extensive experimental investigation shows that the proposed DeepMMSE method outperforms state-of-the-art noise PSD trackers and demonstrates the ability to track abrupt changes in the noise level. Furthermore, when employed in a speech enhancement framework, the proposed DeepMMSE method is able to outperform state-of-the-art noise PSD trackers, as well as multiple deep learning approaches to speech enhancement. Availability: DeepMMSE is available at: https://github.com/anicolson/DeepXi.","Zhang Q,Nicolson A,Wang M,Paliwal KK,Wang C","IEEE/ACM Trans. Audio, Speech and Lang. Proc.",2020,2020-05,https://doi.org/10.1109/TASLP.2020.2987441;http://dx.doi.org/10.1109/TASLP.2020.2987441,deepmmse a deep learning approach to mmse based noise power spectral density estimation,0
33,Predicting Energy Consumption Relevant Indicators of Strong Scaling HPC Applications for Different Compute Resource Configurations,"9,78151E+12",,,,Proceedings of the Symposium on High Performance Computing,"Finding the best energy-performance tradeoffs for High Performance Computing (HPC) applications is a major challenge for many modern supercomputing centers. With the increased focus on data center energy efficiency and the emergence of possible data center power constraints, making the right decision at a given time is becoming more important. A real-world situation like ""can a given 1000 compute node application be executed at a maximum of 2.7 GHz CPU frequency without going over the energy provider defined power band, or the available monthly energy limit?"" is just one example of the types of decisions HPC data centers will face. The previously developed Adaptive Energy and Power Consumption Prediction (AEPCP) model answers this question for the case of a fixed CPU frequency. This paper will extend the AEPCP process to enable the development of analytical models for estimating application execution time, power, and energy consumptions as functions of the number of compute nodes and maximum operating CPU frequency. Based on these analytical models, an adaptive model (Lightweight Adaptive Consumption Prediction (LACP)) is presented that implements the extended prediction process. This information allows for improved estimation of potential energy-performance costs and tradeoffs of applications and thus identifies the optimal resource configuration for specific data center boundary conditions.","Shoukourian H,Wilde T,Auweter A,Bode A,Tafani D",,2015,2015,,predicting energy consumption relevant indicators of strong scaling hpc applications for different compute resource configurations,0
34,Pathogenicity Prediction of Single Amino Acid Variants With Machine Learning Model Based on Protein Structural Energies,,1545-5963,10.1109/TCBB.2021.3139048,https://doi.org/10.1109/TCBB.2021.3139048;http://dx.doi.org/10.1109/TCBB.2021.3139048,,"The most popular tools for predicting pathogenicity of single amino acid variants (SAVs) were developed based on sequence-based techniques. SAVs may change protein structure and function. In the context of van der Waals force and disulfide bridge calculations, no method directly predicts the impact of mutations on the energies of the protein structure. Here, we combined machine learning methods and energy scores of protein structures calculated by Rosetta Energy Function 2015 to predict SAV pathogenicity. The accuracy level of our model (0.76) is higher than that of six prediction tools. Further analyses revealed that the differential reference energies, attractive energies, and solvation of polar atoms between wildtype and mutant side-chains played essential roles in distinguishing benign from pathogenic variants. These features indicated the physicochemical properties of amino acids, which were observed in 3D structures instead of sequences. We added 16 features to Rhapsody (the prediction tool we used for our data set) and consequently improved its performance. The results indicated that these energy scores were more appropriate and more detailed representations of the pathogenicity of SAVs.","Wu TH,Lin PC,Chou HH,Shen MR,Hsieh SY",IEEE/ACM Trans. Comput. Biol. Bioinformatics,2022,2022-12,https://doi.org/10.1109/TCBB.2021.3139048;http://dx.doi.org/10.1109/TCBB.2021.3139048,pathogenicity prediction of single amino acid variants with machine learning model based on protein structural energies,0
35,Neural Network-Based Prediction Algorithms for In-Door Multi-Source Energy Harvesting System for Non-Volatile Processors,"9,78145E+12",,10.1145/2902961.2903037,https://doi.org/10.1145/2902961.2903037;http://dx.doi.org/10.1145/2902961.2903037,Proceedings of the 26th Edition on Great Lakes Symposium on VLSI,"Due to size, longevity, safety, and recharging concerns, energy harvesting is becoming a better choice for many wearable embedded systems than batteries. However, harvested energy is intrinsically unstable. In order to overcome this drawback, non-volatile processors (NVPs) have been proposed to bridge intermittent program execution. However, even with NVPs, frequent power interruptions will severely degrade system performance. Hence, in this paper we adopt a multi-source in-door energy harvesting architecture to compensate the shortcoming of single energy source. We further investigate power harvesting prediction techniques, which are critical for NVP systems since they can coordinate with task scheduler in the NVP system to compensate the intermittent ambient energy harvesting. We investigate prediction methods both for single energy harvesting source and for multiple energy harvesting sources, the total output power of which is more stable compared with the single source case. A comprehensive evaluation framework has been developed using actually measured harvesting traces on the proposed neural network-based power harvesting prediction methods. It turns out that the most favorable prediction methods are directly predicting the total output power of DC-DC converters (connecting between energy sources and NVP), or predicting the total input power of DC-DC converters first and then inferring the total output power using a learned mapping function, for multi-source power harvesting predictions.","Liu N,Ding C,Wang Y,Hu J",,2016,2016,https://doi.org/10.1145/2902961.2903037;http://dx.doi.org/10.1145/2902961.2903037,neural network based prediction algorithms for in door multi source energy harvesting system for non volatile processors,0
38,Deployment of a Machine Learning System for Predicting Lawsuits Against Power Companies: Lessons Learned from an Agile Testing Experience for Improving Software Quality,"9,78145E+12",,10.1145/3439961.3439991,https://doi.org/10.1145/3439961.3439991;http://dx.doi.org/10.1145/3439961.3439991,Proceedings of the XIX Brazilian Symposium on Software Quality,"The advances in Machine Learning (ML) require software organizations to evolve their development processes in order to improve the quality of ML systems. Within the software development process, the testing stage of an ML system is more critical, considering that it is necessary to add data validation, trained model quality evaluation, and model validation to traditional unit, integration tests and system tests. In this paper, we focus on reporting the lessons learned of using model testing and exploratory testing within the context of the agile development process of an ML system that predicts lawsuits proneness in energy supply companies. Through the development of the project, the SCRUM agile methodology was applied and activities related to the development of the ML model and the development of the end-user application were defined. After the testing process of the ML model, we managed to achieve 93.89 accuracy; 95.58 specificity; 88.84 sensitivity; and 87.09 precision. Furthermore, we focused on the quality of use of the application embedding the ML model, by carrying out exploratory testing. As a result, through several iterations, different types of defects were identified and corrected. Our lessons learned support software engineers willing to develop ML systems that consider both the ML model and the end-user application.","Rivero L,Diniz J,Silva G,Borralho G,Braz Junior G,Paiva A,Alves E,Oliveira M",,2021,2021,https://doi.org/10.1145/3439961.3439991;http://dx.doi.org/10.1145/3439961.3439991,deployment of a machine learning system for predicting lawsuits against power companies lessons learned from an agile testing experience for improving software quality,0
39,Machine Learning Predictive Model for the Passive Transparency at the Brazilian Ministry of Mines and Energy,"9,78145E+12",,10.1145/3463677.3463715,https://doi.org/10.1145/3463677.3463715;http://dx.doi.org/10.1145/3463677.3463715,DG.O2021: The 22nd Annual International Conference on Digital Government Research,"This paper presents a case study based on the CRISP-DM Model and the use of Text Mining tools and techniques to automate the Passive Transparency process at the Brazilian Ministry of Mines and Energy. Thus, a Machine Learning Model is proposed to predict the class of the technical unit responsible for the data/information requested by citizens. Through the application of the algorithm LDA and TF-IDF it was possible to map the topics of the most relevant subjects for society. The stability of the model was tested from the comparative analysis between 5 known classification algorithms (Random Forest, Multinomial NB, Linear SVC, Logistic Regression, XGBoost and Gradient Boosting). XGBoost presented better performance and precision in multiclass learning outcomes.","Palma I,Ladeira M,Reis AC",,2021,2021,https://doi.org/10.1145/3463677.3463715;http://dx.doi.org/10.1145/3463677.3463715,machine learning predictive model for the passive transparency at the brazilian ministry of mines and energy,0
41,Machine Learning Approach for Fast Electromigration Aware Aging Prediction in Incremental Design of Large Scale On-Chip Power Grid Network,,1084-4309,10.1145/3399677,https://doi.org/10.1145/3399677;http://dx.doi.org/10.1145/3399677,,"With the advancement of technology nodes, Electromigration (EM) signoff has become increasingly difficult, which requires a considerable amount of time for an incremental change in the power grid (PG) network design in a chip. The traditional Blacks empirical equation and Blechs criterion are still used for EM assessment, which is a time-consuming process. In this article, for the first time, we propose a machine learning (ML) approach to obtain the EM-aware aging prediction of the PG network. We use neural network--based regression as our core ML technique to instantly predict the lifetime of a perturbed PG network. The performance and accuracy of the proposed model using neural network are compared with the well-known standard regression models. We also propose a new failure criterion based on which the EM-aging prediction is done. Potential EM-affected metal segments of the PG network is detected by using a logistic-regression--based classification ML technique. Experiments on different standard PG benchmarks show a significant speedup for our ML model compared to the state-of-the-art models. The predicted value of MTTF for different PG benchmarks using our approach is also better than some of the state-of-the-art MTTF prediction models and comparable to the other accurate models.","Dey S,Nandi S,Trivedi G",ACM Trans. Des. Autom. Electron. Syst.,2020,2020-07,https://doi.org/10.1145/3399677;http://dx.doi.org/10.1145/3399677,machine learning approach for fast electromigration aware aging prediction in incremental design of large scale on chip power grid network,0
42,Automatic Inspection Drone with Deep Learning-Based Auto-Tracking Camera Gimbal to Detect Defects in Power Lines,"9,78145E+12",,10.1145/3387168.3387176,https://doi.org/10.1145/3387168.3387176;http://dx.doi.org/10.1145/3387168.3387176,"Proceedings of the 3rd International Conference on Vision, Image and Signal Processing","The traditional drone inspection performed by human operators is unsuited for the purpose of inspecting power transmission lines, because steel towers and their spans are too high and wide to be inspected with a 250 m line of sight. For this reason, the KEPCO Research Institute developed a new inspection drone system that can automatically fly a predetermined flight path based on the GPS coordinates of steel towers, filming a video of power transmission lines with a high definition camera and a thermal imaging camera. In this system, a camera gimbal with the cameras was still controlled by a human operator from a long distance away. When the drone approached close to a steel tower, however, the camera gimbal was often unable to be controlled and real-time video transmission for the gimbal operator was sometimes interrupted due to radio-frequency interference from steel structure and energized power conductors. To solve such a control problem in the field, we also developed an auto-tracking camera gimbal that can automatically track and photograph power facilities on the basis of Deep Learning. With the automatic gimbal, the entire inspection process can be fully automated. The effectiveness of the developed overall system was confirmed through field tests.","Park JY,Kim ST,Lee JK,Ham JW,Oh KY",,2020,2020,https://doi.org/10.1145/3387168.3387176;http://dx.doi.org/10.1145/3387168.3387176,automatic inspection drone with deep learning based auto tracking camera gimbal to detect defects in power lines,0
43,Optimization of Neural Network through Genetic Algorithm Searches for the Prediction of International Crude Oil Price Based on Energy Products Prices,"9,78145E+12",,10.1145/2597917.2597956,https://doi.org/10.1145/2597917.2597956;http://dx.doi.org/10.1145/2597917.2597956,Proceedings of the 11th ACM Conference on Computing Frontiers,"This study investigated the prediction of crude oil price based on energy product prices using genetically optimized Neural Network (GANN). It was found from experimental evidence that the international crude oil price can be predicted based on energy product prices. The comparison of the prediction performance accuracy of the propose GANN with Support Vector Machine (SVM), Vector Autoregression (VAR), and Feed Forward NN (FFNN) suggested that the propose GANN was more accurate than the SVM, VAR, and FFNN in the prediction accuracy and time computational complexity. The propose GANN was able to improve the performance accuracy of the comparison algorithms. Our approach can easily be modified for the prediction of similar commodities.","Chiroma H,Gital AY,Abubakar A,Usman MJ,Waziri U",,2014,2014,https://doi.org/10.1145/2597917.2597956;http://dx.doi.org/10.1145/2597917.2597956,optimization of neural network through genetic algorithm searches for the prediction of international crude oil price based on energy products prices,0
46,Traffic Prediction Based Power Saving in Cellular Networks: A Machine Learning Method,"9,78145E+12",,10.1145/3139958.3140053,https://doi.org/10.1145/3139958.3140053;http://dx.doi.org/10.1145/3139958.3140053,Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,"In smart cities, green cellular networks play a crucial role to support wireless access for numerous devices anywhere and anytime with efficiency and sustainability. Because base stations (BSes) consume more than 70% of overall cellular network infrastructure energy, saving the power consumption of BSes is the key task to build a green cellular network. Except for low power design of the BS hardware and software, the traffic-driven BS sleeping operation is an economical way to improve existing cellular networks, which can reduce the BS power consumption at low traffic load. However, prior BS sleeping strategies establish on the static temporal characteristics of traffic load, which ignore the fact that network traffic is influenced by many factors such as time, human mobility, holiday, weather, etc. Hence, prior traffic estimation is coarse, and the BS sleeping strategies cannot apply to the changing network traffic. In this paper, we exploit a machine learning method to estimate the BS traffic and propose a BS sleeping strategy based on predicted traffic for power saving in the cellular network. We analyze network traffic in multi-views: temporal influence, spatial influence, and event influence. Then, we propose a multi-view ensemble learning model to predict network traffic load, which learns the traffic in multi-views and combine the results with ensemble. Furthermore, we formulate a BS sleeping strategy based on the predicted traffic load. Finally, we evaluate our traffic prediction algorithm on real cellular network data. The evaluation shows that our traffic prediction algorithm improves about 40% than state-of-the-art machine learning methods. Also, we evaluate the proposed BS sleeping strategy, which yields about 10% more energy savings and less device damage than the competitors in the simulated environment.","Zhang S,Zhao S,Yuan M,Zeng J,Yao J,Lyu MR,King I",,2017,2017,https://doi.org/10.1145/3139958.3140053;http://dx.doi.org/10.1145/3139958.3140053,traffic prediction based power saving in cellular networks a machine learning method,0
50,MaxTracker: Continuously Tracking the Maximum Computation Progress for Energy Harvesting ReRAM-Based CNN Accelerators,,1539-9087,10.1145/3477009,https://doi.org/10.1145/3477009;http://dx.doi.org/10.1145/3477009,,"There is an ongoing trend to increasingly offload inference tasks, such as CNNs, to edge devices in many IoT scenarios. As energy harvesting is an attractive IoT power source, recent ReRAM-based CNN accelerators have been designed for operation on harvested energy. When addressing the instability problems of harvested energy, prior optimization techniques often assume that the load is fixed, overlooking the close interactions among input power, computational load, and circuit efficiency, or adapt the dynamic load to match the just-in-time incoming power under a simple harvesting architecture with no intermediate energy storage.Targeting a more efficient harvesting architecture equipped with both energy storage and energy delivery modules, this paper is the first effort to target whole system, end-to-end efficiency for an energy harvesting ReRAM-based accelerator. First, we model the relationships among ReRAM load power, DC-DC converter efficiency, and power failure overhead. Then, a maximum computation progress tracking scheme (MaxTracker) is proposed to achieve a joint optimization of the whole system by tuning the load power of the ReRAM-based accelerator. Specifically, MaxTracker accommodates both continuous and intermittent computing schemes and provides dynamic ReRAM load according to harvesting scenarios.We evaluate MaxTracker over four input power scenarios, and the experimental results show average speedups of 38.4%/40.3% (up to 51.3%/84.4%), over a full activation scheme (with energy storage) and order-of-magnitude speedups over the recently proposed (energy storage-less) ResiRCA technique. Furthermore, we also explore MaxTracker in combination with the Capybara reconfigurable capacitor approach to offer more flexible tuners and thus further boost the system performance.","Qiu K,Jao N,Zhou K,Liu Y,Sampson J,Kandemir MT,Narayanan V",ACM Trans. Embed. Comput. Syst.,2021,2021-09,https://doi.org/10.1145/3477009;http://dx.doi.org/10.1145/3477009,maxtracker continuously tracking the maximum computation progress for energy harvesting reram based cnn accelerators,0
63,A Low-Energy Computation Platform for Data-Driven Biomedical Monitoring Algorithms,"9,78145E+12",,10.1145/2024724.2024861,https://doi.org/10.1145/2024724.2024861;http://dx.doi.org/10.1145/2024724.2024861,Proceedings of the 48th Design Automation Conference,"A key challenge in closed-loop chronic biomedical systems is the ability to detect complex physiological states from patient signals within a constrained power budget. Data-driven machine-learning techniques are major enablers for the modeling and interpretation of such states. Their computational energy, however, scales with the complexity of the required models. In this paper, we propose a low-energy, biomedical computation platform optimized through the use of an accelerator for data-driven classification. The accelerator retains selective flexibility through hardware reconfiguration and exploits voltage scaling and parallelism to operate at a sub-threshold minimum-energy point. Using cardiac arrhythmia detection algorithms with patient data from the MIT-BIH database, classification is achieved in 2.96 ?J (at Vdd = 0.4 V), over four orders of magnitude smaller than that on a low-power general-purpose processor. The energy of feature extraction is 148 ?J while retaining flexibility for a range of possible biomarkers.","Shoaib M,Jha N,Verma N",,2011,2011,https://doi.org/10.1145/2024724.2024861;http://dx.doi.org/10.1145/2024724.2024861,a low energy computation platform for data driven biomedical monitoring algorithms,0
66,Accelerated Computation and Tracking of AC Optimal Power Flow Solutions Using GPUs,"9,78145E+12",,10.1145/3547276.3548631,https://doi.org/10.1145/3547276.3548631;http://dx.doi.org/10.1145/3547276.3548631,Workshop Proceedings of the 51st International Conference on Parallel Processing,"We present a scalable solution method based on an alternating direction method of multipliers and graphics processing units (GPUs) for rapidly computing and tracking a solution of alternating current optimal power flow (ACOPF) problem. Such a fast computation is particularly useful for mitigating the negative impact of frequent load and generation fluctuations on the optimal operation of a large electrical grid. To this end, we decompose a given ACOPF problem by grid components, resulting in a large number of small independent nonlinear nonconvex optimization subproblems. The computation time of these subproblems is significantly accelerated by employing the massive parallel computing capability of GPUs. In addition, the warm-start ability of our method leads to faster convergence, making the method particularly suitable for fast tracking of optimal solutions. We demonstrate the performance of our method on a 70,000 bus system by solving associated optimal power flow problems with both cold start and warm start.","Kim Y,Kim K",,2023,2023,https://doi.org/10.1145/3547276.3548631;http://dx.doi.org/10.1145/3547276.3548631,accelerated computation and tracking of ac optimal power flow solutions using gpus,0
83,Battery Lifetime Prediction for Energy-Aware Computing,"9,78158E+12",,10.1145/566408.566449,https://doi.org/10.1145/566408.566449;http://dx.doi.org/10.1145/566408.566449,Proceedings of the 2002 International Symposium on Low Power Electronics and Design,"Predicting the time of full discharge of a finite-capacity energy source, such as a battery, is important for the design of portable electronic systems and applications. In this paper we present a novel analytical model of a battery that not only can be used to predict battery lifetime, but also can serve as a cost function for optimization of the energy usage in battery-powered systems. The model is physically justified, and involves only two parameters, which are easily estimated. The paper includes the results of extensive experimental evaluation of the model with respect to numerical simulations of the electrochemical cell, as well as measurements taken on a real battery. The model was tested using constant, interrupted, periodic and non-periodic discharge profiles, which were derived from standard applications run on a pocket computer.","Rakhmatov D,Vrudhula S,Wallach DA",,2002,2002,https://doi.org/10.1145/566408.566449;http://dx.doi.org/10.1145/566408.566449,battery lifetime prediction for energy aware computing,0
84,Evaluating Cloud Computing Techniques for Smart Power Grid Design Using Parallel Scripting,,,10.1109/CCGrid.2013.26,https://doi.org/10.1109/CCGrid.2013.26;http://dx.doi.org/10.1109/CCGrid.2013.26,"Proceedings of the 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing","Applications used to evaluate next-generation electrical power grids (""smart grids"") are anticipated to be compute and data-intensive. In this work, we parallelize and improve performance of one such application which was run sequentially prior to the use of our cloud-based configuration. We examine multiple cloud computing offerings, both commercial and academic, to evaluate their potential for improving the turnaround time for application results. Since the target application does not fit well into existing computational paradigms for the cloud, we employ parallel scripting tool, as a first step toward a broader program of adapting portable, scalable computational tools for use as enablers of the future smart grids. We use multiple clouds as a way to reassure potential users that the risk of cloud-vendor lock-in can be managed. This paper discusses our methods and results. Our experience sheds light on some of the issues facing computational scientists and engineers tasked with adapting new paradigms and infrastructures for existing engineering design problems.","Maheshwari K,Birman K,Wozniak JM,Van Zandt D",,2013,2013,https://doi.org/10.1109/CCGrid.2013.26;http://dx.doi.org/10.1109/CCGrid.2013.26,evaluating cloud computing techniques for smart power grid design using parallel scripting,0
92,Mining Questions about Software Energy Consumption,"9,78145E+12",,10.1145/2597073.2597110,https://doi.org/10.1145/2597073.2597110;http://dx.doi.org/10.1145/2597073.2597110,Proceedings of the 11th Working Conference on Mining Software Repositories,"A growing number of software solutions have been proposed to address application-level energy consumption problems in the last few years. However, little is known about how much software developers are concerned about energy consumption, what aspects of energy consumption they consider important, and what solutions they have in mind for improving energy efficiency. In this paper we present the first empirical study on understanding the views of application programmers on software energy consumption problems. Using StackOverflow as our primary data source, we analyze a carefully curated sample of more than 300 questions and 550 answers from more than 800 users. With this data, we observed a number of interesting findings. Our study shows that practitioners are aware of the energy consumption problems: the questions they ask are not only diverse -- we found 5 main themes of questions -- but also often more interesting and challenging when compared to the control question set. Even though energy consumption-related questions are popular when considering a number of different popularity measures, the same cannot be said about the quality of their answers. In addition, we observed that some of these answers are often flawed or vague. We contrast the advice provided by these answers with the state-of-the-art research on energy consumption. Our summary of software energy consumption problems may help researchers focus on what matters the most to software developers and end users.","Pinto G,Castor F,Liu YD",,2014,2014,https://doi.org/10.1145/2597073.2597110;http://dx.doi.org/10.1145/2597073.2597110,mining questions about software energy consumption,0
101,GreenMiner: A Hardware Based Mining Software Repositories Software Energy Consumption Framework,"9,78145E+12",,10.1145/2597073.2597097,https://doi.org/10.1145/2597073.2597097;http://dx.doi.org/10.1145/2597073.2597097,Proceedings of the 11th Working Conference on Mining Software Repositories,"Green Mining is a field of MSR that studies software energy consumption and relies on software performance data. Unfortunately there is a severe lack of publicly available software power use performance data. This means that green mining researchers must generate this data themselves by writing tests, building multiple revisions of a product, and then running these tests multiple times (10+) for each software revision while measuring power use. Then, they must aggregate these measurements to estimate the energy consumed by the tests for each software revision. This is time consuming and is made more difficult by the constraints of mobile devices and their OSes. In this paper we propose, implement, and demonstrate Green Miner: the first dedicated hardware mining software repositories testbed. The Green Miner physically measures the energy consumption of mobile devices (Android phones) and automates the testing of applications, and the reporting of measurements back to developers and researchers. The Green Miner has already produced valuable results for commercial Android application developers, and has been shown to replicate other power studies' results.","Hindle A,Wilson A,Rasmussen K,Barlow EJ,Campbell JC,Romansky S",,2014,2014,https://doi.org/10.1145/2597073.2597097;http://dx.doi.org/10.1145/2597073.2597097,greenminer a hardware based mining software repositories software energy consumption framework,0
104,Power and Performance Estimation for Fine-Grained Server Power Capping via Controlling Heterogeneous Applications,,2158-656X,10.1145/3086449,https://doi.org/10.1145/3086449;http://dx.doi.org/10.1145/3086449,,"Power capping is a method to save power consumption of servers by limiting performance of the servers. Although users frequently run applications on different virtual machines (VMs) for keeping their performance and having them isolated from the other applications, power capping may degrade performance of all the applications running on the server. We present fine-grained power capping by limiting performance of each application individually. For keeping performance defined in Quality of Service (QoS) requirements, it is important to estimate applications performance and power consumption after the fine-grained power capping is applied. We propose the estimation method of physical CPU usage when limiting virtual CPU usage of applications on VMs. On servers where multiple VMs run, VMs usage of physical CPU is interrupted by the other VMs, and a hypervisor uses physical CPU to control VMs. These VMs and hypervisors behaviors make it difficult to estimate performance and power consumption by straightforward methods, such as linear regression and polynomial regression. The proposed method uses Piecewise Linear Regression to estimate physical CPU usage by assuming that VMs access to physical CPU is not interrupted by the other VMs. Then we estimate how much physical CPU usage is reduced by the interruption. Because physical CPU usage is not stable soon after limiting CPU usage, the proposed method estimates a convergence value of CPU usage after many interruptions are repeated.","Ha TM,Samejima M,Komoda N",ACM Trans. Manage. Inf. Syst.,2017,2017-08,https://doi.org/10.1145/3086449;http://dx.doi.org/10.1145/3086449,power and performance estimation for fine grained server power capping via controlling heterogeneous applications,0
109,Study Effect of Information and Communication Technology (ICT) on Energy Consumption and Greenhouse Gas Emissions in Selected Oil-Producing Countries,"9,78145E+12",,10.1145/3527049.3527123,https://doi.org/10.1145/3527049.3527123;http://dx.doi.org/10.1145/3527049.3527123,Proceedings of the 3rd International Scientific Conference on Innovations in Digital Economy,"The current trend of increasing energy consumption in the world has brought about two major crises for humanity. The first one is environmental pollution and the running out of energy resources. Energy supply is one of the fundamental requirements of economic development and improving the quality of human life. Since the industrial revolution in the mid-18th century, the ever-growing consumption of energy in the world has been continued. Further, Carbon Dioxide emitted during the combustion of fossil fuels has exerted irreversible and threatening changes in the world. Today, experts and researchers are looking for sustainable development and some strategies to reduce energy consumption and environmental pollution. Using ICT has been considered to be one of the effective solutions to achieve these goals. Due to the adverse economic and environmental consequences, as well as the continuous increase of greenhouse gas emissions, there is an emergent need to conduct some inquiries to identify the source of problems and propose some efficient coping strategies. The present study is conducted to investigate the relationship between carbon dioxide emissions, energy consumption, ICT development index, and economic growth. For this purpose, the data panel method was utilized for selected oil producing countries from 1998 to 2011. The results of model estimation revealed that the Kuznets hypothesis was confirmed in the period under investigation and also the development of ICT had a positive effect on reducing energy consumption and air pollution.","Rodionov D,Daniali S,Khortabi F,Moqaddasnejad A",,2022,2022,https://doi.org/10.1145/3527049.3527123;http://dx.doi.org/10.1145/3527049.3527123,study effect of information and communication technology ict on energy consumption and greenhouse gas emissions in selected oil producing countries,0
112,Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet,"9,78158E+12",,10.1145/605397.605408,https://doi.org/10.1145/605397.605408;http://dx.doi.org/10.1145/605397.605408,Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems,"Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.","Juang P,Oki H,Wang Y,Martonosi M,Peh LS,Rubenstein D",,2002,2002,https://doi.org/10.1145/605397.605408;http://dx.doi.org/10.1145/605397.605408,energy efficient computing for wildlife tracking design tradeoffs and early experiences with zebranet,0
113,Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet,,0163-5964,10.1145/635506.605408,https://doi.org/10.1145/635506.605408;http://dx.doi.org/10.1145/635506.605408,,"Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.","Juang P,Oki H,Wang Y,Martonosi M,Peh LS,Rubenstein D",SIGARCH Comput. Archit. News,2002,2002-10,https://doi.org/10.1145/635506.605408;http://dx.doi.org/10.1145/635506.605408,energy efficient computing for wildlife tracking design tradeoffs and early experiences with zebranet,0
114,Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet,,0362-1340,10.1145/605432.605408,https://doi.org/10.1145/605432.605408;http://dx.doi.org/10.1145/605432.605408,,"Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.","Juang P,Oki H,Wang Y,Martonosi M,Peh LS,Rubenstein D",SIGPLAN Not.,2002,2002-10,https://doi.org/10.1145/605432.605408;http://dx.doi.org/10.1145/605432.605408,energy efficient computing for wildlife tracking design tradeoffs and early experiences with zebranet,0
115,Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet,,0163-5980,10.1145/635508.605408,https://doi.org/10.1145/635508.605408;http://dx.doi.org/10.1145/635508.605408,,"Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.","Juang P,Oki H,Wang Y,Martonosi M,Peh LS,Rubenstein D",SIGOPS Oper. Syst. Rev.,2002,2002-10,https://doi.org/10.1145/635508.605408;http://dx.doi.org/10.1145/635508.605408,energy efficient computing for wildlife tracking design tradeoffs and early experiences with zebranet,0
116,On Reducing Computational Complexity in Evaluating the Topological Survivability of Power Systems,,,,,Proceedings of the 2010 Conference on Grand Challenges in Modeling & Simulation,"The topological survivability of a power system is the system ability due to its topology -- the number of system elements that generate and demand power and connections between them -- to supply power to loads under massive sudden damage. Previously we showed that the topological survivability of a power system can be quantified by analyzing the impact of all possible combinations of unrecoverable faults (fault scenarios) on the availability and connectivity of the system elements. The number of possible fault scenarios grows as 2M with increasing the number M of the system elements. Clearly, such an analysis is a computational challenge for large-scale systems. The paper discusses possibilities of reducing computational complexity of the problem.",Poroseva SV,,2010,2010,,on reducing computational complexity in evaluating the topological survivability of power systems,0
120,An Information Monitoring Platform for Thermal Energy Storage Systems Using Cloud Computing,"9,78145E+12",,10.1145/3291064.3291069,https://doi.org/10.1145/3291064.3291069;http://dx.doi.org/10.1145/3291064.3291069,Proceedings of the 2018 International Conference on Cloud Computing and Internet of Things,"Energy storage plays a key element to use new energy to replace traditional coal and petrochemical energy, and it plays an important role of shifting energy utilization ways. Nowadays energy internet is a way of renewable and sharing energy. A cloud platform for monitoring energy information of thermal storage systems is developed by using cloud computing, IoT and energy storage technologies. This platform allows a user to monitor the running conditions of regional thermal energy systems in real-time from anywhere as the condition data are synchronized to the client-side website, and data are stored into a data storage server. To quickly locate any thermal energy storage system, the geographical locations of the systems built anywhere are marked on the map of the web page. The condition data of all systems can be collected and communicated between the control unit installed in the heat system and the servers on cloud. The gathered data can be worked out for further allocating energy consumption. This platform has been launched after successfully tested on a number of practical thermal energy storage systems at different regions. This will provide a guarantee for further intelligent analysis and optimization of energy deployment.","Liu J,Chang Y,Wei D,Wang D,Zhang T",,2018,2018,https://doi.org/10.1145/3291064.3291069;http://dx.doi.org/10.1145/3291064.3291069,an information monitoring platform for thermal energy storage systems using cloud computing,0
123,"Interrelations between Software Quality Metrics, Performance and Energy Consumption in Embedded Applications","9,78145E+12",,10.1145/3207719.3207736,https://doi.org/10.1145/3207719.3207736;http://dx.doi.org/10.1145/3207719.3207736,Proceedings of the 21st International Workshop on Software and Compilers for Embedded Systems,"Source code refactorings and transformations are extensively used by embedded system developers to improve the quality of applications, often supported by various open source and proprietary tools. They either aim at improving the design time quality such as the maintainability and reusability of software artifacts, or the runtime quality such as performance and energy efficiency. However, an inherent trade-off between design- and run-time qualities is often present posing challenges to embedded software development. This work is a first step towards the investigation of the impact of transformations for improving the performance and the energy efficiency on software quality metrics and the impact of refactorings for increasing the design time quality on the execution time, the memory and the energy consumption. Based on a set of embedded applications from widely used benchmark suites and typical transformations and refactorings, we identify interrelations and trade-offs between the aforementioned metrics.","Papadopoulos L,Marantos C,Digkas G,Ampatzoglou A,Chatzigeorgiou A,Soudris D",,2018,2018,https://doi.org/10.1145/3207719.3207736;http://dx.doi.org/10.1145/3207719.3207736,interrelations between software quality metrics performance and energy consumption in embedded applications,0
125,An Energy Efficient Model for Monitoring and Detecting Atrial Fibrillation in Wearable Computing,"9,78194E+12",,,,Proceedings of the 7th International Conference on Body Area Networks,"Current portable healthcare monitoring systems are small, battery-operated electrocardiograph devices that are used to record the heart's rhythm and activity. These on-body healthcare devices fall short on delivering real-time continuous monitoring of early detection of cardiac atrial fibrillation (A-Fib) when the symptoms last only a short period of time and require a long battery life. The focus of this paper is the design of an energy efficient model for real-time early detection of A-Fib in a wearable computing device. The design is realized by incorporating an A-Fib risk factor and a real-time A-Fib incidence-based detection algorithm. The results of the design show that the proposed energy efficient model performs better than a telemetry energy model. The design shows promising results in meeting the energy needs of real-time monitoring, detecting and reporting required in wearable computing healthcare applications.","Bouhenguel R,Mahgoub I,Llyas M",,2012,2012,,an energy efficient model for monitoring and detecting atrial fibrillation in wearable computing,0
127,A Green Miner's Dataset: Mining the Impact of Software Change on Energy Consumption,"9,78145E+12",,10.1145/2597073.2597130,https://doi.org/10.1145/2597073.2597130;http://dx.doi.org/10.1145/2597073.2597130,Proceedings of the 11th Working Conference on Mining Software Repositories,"With the advent of mobile computing, the responsibility of software developers to update and ship energy efficient applications has never been more pronounced. Green mining attempts to address this responsibility by examining the impact of software change on energy consumption. One problem with green mining is that power performance data is not readily available, unlike many other forms of MSR research. Green miners have to create tests and run them across numerous versions of a software project because power performance data was either missing or never existed for that particular project. In this paper we describe multiple open green mining datasets used in prior green mining work. The dataset includes numerous power traces and parallel system call and CPU/IO/Memory traces of multiple versions of multiple products. These datasets enable those more interested in data-mining and modeling to work on green mining problems as well.","Zhang C,Hindle A",,2014,2014,https://doi.org/10.1145/2597073.2597130;http://dx.doi.org/10.1145/2597073.2597130,a green miner s dataset mining the impact of software change on energy consumption,0
132,Bluetooth Low Energy Microlocation Asset Tracking (BLEMAT) in a Context-Aware Fog Computing System,"9,78145E+12",,10.1145/3227609.3227652,https://doi.org/10.1145/3227609.3227652;http://dx.doi.org/10.1145/3227609.3227652,"Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics","In this paper we present a Bluetooth Low Energy Microlocation Asset Tracking system (BLEMAT) that performs real-time position estimation and asset tracking based on BLE beacons and scanners. It is built on a context-aware fog computing system comprising Internet of Things controllers, sensors and a cloud platform, helped by machine-learning models and techniques. The BLEMAT system offers detecting signal propagation obstacles, performing signal perturbation correction and beacon paths exploration as well as auto discovery and onboarding of fog controller devices. These are the key characteristics of semi-supervised indoor position estimation services. In this paper we have shown there are solid basis that a fog computing system can efficiently carry out semi-supervised machine learning procedures for high-precision indoor position estimation and space modeling without the need for detailed input information (i.e. floor plan, signal propagation map, scanner position). In addition, the fog computing system inherently brings high level of system robustness, integrity, privacy and trust.","Pei? S,Toi? M,Ikovi? O,Radovanovi? M,Ivanovi? M,Bokovi? D",,2018,2018,https://doi.org/10.1145/3227609.3227652;http://dx.doi.org/10.1145/3227609.3227652,bluetooth low energy microlocation asset tracking blemat in a context aware fog computing system,0
134,Evaluation of the Energetic Impact of Bluetooth Low-Power Modes for Ubiquitous Computing Applications,"9,7816E+12",,10.1145/1163610.1163612,https://doi.org/10.1145/1163610.1163612;http://dx.doi.org/10.1145/1163610.1163612,"Proceedings of the 3rd ACM International Workshop on Performance Evaluation of Wireless Ad Hoc, Sensor and Ubiquitous Networks","In order to further increase the applicability of Bluetooth in real applications, reducing the energy consumption and hardware cost are important research topics. In this paper we present a wireless communication prototype to support ubiquitous computing, which has been implemented based on commercial Bluetooth off-the-shelf components. It allows every object to be augmented with processing and communication capabilities in order to make them ""smart"". We investigate on the power characteristics of our Bluetooth prototype which supports the use of low-power modes providing helpful information for protocol developers and software designers. We assess if Bluetooth modules implementing low-power modes can significantly alleviate the power consumption of Bluetooth enabled devices. Our prototype has been used in a museum application to support spontaneous and ubiquitous connections between devices without requiring a priori knowledge of each other","Cano JC,Cano JM,González E,Calafate C,Manzoni P",,2006,2006,https://doi.org/10.1145/1163610.1163612;http://dx.doi.org/10.1145/1163610.1163612,evaluation of the energetic impact of bluetooth low power modes for ubiquitous computing applications,0
135,Fluid Flow Model for Energy-Aware Server Performance Evaluation,,0163-5999,10.1145/3199524.3199560,https://doi.org/10.1145/3199524.3199560;http://dx.doi.org/10.1145/3199524.3199560,,We use a fluid flow model with reactive bounds to analyse a data processing center with energy-aware servers. The servers switch between four energy states depending on the level of the buffer content and on three reactive bounds. Every state consumes different amounts of energy. We use a regenerative approach to calculate the stationary distribution of the system and the expected energy consumption.,"Deiana E,Latouche G,Remiche MA",SIGMETRICS Perform. Eval. Rev.,2018,2018-03,https://doi.org/10.1145/3199524.3199560;http://dx.doi.org/10.1145/3199524.3199560,fluid flow model for energy aware server performance evaluation,0
136,Energy-Based Anomaly Detection a New Perspective for Predicting Software Failures,,,10.1109/ICSE-NIER.2019.00026,https://doi.org/10.1109/ICSE-NIER.2019.00026;http://dx.doi.org/10.1109/ICSE-NIER.2019.00026,Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results,"The ability of predicting failures before their occurrence is a fundamental enabler for reducing field failures and improving the reliability of complex software systems. Recent research proposes many techniques to detect anomalous values of system metrics, and demonstrates that collective anomalies are a good symptom of failure-prone states.In this paper (i) we observe the analogy of complex software systems with multi-particle and network systems, (ii) propose to use energy-based models commonly exploited in physics and statistical mechanics to precisely reveal failure-prone behaviors without training with seeded errors, and (iii) present some preliminary experimental results that show the feasibility of our approach.","Monni C,Pezzè M",,2019,2019,https://doi.org/10.1109/ICSE-NIER.2019.00026;http://dx.doi.org/10.1109/ICSE-NIER.2019.00026,energy based anomaly detection a new perspective for predicting software failures,0
143,Lightweight Power Aware and Scalable Movement Monitoring for Wearable Computers: A Mining and Recognition Technique at the Fingertip of Sensors,"9,78145E+12",,10.1145/2077546.2077554,https://doi.org/10.1145/2077546.2077554;http://dx.doi.org/10.1145/2077546.2077554,Proceedings of the 2nd Conference on Wireless Health,"Activity monitoring using Body Sensor Networks(BSN) has gained much attention from the scientific community due to its recreational and medical applications. Suggested techniques for activity monitoring face two major problem. First, systems have to be trained for the individual subjects due to the heterogeneity of the BSN data. While most solutions can address this problem on a small data set, they have no mechanics for automatic scaling of the solution as the data set increases. Second, the battery limitations of the BSN severely limit the maximum deployment time for the continuous monitoring. This problem is often solved by shifting some processing to the local sensor nodes to avoid a very heavy communication cost. However, little work has been done to optimize the sensing and processing cost of the action recognition. In this paper, we propose an action recognition approach based on the BSN repository. We show how the information of a large repository can be automatically used to customize the processing on sensor nodes based on a limited and automated training process. We also investigate the power cost of such a repository mining approach on the sensor nodes based on our implementation. To assess the power requirement, we define an energy model for data sensing and processing. We demonstrate the relationship between the activity recognition precision and the power consumption of the system during continuous action monitoring. We demonstrate the energy effectiveness of our approach with a classification accuracy constraint based on limited data repository.","Loseu V,Mannil J,Jafari R",,2011,2011,https://doi.org/10.1145/2077546.2077554;http://dx.doi.org/10.1145/2077546.2077554,lightweight power aware and scalable movement monitoring for wearable computers a mining and recognition technique at the fingertip of sensors,0
147,Efficient Power Modeling and Software Thermal Sensing for Runtime Temperature Monitoring,,1084-4309,10.1145/1255456.1255462,https://doi.org/10.1145/1255456.1255462;http://dx.doi.org/10.1145/1255456.1255462,,"The evolution of microprocessors has been hindered by increasing power consumption and heat dissipation on die. An excessive amount of heat creates reliability problems, reduces the lifetime of a processor, and elevates the cost of cooling and packaging considerably. It is therefore imperative to be able to monitor the temperature variations across the die in a timely and accurate manner.Most current techniques rely on on-chip thermal sensors to report the temperature of the processor. Unfortunately, significant variation in chip temperature both spatially and temporally exposes the limitation of the sensors. We present a compensating approach to tracking chip temperature through an OS resident software module that generates live power and thermal profiles of the processor. We developed such a software thermal sensor (STS) in a Linux system with a Pentium 4 Northwood core. We employed highly efficient numerical methods in our model to minimize the overhead of temperature calculation. We also developed an efficient algorithm for functional unit power modeling. Our power and thermal models are calibrated and validated against on-chip sensor readings, thermal images of the Northwood heat spreader, and the thermometer measurements on the package. The resulting STS offers detailed power and temperature breakdowns of each functional unit at runtime, enabling more efficient online power and thermal monitoring and management at a higher level, such as the operating system.","Wu W,Jin L,Yang J,Liu P,Tan SX",ACM Trans. Des. Autom. Electron. Syst.,2008,2008-05,https://doi.org/10.1145/1255456.1255462;http://dx.doi.org/10.1145/1255456.1255462,efficient power modeling and software thermal sensing for runtime temperature monitoring,0
148,Hardware/Software Design Challenges of Low-Power Sensor Nodes for Condition Monitoring,"9,78398E+12",,,,"Proceedings of the Conference on Design, Automation and Test in Europe",Structural Health Monitoring (SHM) is a new challenge in wireless sensor design. In our project we are proposing an ultra-sonic measurement system to find malfunctions within structures. Examples of such structures are aircraft bodies and the wings of a wind turbine. It is required to allow for long term monitoring from a single battery or even using energy scavenging techniques.,"Ahlendorf H,Göpfert L",,2010,2010,,hardware software design challenges of low power sensor nodes for condition monitoring,0
160,Strong Agile Metrics: Mining Log Data to Determine Predictive Power of Software Metrics for Continuous Delivery Teams,"9,78145E+12",,10.1145/3106237.3117779,https://doi.org/10.1145/3106237.3117779;http://dx.doi.org/10.1145/3106237.3117779,Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering,"ING Bank, a large Netherlands-based internationally operating bank, implemented a fully automated continuous delivery pipe-line for its software engineering activities in more than 300 teams, that perform more than 2500 deployments to production each month on more than 750 different applications. Our objective is to examine how strong metrics for agile (Scrum) DevOps teams can be set in an iterative fashion. We perform an exploratory case study that focuses on the classification based on predictive power of software metrics, in which we analyze log data derived from two initial sources within this pipeline. We analyzed a subset of 16 metrics from 59 squads. We identified two lagging metrics and assessed four leading metrics to be strong.","Huijgens H,Lamping R,Stevens D,Rothengatter H,Gousios G,Romano D",,2017,2017,https://doi.org/10.1145/3106237.3117779;http://dx.doi.org/10.1145/3106237.3117779,strong agile metrics mining log data to determine predictive power of software metrics for continuous delivery teams,0
164,Approaches to Transient Computing for Energy Harvesting Systems: A Quantitative Evaluation,"9,78145E+12",,10.1145/2820645.2820652,https://doi.org/10.1145/2820645.2820652;http://dx.doi.org/10.1145/2820645.2820652,Proceedings of the 3rd International Workshop on Energy Harvesting & Energy Neutral Sensing Systems,"Systems operating from harvested sources typically integrate batteries or supercapacitors to smooth out rapid changes in harvester output. However, such energy storage devices require time for charging and increase the size, mass and cost of the system. A recent approach to address this is to power systems directly from the harvester output, termed transient computing. To solve the problem of having to restart computation from the start due to power-cycles, a number of techniques have been proposed to deal with transient power sources. In this paper, we quantitatively evaluate three state-of-the-art approaches on a Texas Instruments MSP430 microcontroller characterizing the application scenarios where each performs best. Finally, recommendations are provided to system designers for selecting the most suitable approach.","Rodriguez Arreola A,Balsamo D,Das AK,Weddell AS,Brunelli D,Al-Hashimi BM,Merrett GV",,2015,2015,https://doi.org/10.1145/2820645.2820652;http://dx.doi.org/10.1145/2820645.2820652,approaches to transient computing for energy harvesting systems a quantitative evaluation,0
165,A Software Agent Framework for Exploiting Demand-Side Consumer Social Networks in Power Systems,"9,78077E+12",,10.1109/WI-IAT.2011.245,https://doi.org/10.1109/WI-IAT.2011.245;http://dx.doi.org/10.1109/WI-IAT.2011.245,Proceedings of the 2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology - Volume 02,"This work introduces Energy City, a multi-agent framework designed and developed in order to simulate the power system and explore the potential of Consumer Social Networks (CSNs) as a means to promote demand-side response and raise social awareness towards energy consumption. The power system with all its involved actors (Consumers, Producers, Electricity Suppliers, Transmission and Distribution Operators) and their requirements are modeled. The semantic infrastructure for the formation and analysis of electricity CSNs is discussed, and the basic consumer attributes and CSN functionality are identified. Authors argue that the formation of such CSNs is expected to increase the electricity consumer market power by enabling them to act in a collective way.","Symeonidis AL,Gountis VP,Andreou GT",,2011,2011,https://doi.org/10.1109/WI-IAT.2011.245;http://dx.doi.org/10.1109/WI-IAT.2011.245,a software agent framework for exploiting demand side consumer social networks in power systems,0
169,The Evaluation of Ada Software to Support the Space Station Power Management and Distribution System,"9,7809E+12",,10.1145/76619.77034,https://doi.org/10.1145/76619.77034;http://dx.doi.org/10.1145/76619.77034,Proceedings of the Conference on TRI-Ada '88,,Schubert K,,1989,1989,https://doi.org/10.1145/76619.77034;http://dx.doi.org/10.1145/76619.77034,the evaluation of ada software to support the space station power management and distribution system,0
172,Harnessing Disagreement to Create AI-Powered Systems That Reflect Our Values,"9,78145E+12",,10.1145/3474349.3477590,https://doi.org/10.1145/3474349.3477590;http://dx.doi.org/10.1145/3474349.3477590,Adjunct Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology,"How do we build artificial intelligence systems that reflect our values? Competing potential values we may want to choose from are, at their core, made up of disagreements between individual people. But while the raw datasets that most ML systems rely on are made up of individuals, todays approaches to building AI typically abstract the individuals out of the pipeline. My thesis contributes a set of algorithms and interactive systems that re-imagine the pipeline for designing and evaluating AI systems, requiring that we deal with competing values in an informed and intentional way. I start from the insight that at each stage of the pipeline, we need to treat individuals as the key unit of operation, rather than the abstractions or aggregated pseudo-humans in use by todays approaches. I instantiate this insight to address two problems that arise from todays AI pipeline. First, evaluation metrics produce actively misleading scores about the extent to which some peoples values are being reflected. I introduce a mathematical transformation that more closely aligns metrics with the values and methods of user-facing performance measures. Second, the resulting AI systems either surreptitiously choose which values to listen to without input from users, or simply present several different outcomes to users without mechanisms to help them select an outcome grounded in their values. I propose a new interaction paradigm for deploying classifiers, asking users to compose a jury consisting of the individual people theyd like their classifiers decisions to come from.",Gordon ML,,2021,2021,https://doi.org/10.1145/3474349.3477590;http://dx.doi.org/10.1145/3474349.3477590,harnessing disagreement to create ai powered systems that reflect our values,0
174,Energy Production and Trading: Using Computer Simulation to Mitigate Risk in Electricity Generation/Consumption Collaboration Policies,"9,78078E+12",,,,Proceedings of the 34th Conference on Winter Simulation: Exploring New Frontiers,"The electric utility industry has undergone fundamental change in the last decade. Foremost of these changes have been numerous deregulation attempts. Producers and large consumers have built business models based upon large volume transactions, which lead to smooth production and volume discounting. The risks associated with using these traditional business models in deregulated markets are many. This paper describes the development of a computer simulation environment that models a novel collaborative strategy proposed by a local electricity utility to mitigate highly varying load situations demanded by the largest steel-producing region in the United States. Through the use of this model, collaborative strategies for effective electricity generation and usage are developed and analyzed.",Brady TF,,2002,2002,,energy production and trading using computer simulation to mitigate risk in electricity generation consumption collaboration policies,0
177,AI Waste Prevention: Time and Power Estimation for Edge Tensor Processing Units: Poster,"9,78145E+12",,10.1145/3447555.3466579,https://doi.org/10.1145/3447555.3466579;http://dx.doi.org/10.1145/3447555.3466579,Proceedings of the Twelfth ACM International Conference on Future Energy Systems,"Artificial Intelligence (AI) has changed our daily lives. The evolution from centralised cloud-hosted services towards embedded and mobile devices has shifted the focus from quality-related aspects towards the resource demand of machine learning. Its pervasiveness demands for ""green"" AI---both the development and the operation of AI models still include significant resource investments in terms of processing time and power demand. In order to prevent such AI Waste, this paper presents Precious, an approach, as well as practical implementation, that estimates execution time and power draw of neural networks (NNs) that execute on a commercially-available off-the-shelf accelerator hardware (i.e., Google Coral Edge TPU). The evaluation of our implementations shows that Precious accurately estimates time and power demand.","Reif S,Herzog B,Hemp J,Schröder-Preikschat W,Hönig T",,2021,2021,https://doi.org/10.1145/3447555.3466579;http://dx.doi.org/10.1145/3447555.3466579,ai waste prevention time and power estimation for edge tensor processing units poster,0
182,Green Mining: A Methodology of Relating Software Change to Power Consumption,"9,78147E+12",,,,Proceedings of the 9th IEEE Working Conference on Mining Software Repositories,"Power consumption is becoming more and more important with the increased popularity of smart-phones, tablets and laptops. The threat of reducing a customer's battery-life now hangs over the software developer who asks, ""will this next change be the one that causes my software to drain a customer's battery?"" One solution is to detect power consumption regressions by measuring the power usage of tests, but this is time-consuming and often noisy. An alternative is to rely on software metrics that allow us to estimate the impact that a change might have on power consumption thus relieving the developer from expensive testing. This paper presents a general methodology for investigating the impact of software change on power consumption, we relate power consumption to software changes, and then investigate the impact of static OO software metrics on power consumption. We demonstrated that software change can effect power consumption using the Firefox web-browser and the Azureus/Vuze BitTorrent client. We found evidence of a potential relationship between some software metrics and power consumption. In conclusion, we explored the effect of software change on power consumption on two projects; and we provide an initial investigation on the impact of software metrics on power consumption.",Hindle A,,2012,2012,,green mining a methodology of relating software change to power consumption,0
188,PETrA: A Software-Based Tool for Estimating the Energy Profile of Android Applications,"9,78154E+12",,10.1109/ICSE-C.2017.18,https://doi.org/10.1109/ICSE-C.2017.18;http://dx.doi.org/10.1109/ICSE-C.2017.18,Proceedings of the 39th International Conference on Software Engineering Companion,"Energy efficiency is a vital characteristic of any mobile application, and indeed is becoming an important factor for user satisfaction. For this reason, in recent years several approaches and tools for measuring the energy consumption of mobile devices have been proposed. Hardware-based solutions are highly precise, but at the same time they require costly hardware toolkits. Model-based techniques require a possibly difficult calibration of the parameters needed to correctly create a model on a specific hardware device. Finally, software-based solutions are easier to use, but they are possibly less precise than hardware-based solution. In this demo, we present PETrA, a novel software-based tool for measuring the energy consumption of Android apps. With respect to other tools, PETrA is compatible with all the smartphones with Android 5.0 or higher, not requiring any device specific energy profile. We also provide evidence that our tool is able to perform similarly to hardware-based solutions.","Di Nucci D,Palomba F,Prota A,Panichella A,Zaidman A,De Lucia A",,2017,2017,https://doi.org/10.1109/ICSE-C.2017.18;http://dx.doi.org/10.1109/ICSE-C.2017.18,petra a software based tool for estimating the energy profile of android applications,0
191,"FATEsys 2021: The First ACM SIGEnergy Workshop on Fair, Accountable, Transparent, and Ethical (FATE) AI for Smart Environments and Energy Systems","9,78145E+12",,10.1145/3486611.3492408,https://doi.org/10.1145/3486611.3492408;http://dx.doi.org/10.1145/3486611.3492408,"Proceedings of the 8th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation","The advent of IoT, ubiquitous and smart sensing, and high performance computing has resulted in a big shift in the adoption of data-driven black-box modeling (also referred to as machine/deep learning) to make our environments smarter and energy systems efficient. Several studies have shown that these AI-enabled solutions for smart buildings, smart cities, smart grids, electric transportation, among others are much more accurate and efficient. However, these data-driven black-box solutions are rarely held accountable for the impact of their actions on the human in the loop which significantly impacts their real-world adoption. To truly conceptualize the idea of smart systems for everyone, it is critical to study these AI-enabled smart environments and energy systems for not just efficiency, but also for affordability and accessibility for all. The first ACM SIGEnergy workshop on Fair, Accountable, Transparent, and Ethical AI for Smart Environments and Energy Systems intends to bring together researchers from diverse backgrounds and discuss key issues, challenges, breakthroughs, and socio-economic impact in developing fair, accountable, transparent and ethical AI techniques for smart environments and energy systems.","Jain M,Arjunan P",,2021,2021,https://doi.org/10.1145/3486611.3492408;http://dx.doi.org/10.1145/3486611.3492408,fatesys the first acm sigenergy workshop on fair accountable transparent and ethical fate ai for smart environments and energy systems,0
192,"FATEsys 2022: The Second ACM SIGEnergy Workshop on Fair, Accountable, Transparent, and Ethical (FATE) AI for Smart Environments and Energy Systems","9,78145E+12",,10.1145/3563357.3568731,https://doi.org/10.1145/3563357.3568731;http://dx.doi.org/10.1145/3563357.3568731,"Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation","The advent of IoT, ubiquitous and smart sensing and high-performance computing has resulted in a big shift in the adoption of data-driven black-box modelling (also referred to as machine/deep learning) to make our environments smarter and energy systems efficient. Several studies have shown that these AI-enabled solutions for smart buildings, smart cities, smart grids, and electric transportation, among others, are much more accurate and efficient. However, these data-driven black-box solutions are rarely held accountable for the impact of their actions on the human in the loop which significantly impacts their real-world adoption. To truly conceptualize the idea of smart systems for everyone, it is critical to study these AI-enabled smart environments and energy systems for not just efficiency, but also for affordability and accessibility for all. The first ACM SIGEnergy workshop on Fair, Accountable, Transparent, and Ethical AI for Smart Environments and Energy Systems intends to bring together researchers from diverse backgrounds and discuss key issues, challenges, breakthroughs, and socioeconomic impact in developing fair, accountable, transparent and ethical AI techniques for smart environments and energy systems.","Jain M,Arjunan P",,2022,2022,https://doi.org/10.1145/3563357.3568731;http://dx.doi.org/10.1145/3563357.3568731,fatesys the second acm sigenergy workshop on fair accountable transparent and ethical fate ai for smart environments and energy systems,0
