@inproceedings{10.1145/339331.339421,
author = {Farkas, Keith I. and Flinn, Jason and Back, Godmar and Grunwald, Dirk and Anderson, Jennifer M.},
title = {Quantifying the Energy Consumption of a Pocket Computer and a Java Virtual Machine},
year = {2000},
isbn = {1581131941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/339331.339421},
doi = {10.1145/339331.339421},
abstract = {In this paper, we examine the energy consumption of a state-of-the-art pocket computer. Using a data acquisition system, we measure the energy consumption of the Itsy Pocket Computer, developed by Compaq Computer Corporation's Palo Alto Research Labs. We begin by showing that the energy usage characteristics of the Itsy differ markedly from that of a notebook computer. Then, since we expect that flexible software environments will become increasingly prevalent on pocket computers, we consider applications running in a Java environment. In particular, we explain some of the Java design tradeoffs applicable to pocket computers, and quantify their energy costs. For the design options we considered and the three workloads we studied, we find a maximum change in energy use of 25%.},
booktitle = {Proceedings of the 2000 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {252–263},
numpages = {12},
location = {Santa Clara, California, USA},
series = {SIGMETRICS '00}
}

@article{10.1145/345063.339421,
author = {Farkas, Keith I. and Flinn, Jason and Back, Godmar and Grunwald, Dirk and Anderson, Jennifer M.},
title = {Quantifying the Energy Consumption of a Pocket Computer and a Java Virtual Machine},
year = {2000},
issue_date = {June 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/345063.339421},
doi = {10.1145/345063.339421},
abstract = {In this paper, we examine the energy consumption of a state-of-the-art pocket computer. Using a data acquisition system, we measure the energy consumption of the Itsy Pocket Computer, developed by Compaq Computer Corporation's Palo Alto Research Labs. We begin by showing that the energy usage characteristics of the Itsy differ markedly from that of a notebook computer. Then, since we expect that flexible software environments will become increasingly prevalent on pocket computers, we consider applications running in a Java environment. In particular, we explain some of the Java design tradeoffs applicable to pocket computers, and quantify their energy costs. For the design options we considered and the three workloads we studied, we find a maximum change in energy use of 25%.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {252–263},
numpages = {12}
}

@inproceedings{10.1145/3582935.3582972,
author = {Gao, Yi and Yan, Dawei and Liu, Ning and Luo, Shuai and Zhou, Zhiyu and Wang, Yang and Chen, Yue and Gao, Bixuan},
title = {A High-Frequency Monitoring Method for Urban Carbon Emissions Based on Vertical Federated Deep Learning and Multi-Source Heterogeneous Data Fusion Methods},
year = {2023},
isbn = {9781450396806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582935.3582972},
doi = {10.1145/3582935.3582972},
abstract = {Carbon emissions are the main culprit of global warming. Accurate carbon emission forecasting helps government departments formulate effective carbon emission reduction policies and helps the carbon emission market develop orderly. Implementing an accurate and effective carbon emission monitoring model requires the collaboration of many parties because carbon emission-related data involves many sectors and industries. However, for the relevant characteristics of carbon emission monitoring, due to the different collection and storage standards of various departments, poor maintenance environment, lack of data, data loss, and abnormal severe, resulting in high frequency and high precision carbon emission monitoring. As privacy protection and data security issues are gradually taken seriously by government departments and related enterprises, the inability or unwillingness to share carbon emission-related data among enterprises or even among various departments within enterprises has created an increasingly severe data silo phenomenon. In addition, how effectively breaking the data barriers between various sectors is an urgent problem in grasping carbon emission change changes accurately. Therefore, this paper proposes a carbon emission monitoring model for key urban sectors based on vertical federated deep learning and multi-source heterogeneous data fusion and sharing. The experimental results show that the model accurately predicts carbon emission change trends in various application scenarios under the data availability and invisibility of each participant.},
booktitle = {Proceedings of the 5th International Conference on Information Technologies and Electrical Engineering},
pages = {232–237},
numpages = {6},
keywords = {Carbon Emissions Monitoring, Vertical Federated Deep Learning, Privacy and security protection, Multi-source heterogeneous data fusion},
location = {Changsha, China},
series = {ICITEE '22}
}

@inproceedings{10.1145/3387168.3387192,
author = {Jun, Liu and Jie, Zhang and DingHong, Pu},
title = {Cloud Computing Virtual Machine Migration Energy Measuring Research},
year = {2020},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387192},
doi = {10.1145/3387168.3387192},
abstract = {This paper research virtual machine migration energy measuring on IPv4/IPv6 network based on cloud computing infrastructure platform, it conducts a research on the energy measuring in IPv4/IPv6 cloud computing platform, and presents a dynamic energy measuring mathematical model based on analyzing CPU energy consumption changes brought by random assignment works. The research determines mathematical model parameter values and it completes the IPv4/IPv6 cloud computing platform virtual machine migration experimentally. This paper achieves the energy consumption of IPv4/IPv6 transition prior-period, mid-period and last-period cloud computing platform virtual machine migration, the conclusions in line with the cloud energy measurement needs, it builds the theoretical foundation for cloud computing platform energy consumption optimize.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {21},
numpages = {5},
keywords = {Virtual Machine Migration, Energy Measuring, Cloud Computing, Migration Energy Consumption},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@inproceedings{10.1145/3551349.3561170,
author = {Pathania, Priyavanshi and Mehra, Rohit and Sharma, Vibhu Saujanya and Kaulgud, Vikrant and Podder, Sanjay and Burden, Adam P.},
title = {ESAVE: Estimating Server and Virtual Machine Energy},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3561170},
doi = {10.1145/3551349.3561170},
abstract = {Sustainable software engineering has received a lot of attention in recent times, as we witness an ever-growing slice of energy use, for example, at data centers, as software systems utilize the underlying infrastructure. Characterizing servers for their energy use accurately without being intrusive, is therefore important to make sustainable software deployment choices. In this paper, we introduce ESAVE which is a machine learning-based approach that leverages a small set of hardware attributes to characterize a server or virtual machine’s energy usage across different levels of utilization. This is based upon an extensive exploration of multiple ML approaches, with a focus on a minimal set of required attributes, while showcasing good accuracy. Early validations show that ESAVE has only around 12% average prediction error, despite being non-intrusive.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {142},
numpages = {3},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3380688.3380715,
author = {Huynh, Hieu Trung and Quan, Ho Dac},
title = {Energy Expenditure Estimation Based on Artificial Intelligence and Microservice Architecture},
year = {2020},
isbn = {9781450376310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380688.3380715},
doi = {10.1145/3380688.3380715},
abstract = {Nutritional status plays an important role in not only pregnancy outcomes but also neonatal health. One of efficient techniques to control the nutritional status is to estimate the energy expenditure. There are some approaches for estimating energy expenditure. However, they have limitations including high cost, relative complexity, trained personnel requirements, or locality. This study investigates in a system for data collection and analysis (IoH-Internet of Health) developing based on microservice architecture, and its application for energy expenditure estimation. The proposed system has a good ability to scale and integrate with other systems; the energy expenditure estimation is performed by using artificial intelligence. The experimental results have shown the promising results of the proposed system.},
booktitle = {Proceedings of the 4th International Conference on Machine Learning and Soft Computing},
pages = {159–163},
numpages = {5},
keywords = {IoH system, data collection, expenditure energy estimation, healthcare, visualization},
location = {Haiphong City, Viet Nam},
series = {ICMLSC '20}
}

@article{10.1145/3603533,
author = {Alavani, Gargi and Desai, Jineet and Saha, Snehanshu and Sarkar, Santonu},
title = {Program Analysis and Machine Learning Based Approach to Predict Power Consumption of CUDA Kernel},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2376-3639},
url = {https://doi.org/10.1145/3603533},
doi = {10.1145/3603533},
abstract = {General Purpose Graphics Processing Unit (GPGPU) has secured a prominent position in the High-Performance Computing (HPC) world due to its performance gain and programmability. Understanding the relationship between GPU power consumption and program features can aid developers in building energy-efficient sustainable applications. In this work, we propose a static analysis based power model built using machine learning techniques. We have investigated six machine learning models across three NVIDIA GPU architectures: Kepler, Maxwell, and Volta with Random Forest, Extra Trees, Gradient Boosting, CatBoost, and XGBoost, reporting favorable results. We observed that the XGBoost technique based prediction model is the most efficient technique with an R-square value of 0.9646 on Volta Architecture. The dataset used for these techniques includes kernels from different benchmarks suits, sizes, nature (e.g., compute-bound, memory-bound), and complexity (e.g., control divergence, memory access patterns). Experimental results suggest that the proposed solution can help developers precisely predict GPU applications power consumption using program analysis across GPU architectures. Developers can use this approach to refactor their code to build energy-efficient GPU applications.},
note = {Just Accepted},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = {jun},
keywords = {GPGPU Computing ; XGBoost ; CatBoost ; CUDA; Static Analysis ; Sustainable Computing}
}

@inproceedings{10.1145/2741948.2741971,
author = {Colmant, Maxime and Kurpicz, Mascha and Felber, Pascal and Huertas, Lo\"{\i}c and Rouvoy, Romain and Sobe, Anita},
title = {Process-Level Power Estimation in VM-Based Systems},
year = {2015},
isbn = {9781450332385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2741948.2741971},
doi = {10.1145/2741948.2741971},
abstract = {Power estimation of software processes provides critical indicators to drive scheduling or power capping heuristics. State-of-the-art solutions can perform coarse-grained power estimation in virtualized environments, typically treating virtual machines (VMs) as a black box. Yet, VM-based systems are nowadays commonly used to host multiple applications for cost savings and better use of energy by sharing common resources and assets.In this paper, we propose a fine-grained monitoring middleware providing real-time and accurate power estimation of software processes running at any level of virtualization in a system. In particular, our solution automatically learns an application-agnostic power model, which can be used to estimate the power consumption of applications.Our middleware implementation, named BitWatts, builds on a distributed actor implementation to collect process usage and infer fine-grained power consumption without imposing any hardware investment (e.g., power meters). BitWatts instances use high-throughput communication channels to spread the power consumption across the VM levels and between machines. Our experiments, based on CPU- and memory-intensive benchmarks running on different hardware setups, demonstrate that BitWatts scales both in number of monitored processes and virtualization levels. This non-invasive monitoring solution therefore paves the way for scalable energy accounting that takes into account the dynamic nature of virtualized environments.},
booktitle = {Proceedings of the Tenth European Conference on Computer Systems},
articleno = {14},
numpages = {14},
location = {Bordeaux, France},
series = {EuroSys '15}
}

@inproceedings{10.5555/3021955.3021979,
author = {Hinz, Mauro and Miers, Charles C. and Pillon, Mauricio A. and Koslovski, Guilherme P.},
title = {A Cost Model for IaaS Clouds Based on Virtual Machine Energy Consumption},
year = {2016},
isbn = {9788576693178},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {Reduction in data center energy consumption is a constant motivation for IaaS providers. Among all components, CPU appears as a main energy consumer. Although there is a strong relationship between CPU load and its energy consumption, pricing models of popular IaaS providers do not consider this information as a primary and variable element. This paper quantifies the relationship by identifying the individual consumption of virtual CPUs, which form the basis for an allocation cost model. The proposed model, termed Virtual Power, is faced with Amazon EC2 pricing model pointing a cost reduction for IaaS provider and a proportional sharing between users.},
booktitle = {Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1},
pages = {136–143},
numpages = {8},
keywords = {IaaS, Cost, Virtual Machine, Model},
location = {Florianopolis, Santa Catarina, Brazil},
series = {SBSI 2016}
}

@inproceedings{10.1145/3529836.3529843,
author = {Lu, Yingdong and Wei, Duqu},
title = {Chaos Prediction of Power Systems by Using Deep Learning},
year = {2022},
isbn = {9781450395700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529836.3529843},
doi = {10.1145/3529836.3529843},
abstract = {Ensuring the stability of power systems is an important issue that should be considered in order to ensure the social and economic development of a country. Therefore, predicting the chaotic behavior of power systems in order to develop protection measures and keep power systems stable is vital. In this paper, a deep learning algorithm was proposed to predict the chaotic behavior of power systems by using deep long short-term memory (DLSTM) networks, which have two forms: deep long short-term memory with static scenario (DLSTM-s) and deep long-term memory with dynamic scenario (DLSTM-d). The genetic algorithm was used to optimize the hyperparameters of the networks. Then, taking interconnected power systems as an example, the effectiveness of the proposed DLSTM network was verified via numerical simulation. Finally, the experimental results of the DLSTM network were compared with those of the echo state network, multi-recurrent neural network, deep gated recurrent unit, and long short-term memory. Experimental results illustrated that a trained DLSTM network can predict the chaotic behavior of power systems by using the time series data of a single state variable. Moreover, the DLSTM-s network proposed in this paper can achieve competitive prediction performance compared with other baseline methods.},
booktitle = {2022 14th International Conference on Machine Learning and Computing (ICMLC)},
pages = {11–17},
numpages = {7},
keywords = {Chaos prediction, Deep learning, Deep long short-term memory, Power system},
location = {Guangzhou, China},
series = {ICMLC 2022}
}

@article{10.1145/3564932,
author = {Dong, Xiao and Chen, Yufei and Chen, Jun and Wang, Yucheng and Li, Ji and Ni, Tianming and Shi, Zhiguo and Yin, Xunzhao and Zhuo, Cheng},
title = {Worst-Case Power Integrity Prediction Using Convolutional Neural Network},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1084-4309},
url = {https://doi.org/10.1145/3564932},
doi = {10.1145/3564932},
abstract = {Power integrity analysis is an essential step in power distribution network (PDN) sign-off to ensure the performance and reliability of chips. However, with the growing PDN size and increasing scenarios to be validated, it becomes very time- and resource-consuming to conduct full-stack PDN simulation to check the power integrity for different test vectors. Recently, various works have proposed machine learning–based methods for PDN power integrity prediction, many of which still suffer from large training overhead, inefficiency, or non-scalability. Thus, this article proposed an efficient and scalable framework for the worst-case power integrity prediction, which can handle general tasks including dynamic noise prediction and bump current prediction. The framework first reduces the spatial and temporal redundancy in the PDN and input current vector and then employs efficient feature extraction as well as a novel convolutional neural network architecture to predict the worst-case power integrity. Experimental results show that the proposed framework consistently outperforms the commercial tool and the state-of-the-art machine learning method with only 0.63–1.02% mean relative error and 25–69\texttimes{} speedup for noise prediction and 0.22–1.06% mean relative error and 24–64\texttimes{} speedup for bump current prediction.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {may},
articleno = {54},
numpages = {19},
keywords = {convolutional neural network, Power distribution network, sign-off, power integrity, dynamic noise validation, bump current prediction}
}

@article{10.5555/3455716.3455964,
author = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
title = {Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {248},
numpages = {43},
keywords = {climate change, deep learning, green computing, reinforcement learning, energy efficiency}
}

@inproceedings{10.1145/3203217.3203273,
author = {Dutta, Bishwajit and Adhinarayanan, Vignesh and Feng, Wu-chun},
title = {GPU Power Prediction via Ensemble Machine Learning for DVFS Space Exploration},
year = {2018},
isbn = {9781450357616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3203217.3203273},
doi = {10.1145/3203217.3203273},
abstract = {A software-based approach to achieve high performance within a power budget often involves dynamic voltage and frequency scaling (DVFS). Thus, accurately predicting the power consumption of an application at different DVFS levels (or more generally, different processor configurations) is paramount for the energy-efficient functioning of a high-performance computing (HPC) system. The increasing prevalence of graphics processing units (GPUs) in HPC systems presents new challenges in power management, and machine learning presents an unique way to improve the software-based power management of these systems. As such, we explore the problem of GPU power prediction at different DVFS states via machine learning. Specifically, we propose a new ensemble technique that incorporates three machine-learning techniques --- sequential minimal optimization regression, simple linear regression, and decision tree --- to reduce the mean absolute error (MAE) to 3.5%.},
booktitle = {Proceedings of the 15th ACM International Conference on Computing Frontiers},
pages = {240–243},
numpages = {4},
location = {Ischia, Italy},
series = {CF '18}
}

@inproceedings{10.5555/201081.201094,
author = {Jeyasurya, B.},
title = {Power System Voltage Instability Monitoring with Artificial Neural Networks},
year = {1994},
isbn = {2884491287},
publisher = {Gordon and Breach Science Publishers, Inc.},
address = {USA},
booktitle = {Proceedings of the 7th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems},
pages = {57–62},
numpages = {6},
location = {Austin, Texas, USA},
series = {IEA/AIE '94}
}

@inproceedings{10.1145/3277453.3277464,
author = {Zhang, Bin and Han, Jian and Ren, Yanlin and Wen, Huimin and Song, Ziye and Gan, Qirui and Wei, Ran and Dang, Xin and Zhou, Bin},
title = {An Online Power System Dynamics Prediction Based on Deep Neural Network},
year = {2018},
isbn = {9781450365413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277453.3277464},
doi = {10.1145/3277453.3277464},
abstract = {Building Power analysis has drawn more and more attention in recent years. In this paper, we present a system for online power prediction for the public building. It is based on a 4-layers Deep Neural Network that use architectural metrics of the physical machines collected dynamically by our system to predict the physical machine power consumption. A real implementation of our system shows that the prediction accuracy could reach 76.50%.},
booktitle = {Proceedings of the 2018 International Conference on Electronics and Electrical Engineering Technology},
pages = {39–43},
numpages = {5},
keywords = {Deep computer architecture, Energy management, Deep neural networks},
location = {Tianjin, China},
series = {EEET '18}
}

@inproceedings{10.1145/3324921.3328787,
author = {Ciftcioglu, Ertugrul and Ricos, Mike},
title = {Efficient Power Adaptation against Deep Learning Based Predictive Adversaries},
year = {2019},
isbn = {9781450367691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324921.3328787},
doi = {10.1145/3324921.3328787},
abstract = {Wireless communication networks are subject to various types of adversarial attacks, which might be passive in the form of eavesdropping, or active in the form of jamming. For the former category, even if the traffic is encrypted, an adversary performing analysis on observed traffic signatures may lead to leakage of the so called contextual information regarding the traffic. New advances in the field of machine learning also result in significantly more complex adversarial units, which may deduce different forms and uses of such contextual information. In this work, we are interested in power adaptation against an intelligent adversary which utilizes deep learning and attempts to perform predictions and time forecasting on the observed traffic traces to estimate the imminent traffic intensities. Based on its traffic predictions, the adversary might possibly activate its jamming mode and utilize its limited power more efficiently to inflict maximal damage. As a method of mitigation, the transmitter may want to increase transmitter power if it expects a higher probability of jamming, and it has a significant amount of upcoming data to transmit. We leverage Lyapunov optimization and virtual queues to meet a certain level of data transmission reliability while also minimizing power consumption.},
booktitle = {Proceedings of the ACM Workshop on Wireless Security and Machine Learning},
pages = {37–42},
numpages = {6},
keywords = {power control, wireless security, recurrent neural networks},
location = {Miami, FL, USA},
series = {WiseML 2019}
}

@inproceedings{10.1145/3502300.3502307,
author = {Shanti, Naser and Assi, Akram and Shakhshir, Hamza and Salman, Adnan},
title = {Machine Learning-Powered Mobile App for Predicting Used Car Prices},
year = {2022},
isbn = {9781450390552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502300.3502307},
doi = {10.1145/3502300.3502307},
abstract = {Buying and selling used cars is a common practice in all countries. When looking to sell a car, the seller decides the price of their car after monitoring the prices of similar cars in the advertisements. When someone is looking to buy a car, they watch advertisements for similar cars to get an idea of the price of the car they want to purchase. Despite the availability of blue books that provide an estimate of automotive pricing, real market prices vary depending on demand and supply. In this paper, we applied cutting-edge machine learning techniques to automate this process. The training data set is up-to-date and it was collected from an active commercial website. We created semi-automated rule-based scripts to clean and prepare the data for machine learning. Several machine learning algorithms were explored to generate an approximate value for the car pricing, including Artificial Neural Network, Support Vector Machine, K-Nearest Neighbors, Random Forest, and Gradient Boosted Decision Tree. To determine the features that most affect the price, extensive data analysis and cleaning were undertaken. Our findings indicate that the testing accuracy is 90%. Finally, a mobile application was created that provides an estimated price of a given car's properties, guiding a user in determining the price of their car. The complete code and the data used to obtain these results can be accessed on GitHub at [1] [19].},
booktitle = {Proceedings of the 2021 3rd International Conference on Big-Data Service and Intelligent Computation},
pages = {52–60},
numpages = {9},
keywords = {mobile application, &nbsp;Car price Prediction, Regression, Machine learning},
location = {Xiamen, China},
series = {BDSIC '21}
}

@inproceedings{10.1145/3501409.3501532,
author = {Zhang, Kexin},
title = {Application of Data Mining Based on Machine Learning in Automobile Power Prediction},
year = {2022},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501532},
doi = {10.1145/3501409.3501532},
abstract = {Automobile power prediction is the key to the automobile industry. Only by reasonably predicting the automobile power can we produce cars that meet the needs of consumers. Compared with traditional methods, machine learning model improves the accuracy of classification in power. Machine learning models include BP neural network, random forest and KNN algorithm. In order to select the optimal vehicle power prediction model, this paper compares the advantages and disadvantages of these three machine learning models through design experiments.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1678–1681},
numpages = {4},
keywords = {KNN algorithm, BP neural network, machine learning, random forest, automobile power prediction},
location = {Xiamen, China},
series = {EITCE '21}
}

@inproceedings{10.1145/3018896.3018947,
author = {Rugwiro, Ulysse and Chunhua, Gu},
title = {Customization of Virtual Machine Allocation Policy Using K-Means Clustering Algorithm to Minimize Power Consumption in Data Centers},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018947},
doi = {10.1145/3018896.3018947},
abstract = {Cloud Computing provides rapid provision of computing resources like processing power, memory, network resources, storage, etc. Running computing resources for longer time, leads energy consumption, increase the emission of Carbon Dioxide (CO2) and increase the expenditure cost for the resources usage. Hence there is a necessity to minimize the execution time to reduce energy consumption in the cloud environment. One of the existing approaches to reducing energy consumption is based on Migration and Placement Policy for Virtual Machine, but still improving placement technique we can further minimize power consumption. In our proposed architecture for cloud resource allocation based on Clustering method, we do map a group of tasks to virtual machines. For clustering, we work on task usage of CPU, memory, and bandwidth. This proposed clustering technique further decreases energy consumption by efficient resource allocation.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {52},
numpages = {8},
keywords = {cloud computing, K-means clustering, virtual machine allocation, energy efficiency},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.5555/3586210.3586446,
author = {Burger, Mernout and Boer, Csaba A. and Straub, Edwin and Saanen, Yvo A.},
title = {Predictive Maintenance Powered by Machine Learning and Simulation},
year = {2023},
publisher = {IEEE Press},
abstract = {To optimize the balance between costs and reliability of cranes, it is important to perform maintenance when the risk of failures becomes high while possibly delaying planned maintenance when the crane shows no signs of possible problems. To accomplish this, we investigate the possibility of applying predictive maintenance for container-handling cranes. The application of predictive maintenance requires historical data collection and preprocessing of equipment sensor and maintenance data. To get a feeling of the possibilities and limitations of predictive maintenance for container-handling cranes, before investing time and money to collect operational data, we have used simulations to generate synthetic data for a few components of the cranes. Using the simulated crane data, a prediction model was trained to predict upcoming component failures. The results show that using simulation we can identify the possibilities and limitations of machine learning for predicting failures of components of the crane.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2807–2818},
numpages = {12},
location = {Singapore, Singapore},
series = {WSC '22}
}

@inbook{10.1145/3107990.3108006,
author = {Bengio, Samy and Deng, Li and Morency, Louis-Philippe and Schuller, Bj\"{o}rn},
title = {Perspectives on Predictive Power of Multimodal Deep Learning: Surprises and Future Directions},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3107990.3108006},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {455–472},
numpages = {18}
}

@inproceedings{10.1145/3147213.3149450,
author = {Chuah, Joon Yee},
title = {Machine Learning GPU Power Measurement on Chameleon Cloud},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3149450},
doi = {10.1145/3147213.3149450},
abstract = {Machine Learning (ML) is becoming critical for many industrial and scientific endeavors, and has a growing presence in High Performance Computing (HPC) environments. Neural network training requires long execution times for large data sets, and libraries like TensorFlow implement GPU acceleration to reduce the total runtime for each calculation. This tutorial demonstrates how to 1) use Chameleon Cloud to perform comparative studies of ML training performance across different hardware configurations; and 2) run and monitor power utilization of TensorFlow on NVIDIA GPUs.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {181},
numpages = {1},
keywords = {power, gpu, machine learning, acm proceedings},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/3368756.3369084,
author = {Karami, Elmehdi and Rafi, Mohamed and Ridah, Abderraouf},
title = {Output PV Power Prediction Using an Artificial Neural Network in Casablanca, Morocco},
year = {2019},
isbn = {9781450362894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368756.3369084},
doi = {10.1145/3368756.3369084},
abstract = {Optimal use of renewable energy requires its characterization and prediction to size detectors or estimate the potential of power plants [20-21]. In terms of prediction, electricity suppliers are interested in different horizons to manage power plants and predict their production [1-2]. This paper proposes a model for predicting the output power in photovoltaic (PV) panels installed on the rooftop of the Ben m'sik faculty at Hassan II University, Casablanca, Morocco, and this model is based on a multilayer perceptron (MLP) model. In this work, different combinations of weather variables were used to develop this model and for validate the proposed model results different practical measurement methods are used, such as mean square error (MSE), mean absolute error (MAE), correlation (R) and coefficient of determination (R2). The determination coefficient of the proposed model is 0.98501 with an RMSE value of 30.663. The proposed model was tested on new data, the results showed that the model works with a good preferment and that the prediction quality depends on the time of year with a determination coefficient of 0.9972, 0.9856, 0.9487 and 0.9942 for summer, autumn, winter and spring respectively.},
booktitle = {Proceedings of the 4th International Conference on Smart City Applications},
articleno = {97},
numpages = {8},
keywords = {artificial neural network, PV system, output PV power, meteorological parameters, prediction},
location = {Casablanca, Morocco},
series = {SCA '19}
}

@inproceedings{10.1145/3489517.3530600,
author = {Dong, Xiao and Chen, Yufei and Yin, Xunzhao and Zhuo, Cheng},
title = {Worst-Case Dynamic Power Distribution Network Noise Prediction Using Convolutional Neural Network},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530600},
doi = {10.1145/3489517.3530600},
abstract = {Worst-case dynamic PDN noise analysis is an essential step in PDN sign-off to ensure the performance and reliability of chips. However, with the growing PDN size and increasing scenarios to be validated, it becomes very time- and resource-consuming to conduct full-stack PDN simulation to check the worst-case noise for different test vectors. Recently, various works have proposed machine learning based methods for supply noise prediction, many of which still suffer from large training overhead, inefficiency, or non-scalability. Thus, this paper proposed an efficient and scalable framework for the worst-case dynamic PDN noise prediction. The framework first reduces the spatial and temporal redundancy in the PDN and input current vector, and then employs efficient feature extraction as well as a novel convolutional neural network architecture to predict the worst-case dynamic PDN noise. Experimental results show that the proposed framework consistently outperforms the commercial tool and the state-of-the-art machine learning method with only 0.63--1.02% mean relative error and 25--69\texttimes{} speedup.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {1225–1230},
numpages = {6},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3239576.3239609,
author = {Li, Rui and Li, Da and Zhang, Shuo},
title = {A Deep Learning Prediction Process Based on Low-Power Heterogeneous Multi Core Architecture},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239609},
doi = {10.1145/3239576.3239609},
abstract = {With the rapid development of machine learning both in theory and practice in the past decade. And recently, it is widely used in applications and cloud services. As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. In this paper, we designed a deep learning prediction process based on low-power heterogeneous multi core architecture. Firstly, the fundamental principle of image recognition method based on deep learning reviewed as the basis of the research. Secondly, a set of key algorithm design to parallel access and process image for object detection based on Parallella multi core platform was proposed to improve the detection speed and the computational resource efficiency on single node. Thirdly, Rockchip RK3288 SoC with 4 Arm Cortex-A17 cores hardware platform, Xilinx Zynq and Adapteva Epiphany combined heterogeneous multi core hardware platform was introduced. Some key designs based on Parallella board's architecture to achieve image recognition was proposed to improve the recognition speed and the computational resource efficiency. Finally, The experimental results that based on Parallella board indicate that the proposed image recognition system can achieve nearly 14.8 times speedup than dual-core Arm which was integrated in Parallella board with similar accuracy and achieve 8.6 times speedup than RK3288 board which has the newest series of high-performance Arm core CPU as the control included 4 Arm Cortex-A17 cores.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {220–224},
numpages = {5},
keywords = {Epiphany, the deep learning prediction process, multi core, Arm Cortex core, Accelerator},
location = {Chengdu, China},
series = {ICAIP '18}
}

@inproceedings{10.1145/2940679.2940685,
author = {Li, Yuanlong and Hu, Han and Wen, Yonggang and Zhang, Jun},
title = {Learning-Based Power Prediction for Data Centre Operations via Deep Neural Networks},
year = {2016},
isbn = {9781450344210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2940679.2940685},
doi = {10.1145/2940679.2940685},
abstract = {Modelling and analyzing power consumption for data centres can diagnose potential energy-hungry components and applications, and facilitate in-time control, benefiting the energy efficiency of data centers. However, solutions to this problem, including static power models and canonical prediction models, either aim to build a static relationship between power consumption and hardware/application configurations without considering the dynamic fluctuation of power; or simply treat it as time series, ignoring the inherit power data characteristics. To tackle these issues, in this paper, we present a systematic power prediction framework based on extensive power dynamic profiling and deep learning models. In particular, we first analyse different power series samples to illustrate their noise patterns; accordingly we propose a power data de-noising method, which lowers noise interference to the modelling. With the pretreated data, we propose two deep learning based prediction models, including a fine-grained model and a coarse-grained model, which are suitable for different time scales. In the fine-grained prediction model, a recursive autoencoder (AE) is employed for short-duration prediction; in the coarse-grained model, an AE is used to encode massive fine-grained historical data as a further data pretreatment for long-duration prediction. Experimental results show that our proposed models outperform canonical prediction methods with higher accuracy, up to 79% error reduction for certain cases.},
booktitle = {Proceedings of the 5th International Workshop on Energy Efficient Data Centres},
articleno = {6},
numpages = {10},
keywords = {power modelling, data centre, deep learning, power prediction},
location = {Waterloo, Ontario, Canada},
series = {E2DC '16}
}

@article{10.1145/3569942,
author = {Lu, Yi-Chen and Nath, Siddhartha and Pentapati, Sai and Lim, Sung Kyu},
title = {ECO-GNN: Signoff Power Prediction Using Graph Neural Networks with Subgraph Approximation},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1084-4309},
url = {https://doi.org/10.1145/3569942},
doi = {10.1145/3569942},
abstract = {Modern electronic design automation flows depend on both implementation and signoff tools to perform timing-constrained power optimization through Engineering Change Orders (ECOs), which involve gate sizing and threshold-voltage (Vth)-assignment of standard cells. However, the signoff ECO optimization is highly time-consuming, and the power improvement is hard to predict in advance. Ever since the industrial benchmarks released by the ISPD-2012 gate-sizing contest, active research has been conducted extensively to improve the optimization process. Nonetheless, previous works were mostly based on heuristics or analytical methods whose timing models were oversimplified and lacked of formal validations from commercial signoff tools. In this article, we propose ECO-graph neural networks (GNN), a transferable graph-learning-based framework, which harnesses GNNs to perform commercial-quality signoff power optimization through discrete (Vth-assignment. One of the highlights of our framework is that it generates tool-accurate optimization results instantly on unseen netlists that are not utilized in the training process. Furthermore, we propose a subgraph approximation technique to improve training and inferencing time of the proposed GNN model. We show that design instances with non-overlapping subgraphs can be optimized in parallel so as to improve the inference time of the learning-based model. Finally, we implement a GNN-based explanation method to interpret the optimization results achieved by our framework. Experimental results on 14 industrial designs, including a RISC-V-based multi-core system and the renowned ISPD-2012 benchmarks, demonstrate that our framework achieves up to 14\texttimes{} runtime improvement with similar signoff power optimization quality compared with Synopsys PrimeTime, an industry-leading signoff tool.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {may},
articleno = {55},
numpages = {22},
keywords = {power prediction, Graph Neural Networks (GNNs), Engineering Change Order (ECO)}
}

@inproceedings{10.1145/3297280.3297338,
author = {H\"{o}nig, Timo and Herzog, Benedict and Schr\"{o}der-Preikschat, Wolfgang},
title = {Energy-Demand Estimation of Embedded Devices Using Deep Artificial Neural Networks},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297338},
doi = {10.1145/3297280.3297338},
abstract = {The need for high performance in embedded devices grows at a breathtaking pace. Embedded processors that satisfy the hunger for superlative processing power share a common issue: the increasing performance leads to growing energy demands during operation. As energy remains a limited resource to embedded devices, it is critical to optimise software components for low power. Low-power software needs energy models which, however, are increasingly difficult to create as to the complexity of today's devices.In this paper we present a black-box approach to construct precise energy models for complex hardware devices. We apply machine-learning techniques in combination with fully automatic energy measurements and evaluate our approach with an ARM Cortex platform. We show that our system estimates the energy demand of program code with a mean percentage error of 1.8% compared to the results of energy measurements.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {617–624},
numpages = {8},
keywords = {machine learning, embedded systems, energy demand analysis},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3446999.3447639,
author = {Gong, Haixia},
title = {Uninterruptible Power Supply State of Charge Estimation Based on BP Neural Network},
year = {2021},
isbn = {9781450388559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3446999.3447639},
doi = {10.1145/3446999.3447639},
abstract = {Objetive: Display console is the software and hardware platform of warship and submarine control system. It's very important to strengthen the performance and improve the life of the Uninterruptible power supply (UPS) in display console . The residual capacity of UPS is a nonlinear function of voltage, discharge current, temperature and other variables. At present, there are some problems such as large measurement error and poor state prediction, what influence the battery power management system's management effectiveness. Therefore, this paper studies the estimation method of battery residual capacity based on BP Algorithm according to the principle of neural network, so as to improve the estimation accuracy of UPS residual capacity. Method: Firstly, we establish the BP neural network model consists of three layers, secondly gather UPS experimental data set, then build, train and test BP network model with LM algorithm by Matlab program language, finally gather the state of charge(SOC) training results. Result: Experimental results indicate that the method in this paper can estimate UPS SOC accurately and efficiently. Conclusion: It can satisfy the system requirements of uninterruptible power supply SOC estimation.},
booktitle = {Proceedings of the 2020 8th International Conference on Information Technology: IoT and Smart City},
pages = {240–243},
numpages = {4},
keywords = {state of charge, BP neural network, MATLAB, uninterruptible power supply},
location = {Xi'an, China},
series = {ICIT '20}
}

@inproceedings{10.1145/3274783.3274836,
author = {Jia, Zhenhua and Lyu, Xinmeng and Zhang, Wuyang and Martin, Richard P. and Howard, Richard E. and Zhang, Yanyong},
title = {Continuous Low-Power Ammonia Monitoring Using Long Short-Term Memory Neural Networks},
year = {2018},
isbn = {9781450359528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274783.3274836},
doi = {10.1145/3274783.3274836},
abstract = {Accurate and continuous ammonia monitoring is important for laboratory animal studies and many other applications. Existing solutions are often expensive, inaccurate, or unsuitable for long-term monitoring. In this work, we propose a new ammonia monitoring approach that is low-power, automatic, accurate, and wireless.Our system uses metal oxide sensors which change their electrical resistance due to an induced reduction reaction with ammonia at high temperatures. Traditional methods infer the ammonia level by measuring the sensor's electrical resistance after it reaches equilibrium. Such a system consumes a significant amount of energy because reaching equilibrium requires heating the sensor for minutes. Our proposed approach does not wait for equilibrium, but tries to predict the resistance at equilibrium using the sensor's initial resistance response curve in a very short heating pulse (as short as 200ms). The prediction model is built on long short-term memory (LSTM) neural networks.We built 38 prototype sensors and a home-grown gas flow system. In a 3-month in-lab testing period, we conducted extensive experiments and collected 13,770 measurements. Our model accurately predicts the equilibrium state resistance value, with an average error rate of 0.12%. The final average estimation error for the ammonia concentration level is 9.38ppm. Given the ultra low power consumption and accurate measurements, we have partnered with cage vendors and deployed our system at two animal research facilities (NIH and Cornell University) for month-long medical trials.},
booktitle = {Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems},
pages = {224–236},
numpages = {13},
keywords = {Low-power, Neural Networks, Ammonia Sensor, Long Short-term Memory, Transient Response},
location = {Shenzhen, China},
series = {SenSys '18}
}

@article{10.1109/TASLP.2020.2987441,
author = {Zhang, Qiquan and Nicolson, Aaron and Wang, Mingjiang and Paliwal, Kuldip K. and Wang, Chenxu},
title = {DeepMMSE: A Deep Learning Approach to MMSE-Based Noise Power Spectral Density Estimation},
year = {2020},
issue_date = {2020},
publisher = {IEEE Press},
volume = {28},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2020.2987441},
doi = {10.1109/TASLP.2020.2987441},
abstract = {An accurate noise power spectral density (PSD) tracker is an indispensable component of a single-channel speech enhancement system. Bayesian-motivated minimum mean-square error (MMSE)-based noise PSD estimators have been the most prominent in recent time. However, they lack the ability to track highly non-stationary noise sources due to current methods of a priori signal-to-noise (SNR) estimation. This is caused by the underlying assumption that the noise signal changes at a slower rate than the speech signal. As a result, MMSE-based noise PSD trackers exhibit a large tracking delay and produce noise PSD estimates that require bias compensation. Motivated by this, we propose an MMSE-based noise PSD tracker that employs a temporal convolutional network (TCN) a priori SNR estimator. The proposed noise PSD tracker, called DeepMMSE makes no assumptions about the characteristics of the noise or the speech, exhibits no tracking delay, and produces an accurate estimate that requires no bias correction. Our extensive experimental investigation shows that the proposed DeepMMSE method outperforms state-of-the-art noise PSD trackers and demonstrates the ability to track abrupt changes in the noise level. Furthermore, when employed in a speech enhancement framework, the proposed DeepMMSE method is able to outperform state-of-the-art noise PSD trackers, as well as multiple deep learning approaches to speech enhancement. Availability: DeepMMSE is available at: https://github.com/anicolson/DeepXi.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = {may},
pages = {1404–1415},
numpages = {12}
}

@inproceedings{10.1145/3127540.3127577,
author = {Al Qathrady, Mimonah and Helmy, Ahmed},
title = {Improving BLE Distance Estimation and Classification Using TX Power and Machine Learning: A Comparative Analysis},
year = {2017},
isbn = {9781450351621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127540.3127577},
doi = {10.1145/3127540.3127577},
abstract = {Distance estimation and proximity classification techniques are essential for numerous IoT applications and in providing efficient services in smart cities. Bluetooth Low Energy (BLE) is designed for IoT devices, and its received signal strength indicator (RSSI) has been used in distance and proximity estimation, though they are noisy and unreliable. In this study, we leverage the BLE TX power level in BLE models.We adopt a comparative analysis framework that utilizes our extensive data library of measurements. It considers commonly used state-of-the-art model, in addition to our data-driven proposed approach. The RSSI and TX power are integrated into several parametric models such as log shadowing and Android Beacon library models, and machine learning models such as linear regression, decision trees, random forests and neural networks. Specific mobile apps are developed for the study experiment. We have collected more than 1.8 millions of BLE records between encounters with various distances that range from 0.5 to 22 meters in an indoor environment. Interestingly, considering TX power when estimating the distance reduced the mean errors by up to 46% in parametric models and by up to 35% in machine learning models. Also, the proximity classification accuracy increased by up to 103% and 70% in parametric and machine learning models, respectively. This work is one of the first studies (if not the first) that analyze in depth the TX power variations in improving the distance estimation and classification.},
booktitle = {Proceedings of the 20th ACM International Conference on Modelling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {79–83},
numpages = {5},
keywords = {ble, distance estimation, iot, proximity classification},
location = {Miami, Florida, USA},
series = {MSWiM '17}
}

@inproceedings{10.1145/2593743.2593745,
author = {Bergen, Andreas and Desmarais, Ronald and Ganti, Sudhakar and Stege, Ulrike},
title = {Towards Software-Adaptive Green Computing Based on Server Power Consumption},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593743.2593745},
doi = {10.1145/2593743.2593745},
abstract = {With the proliferation of virtualization and cloud comput- ing, optimizing the power usage effectiveness of enterprise data centers has become a laudable goal and a critical re- quirement in IT operations all over the world. While a sig- nificant body of research exists to measure, monitor, and control the greenness level of hardware components, signif- icant research efforts are needed to relate hardware energy consumption to energy consumption due to program exe- cution. In this paper we report on our investigations to characterize power consumption profiles for different types of compute and memory intensive software applications. In particular, we focus on studying the effects of CPU loads on the power consumption of compute servers by monitoring rack power consumption in a data center. We conducted a series of experiments with a variety of processes of differ- ent complexity to understand and characterize the effect on power consumption. Combining processes of varying com- plexity with varying resource allocations produces different energy consumption levels. The challenge is to optimize pro- cess orchestration based on a power consumption framework to accrue energy savings. Our ultimate goal is to develop smart adaptive green computing techniques, such as adap- tive job scheduling and resource provisioning, to reduce over- all power consumption in data centers or clouds.},
booktitle = {Proceedings of the 3rd International Workshop on Green and Sustainable Software},
pages = {9–16},
numpages = {8},
keywords = {cloud computing, data centers, Power consumption measurments, power consumption framework, green-aware, power application pro- files, self-adaptive green computing},
location = {Hyderabad, India},
series = {GREENS 2014}
}

@inproceedings{10.5555/2872599.2872614,
author = {Shoukourian, Hayk and Wilde, Torsten and Auweter, Axel and Bode, Arndt and Tafani, Daniele},
title = {Predicting Energy Consumption Relevant Indicators of Strong Scaling HPC Applications for Different Compute Resource Configurations},
year = {2015},
isbn = {9781510801011},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Finding the best energy-performance tradeoffs for High Performance Computing (HPC) applications is a major challenge for many modern supercomputing centers. With the increased focus on data center energy efficiency and the emergence of possible data center power constraints, making the right decision at a given time is becoming more important. A real-world situation like "can a given 1000 compute node application be executed at a maximum of 2.7 GHz CPU frequency without going over the energy provider defined power band, or the available monthly energy limit?" is just one example of the types of decisions HPC data centers will face. The previously developed Adaptive Energy and Power Consumption Prediction (AEPCP) model answers this question for the case of a fixed CPU frequency. This paper will extend the AEPCP process to enable the development of analytical models for estimating application execution time, power, and energy consumptions as functions of the number of compute nodes and maximum operating CPU frequency. Based on these analytical models, an adaptive model (Lightweight Adaptive Consumption Prediction (LACP)) is presented that implements the extended prediction process. This information allows for improved estimation of potential energy-performance costs and tradeoffs of applications and thus identifies the optimal resource configuration for specific data center boundary conditions.},
booktitle = {Proceedings of the Symposium on High Performance Computing},
pages = {115–126},
numpages = {12},
keywords = {LACP, HPC, power and energy capping, consumption modeling and prediction, compute node number and CPU frequency},
location = {Alexandria, Virginia},
series = {HPC '15}
}

@article{10.1109/TCBB.2021.3139048,
author = {Wu, Tzu-Hsuan and Lin, Peng-Chan and Chou, Hsin-Hung and Shen, Meng-Ru and Hsieh, Sun-Yuan},
title = {Pathogenicity Prediction of Single Amino Acid Variants With Machine Learning Model Based on Protein Structural Energies},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3139048},
doi = {10.1109/TCBB.2021.3139048},
abstract = {The most popular tools for predicting pathogenicity of single amino acid variants (SAVs) were developed based on sequence-based techniques. SAVs may change protein structure and function. In the context of van der Waals force and disulfide bridge calculations, no method directly predicts the impact of mutations on the energies of the protein structure. Here, we combined machine learning methods and energy scores of protein structures calculated by Rosetta Energy Function 2015 to predict SAV pathogenicity. The accuracy level of our model (0.76) is higher than that of six prediction tools. Further analyses revealed that the differential reference energies, attractive energies, and solvation of polar atoms between wildtype and mutant side-chains played essential roles in distinguishing benign from pathogenic variants. These features indicated the physicochemical properties of amino acids, which were observed in 3D structures instead of sequences. We added 16 features to Rhapsody (the prediction tool we used for our data set) and consequently improved its performance. The results indicated that these energy scores were more appropriate and more detailed representations of the pathogenicity of SAVs.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {dec},
pages = {606–615},
numpages = {10}
}

@inproceedings{10.1145/2902961.2903037,
author = {Liu, Ning and Ding, Caiwen and Wang, Yanzhi and Hu, Jingtong},
title = {Neural Network-Based Prediction Algorithms for In-Door Multi-Source Energy Harvesting System for Non-Volatile Processors},
year = {2016},
isbn = {9781450342742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2902961.2903037},
doi = {10.1145/2902961.2903037},
abstract = {Due to size, longevity, safety, and recharging concerns, energy harvesting is becoming a better choice for many wearable embedded systems than batteries. However, harvested energy is intrinsically unstable. In order to overcome this drawback, non-volatile processors (NVPs) have been proposed to bridge intermittent program execution. However, even with NVPs, frequent power interruptions will severely degrade system performance. Hence, in this paper we adopt a multi-source in-door energy harvesting architecture to compensate the shortcoming of single energy source. We further investigate power harvesting prediction techniques, which are critical for NVP systems since they can coordinate with task scheduler in the NVP system to compensate the intermittent ambient energy harvesting. We investigate prediction methods both for single energy harvesting source and for multiple energy harvesting sources, the total output power of which is more stable compared with the single source case. A comprehensive evaluation framework has been developed using actually measured harvesting traces on the proposed neural network-based power harvesting prediction methods. It turns out that the most favorable prediction methods are directly predicting the total output power of DC-DC converters (connecting between energy sources and NVP), or predicting the total input power of DC-DC converters first and then inferring the total output power using a learned mapping function, for multi-source power harvesting predictions.},
booktitle = {Proceedings of the 26th Edition on Great Lakes Symposium on VLSI},
pages = {275–280},
numpages = {6},
keywords = {energy harvesting, neural network, non-volatile processors, multiple energy source},
location = {Boston, Massachusetts, USA},
series = {GLSVLSI '16}
}

@inproceedings{10.1145/2318716.2318718,
author = {Basmadjian, Robert and Ali, Nasir and Niedermeier, Florian and de Meer, Hermann and Giuliani, Giovanni},
title = {A Methodology to Predict the Power Consumption of Servers in Data Centres},
year = {2011},
isbn = {9781450313131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2318716.2318718},
doi = {10.1145/2318716.2318718},
abstract = {Until recently, there have been relatively few studies exploring the power consumption of ICT resources in data centres. In this paper, we propose a methodology to capture the behaviour of most relevant energy-related ICT resources in data centres and present a generic model for them. This is achieved by decomposing the design process into four modelling phases. Furthermore, unlike the state-of-the-art approaches, we provide detailed power consumption models at server and storage levels. We evaluate our model for different types of servers and show that it suffers from an error rate of 2% in the best case, and less than 10% in the worst case.},
booktitle = {Proceedings of the 2nd International Conference on Energy-Efficient Computing and Networking},
pages = {1–10},
numpages = {10},
keywords = {IT resources, power consumption, modelling, data centre},
location = {New York, New York, USA},
series = {e-Energy '11}
}

@inproceedings{10.1145/3297663.3310298,
author = {von Kistowski, J\'{o}akim and Grohmann, Johannes and Schmitt, Norbert and Kounev, Samuel},
title = {Predicting Server Power Consumption from Standard Rating Results},
year = {2019},
isbn = {9781450362399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297663.3310298},
doi = {10.1145/3297663.3310298},
abstract = {Data center providers and server operators try to reduce the power consumption of their servers. Finding an energy efficient server for a specific target application is a first step in this regard. Estimating the power consumption of an application on an unavailable server is difficult, as nameplate power values are generally overestimations. Offline power models are able to predict the consumption accurately, but are usually intended for system design, requiring very specific and detailed knowledge about the system under consideration.In this paper, we introduce an offline power prediction method that uses the results of standard power rating tools. The method predicts the power consumption of a specific application for multiple load levels on a target server that is otherwise unavailable for testing. We evaluate our approach by predicting the power consumption of three applications on different physical servers. Our method is able to achieve an average prediction error of 9.49% for three workloads running on real-world, physical servers.},
booktitle = {Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {301–312},
numpages = {12},
keywords = {interpolation, power, regression, energy efficiency, prediction, performance, benchmarking, load level},
location = {Mumbai, India},
series = {ICPE '19}
}

@inproceedings{10.1145/3439961.3439991,
author = {Rivero, Luis and Diniz, Jo\~{a}o and Silva, Giovanni and Borralho, Gabriel and Braz Junior, Geraldo and Paiva, Anselmo and Alves, Erika and Oliveira, Milton},
title = {Deployment of a Machine Learning System for Predicting Lawsuits Against Power Companies: Lessons Learned from an Agile Testing Experience for Improving Software Quality},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439991},
doi = {10.1145/3439961.3439991},
abstract = {The advances in Machine Learning (ML) require software organizations to evolve their development processes in order to improve the quality of ML systems. Within the software development process, the testing stage of an ML system is more critical, considering that it is necessary to add data validation, trained model quality evaluation, and model validation to traditional unit, integration tests and system tests. In this paper, we focus on reporting the lessons learned of using model testing and exploratory testing within the context of the agile development process of an ML system that predicts lawsuits proneness in energy supply companies. Through the development of the project, the SCRUM agile methodology was applied and activities related to the development of the ML model and the development of the end-user application were defined. After the testing process of the ML model, we managed to achieve 93.89 accuracy; 95.58 specificity; 88.84 sensitivity; and 87.09 precision. Furthermore, we focused on the quality of use of the application embedding the ML model, by carrying out exploratory testing. As a result, through several iterations, different types of defects were identified and corrected. Our lessons learned support software engineers willing to develop ML systems that consider both the ML model and the end-user application.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {30},
numpages = {10},
keywords = {and Tools, Methods, Verification, Software Processes, and Testing, Validation},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@inproceedings{10.1145/3463677.3463715,
author = {Palma, Ingrid and Ladeira, Marcelo and Reis, Ana Carla Bittencourt},
title = {Machine Learning Predictive Model for the Passive Transparency at the Brazilian Ministry of Mines and Energy},
year = {2021},
isbn = {9781450384926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463677.3463715},
doi = {10.1145/3463677.3463715},
abstract = {This paper presents a case study based on the CRISP-DM Model and the use of Text Mining tools and techniques to automate the Passive Transparency process at the Brazilian Ministry of Mines and Energy. Thus, a Machine Learning Model is proposed to predict the class of the technical unit responsible for the data/information requested by citizens. Through the application of the algorithm LDA and TF-IDF it was possible to map the topics of the most relevant subjects for society. The stability of the model was tested from the comparative analysis between 5 known classification algorithms (Random Forest, Multinomial NB, Linear SVC, Logistic Regression, XGBoost and Gradient Boosting). XGBoost presented better performance and precision in multiclass learning outcomes.},
booktitle = {DG.O2021: The 22nd Annual International Conference on Digital Government Research},
pages = {76–81},
numpages = {6},
keywords = {Passive Transparency, Predictive Analisys and XGBoost., Topic Modeling, Multicriteria Decision Making, Machine Learning Algorithms},
location = {Omaha, NE, USA},
series = {DG.O'21}
}

@inproceedings{10.1145/3579170.3579263,
author = {Dariol, Quentin and Le Nours, Sebastien and Helms, Domenik and Stemmer, Ralf and Pillement, Sebastien and Gr\"{u}ttner, Kim},
title = {Fast Yet Accurate Timing and Power Prediction of Artificial Neural Networks Deployed on Clock-Gated Multi-Core Platforms},
year = {2023},
isbn = {9798400700453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579170.3579263},
doi = {10.1145/3579170.3579263},
abstract = {When deploying Artificial Neural Networks (ANNs) onto multi-core embedded platforms, an intensive evaluation flow is necessary to find implementations that optimize resource usage, timing and power. ANNs require indeed significant amounts of computational and memory resources to execute, while embedded execution platforms offer limited resources with strict power budget. Concurrent accesses from processors to shared resources on multi-core platforms can lead to bottlenecks with impact on performance and power. Existing approaches show limitations to deliver fast yet accurate evaluation ahead of ANN deployment on the targeted hardware. In this paper, we present a modeling flow for timing and power prediction in early design stage of fully-connected ANNs on multi-core platforms. Our flow offers fast yet accurate predictions with consideration of shared communication resources and scalability in regards of the number of cores used. The flow is evaluated on real measurements for 42 mappings of 3 fully-connected ANNs executed on a clock-gated multi-core platform featuring two different communication modes: polling or interrupt-based. Our modeling flow predicts timing with accuracy and power with accuracy on the tested mappings for an average simulation time of 0.23 s for 100 iterations. We then illustrate the application of our approach for efficient design space exploration of ANN implementations.},
booktitle = {Proceedings of the DroneSE and RAPIDO: System Engineering for Constrained Embedded Systems},
pages = {79–86},
numpages = {8},
keywords = {System Level Simulation, Power Model, Multi-Core, Artificial Neural Networks},
location = {Toulouse, France},
series = {RAPIDO '23}
}

@article{10.1145/3399677,
author = {Dey, Sukanta and Nandi, Sukumar and Trivedi, Gaurav},
title = {Machine Learning Approach for Fast Electromigration Aware Aging Prediction in Incremental Design of Large Scale On-Chip Power Grid Network},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3399677},
doi = {10.1145/3399677},
abstract = {With the advancement of technology nodes, Electromigration (EM) signoff has become increasingly difficult, which requires a considerable amount of time for an incremental change in the power grid (PG) network design in a chip. The traditional Black’s empirical equation and Blech’s criterion are still used for EM assessment, which is a time-consuming process. In this article, for the first time, we propose a machine learning (ML) approach to obtain the EM-aware aging prediction of the PG network. We use neural network--based regression as our core ML technique to instantly predict the lifetime of a perturbed PG network. The performance and accuracy of the proposed model using neural network are compared with the well-known standard regression models. We also propose a new failure criterion based on which the EM-aging prediction is done. Potential EM-affected metal segments of the PG network is detected by using a logistic-regression--based classification ML technique. Experiments on different standard PG benchmarks show a significant speedup for our ML model compared to the state-of-the-art models. The predicted value of MTTF for different PG benchmarks using our approach is also better than some of the state-of-the-art MTTF prediction models and comparable to the other accurate models.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {jul},
articleno = {42},
numpages = {29},
keywords = {Electromigration, machine learning, regression, power grid network, reliability, MTTF, neural network}
}

@inproceedings{10.1145/3387168.3387176,
author = {Park, Joon-Young and Kim, Seok-Tae and Lee, Jae-Kyung and Ham, Ji-Wan and Oh, Ki-Yong},
title = {Automatic Inspection Drone with Deep Learning-Based Auto-Tracking Camera Gimbal to Detect Defects in Power Lines},
year = {2020},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387176},
doi = {10.1145/3387168.3387176},
abstract = {The traditional drone inspection performed by human operators is unsuited for the purpose of inspecting power transmission lines, because steel towers and their spans are too high and wide to be inspected with a 250 m line of sight. For this reason, the KEPCO Research Institute developed a new inspection drone system that can automatically fly a predetermined flight path based on the GPS coordinates of steel towers, filming a video of power transmission lines with a high definition camera and a thermal imaging camera. In this system, a camera gimbal with the cameras was still controlled by a human operator from a long distance away. When the drone approached close to a steel tower, however, the camera gimbal was often unable to be controlled and real-time video transmission for the gimbal operator was sometimes interrupted due to radio-frequency interference from steel structure and energized power conductors. To solve such a control problem in the field, we also developed an auto-tracking camera gimbal that can automatically track and photograph power facilities on the basis of Deep Learning. With the automatic gimbal, the entire inspection process can be fully automated. The effectiveness of the developed overall system was confirmed through field tests.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {46},
numpages = {6},
keywords = {Deep Learning, Power Line Inspection, Gimbal, Automatic Drone, Auto-tracking, Camera},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@inproceedings{10.1145/2597917.2597956,
author = {Chiroma, Haruna and Gital, Abdulsalam Ya'u and Abubakar, Adamu and Usman, Mohammed Joda and Waziri, Usman},
title = {Optimization of Neural Network through Genetic Algorithm Searches for the Prediction of International Crude Oil Price Based on Energy Products Prices},
year = {2014},
isbn = {9781450328708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597917.2597956},
doi = {10.1145/2597917.2597956},
abstract = {This study investigated the prediction of crude oil price based on energy product prices using genetically optimized Neural Network (GANN). It was found from experimental evidence that the international crude oil price can be predicted based on energy product prices. The comparison of the prediction performance accuracy of the propose GANN with Support Vector Machine (SVM), Vector Autoregression (VAR), and Feed Forward NN (FFNN) suggested that the propose GANN was more accurate than the SVM, VAR, and FFNN in the prediction accuracy and time computational complexity. The propose GANN was able to improve the performance accuracy of the comparison algorithms. Our approach can easily be modified for the prediction of similar commodities.},
booktitle = {Proceedings of the 11th ACM Conference on Computing Frontiers},
articleno = {27},
numpages = {2},
keywords = {genetic algorithm, neural network, crude oil price},
location = {Cagliari, Italy},
series = {CF '14}
}

@inproceedings{10.1145/3555776.3577739,
author = {Rubin, Felipe and Souza, Paulo and Ferreto, Tiago},
title = {Reducing Power Consumption during Server Maintenance on Edge Computing Infrastructures},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577739},
doi = {10.1145/3555776.3577739},
abstract = {Edge servers must routinely undergo maintenance to ensure the environment's performance and security. During maintenance, applications hosted by outdated servers must be relocated to alternative servers to avoid downtime. In distributed edges with servers spread across large regions, ensuring that applications are not migrated to servers too far away from their users to avoid high latency hardens the maintenance planning. In addition, the limited power supply of edge sites restricts the list of suitable alternative hosts for the applications even further. Past work has focused on optimizing maintenance or increasing the power efficiency of edge computing infrastructures. However, no work addresses both objectives together. This paper presents Emma, a maintenance strategy that reduces power consumption during edge server maintenance without excessively extending maintenance time or increasing application latency. Experiments show that Emma can minimize power consumption during maintenance by up to 26.48% compared to strategies from the literature.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {691–698},
numpages = {8},
keywords = {edge computing, update, maintenance, infrastructure, power consumption},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@article{10.1145/2355585.2355588,
author = {Lewis, Adam Wade and Tzeng, Nian-Feng and Ghosh, Soumik},
title = {Runtime Energy Consumption Estimation for Server Workloads Based on Chaotic Time-Series Approximation},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1544-3566},
url = {https://doi.org/10.1145/2355585.2355588},
doi = {10.1145/2355585.2355588},
abstract = {This article proposes a runtime model that relates server energy consumption to its overall thermal envelope, using hardware performance counters and experimental measurements. While previous studies have attempted system-wide modeling of server power consumption through subsystem models, our approach is different in that it links system energy input to subsystem energy consumption based on a small set of tightly correlated parameters. The proposed model takes into account processor power, bus activities, and system ambient temperature for real-time prediction on the power consumption of long running jobs. Using the HyperTransport and QuickPath Link structures as case studies and through electrical measurements on example server subsystems, we develop a chaotic time-series approximation for runtime power consumption, arriving at the Chaotic Attractor Predictor (CAP). With polynomial time complexity, CAP exhibits high prediction accuracy, having the prediction errors within 1.6% (or 3.3%) for servers based on the HyperTransport bus (or the QuickPath Links), as verified by a set of common processor benchmarks. Our CAP is a superior predictive mechanism over existing linear auto-regressive methods, which require expensive and complex corrective steps to address the nonlinear and chaotic aspects of the underlying physical system.},
journal = {ACM Trans. Archit. Code Optim.},
month = {oct},
articleno = {15},
numpages = {26},
keywords = {chaotic time series, Analysis of variance, thermal envelope, time series approximation, QuickPath links, performance counters, HyperTransport buses, energy consumption}
}

@inproceedings{10.1145/3139958.3140053,
author = {Zhang, Sheng and Zhao, Shenglin and Yuan, Mingxuan and Zeng, Jia and Yao, Jianguo and Lyu, Michael R. and King, Irwin},
title = {Traffic Prediction Based Power Saving in Cellular Networks: A Machine Learning Method},
year = {2017},
isbn = {9781450354905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139958.3140053},
doi = {10.1145/3139958.3140053},
abstract = {In smart cities, green cellular networks play a crucial role to support wireless access for numerous devices anywhere and anytime with efficiency and sustainability. Because base stations (BSes) consume more than 70% of overall cellular network infrastructure energy, saving the power consumption of BSes is the key task to build a green cellular network. Except for low power design of the BS hardware and software, the traffic-driven BS sleeping operation is an economical way to improve existing cellular networks, which can reduce the BS power consumption at low traffic load. However, prior BS sleeping strategies establish on the static temporal characteristics of traffic load, which ignore the fact that network traffic is influenced by many factors such as time, human mobility, holiday, weather, etc. Hence, prior traffic estimation is coarse, and the BS sleeping strategies cannot apply to the changing network traffic. In this paper, we exploit a machine learning method to estimate the BS traffic and propose a BS sleeping strategy based on predicted traffic for power saving in the cellular network. We analyze network traffic in multi-views: temporal influence, spatial influence, and event influence. Then, we propose a multi-view ensemble learning model to predict network traffic load, which learns the traffic in multi-views and combine the results with ensemble. Furthermore, we formulate a BS sleeping strategy based on the predicted traffic load. Finally, we evaluate our traffic prediction algorithm on real cellular network data. The evaluation shows that our traffic prediction algorithm improves about 40% than state-of-the-art machine learning methods. Also, we evaluate the proposed BS sleeping strategy, which yields about 10% more energy savings and less device damage than the competitors in the simulated environment.},
booktitle = {Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
articleno = {29},
numpages = {10},
keywords = {Smart City, Green Cellular Network, Network Traffic Prediction, Multi-view Learning, Spatio-Temporal Data Analysis},
location = {Redondo Beach, CA, USA},
series = {SIGSPATIAL '17}
}

@inproceedings{10.1145/2150976.2150980,
author = {Chang, Jichuan and Meza, Justin and Ranganathan, Parthasarathy and Shah, Amip and Shih, Rocky and Bash, Cullen},
title = {Totally Green: Evaluating and Designing Servers for Lifecycle Environmental Impact},
year = {2012},
isbn = {9781450307598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2150976.2150980},
doi = {10.1145/2150976.2150980},
abstract = {The environmental impact of servers and datacenters is an important future challenge. System architects have traditionally focused on operational energy as a proxy for designing green servers, but this ignores important environmental implications from server production (materials, manufacturing, etc.). In contrast, this paper argues for a lifecycle focus on the environmental impact of future server designs, to include both operation and production. We present a new methodology to quantify the total environmental impact of system design decisions. Our approach uses the thermodynamic metric of exergy consumption, adapted and validated for use by system architects. Using this methodology, we evaluate the lifecycle impact of several example system designs with environment-friendly optimizations. Our results show that environmental impact from production can be important (around 20% on current servers and growing) and system design choices can reduce this component (by 30--40%). Our results also highlight several, sometimes unexpected, cross-interactions between the environmental impact of production and operation that further motivate a total lifecycle emphasis for future green server designs.},
booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {25–36},
numpages = {12},
keywords = {dematerialization, green computing, lifecycle impact, server architecture, environmental sustainability, datacenter design, exergy, disaggregation},
location = {London, England, UK},
series = {ASPLOS XVII}
}

@article{10.1145/2189750.2150980,
author = {Chang, Jichuan and Meza, Justin and Ranganathan, Parthasarathy and Shah, Amip and Shih, Rocky and Bash, Cullen},
title = {Totally Green: Evaluating and Designing Servers for Lifecycle Environmental Impact},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2189750.2150980},
doi = {10.1145/2189750.2150980},
abstract = {The environmental impact of servers and datacenters is an important future challenge. System architects have traditionally focused on operational energy as a proxy for designing green servers, but this ignores important environmental implications from server production (materials, manufacturing, etc.). In contrast, this paper argues for a lifecycle focus on the environmental impact of future server designs, to include both operation and production. We present a new methodology to quantify the total environmental impact of system design decisions. Our approach uses the thermodynamic metric of exergy consumption, adapted and validated for use by system architects. Using this methodology, we evaluate the lifecycle impact of several example system designs with environment-friendly optimizations. Our results show that environmental impact from production can be important (around 20% on current servers and growing) and system design choices can reduce this component (by 30--40%). Our results also highlight several, sometimes unexpected, cross-interactions between the environmental impact of production and operation that further motivate a total lifecycle emphasis for future green server designs.},
journal = {SIGARCH Comput. Archit. News},
month = {mar},
pages = {25–36},
numpages = {12},
keywords = {exergy, dematerialization, green computing, disaggregation, lifecycle impact, environmental sustainability, datacenter design, server architecture}
}

@article{10.1145/2248487.2150980,
author = {Chang, Jichuan and Meza, Justin and Ranganathan, Parthasarathy and Shah, Amip and Shih, Rocky and Bash, Cullen},
title = {Totally Green: Evaluating and Designing Servers for Lifecycle Environmental Impact},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2248487.2150980},
doi = {10.1145/2248487.2150980},
abstract = {The environmental impact of servers and datacenters is an important future challenge. System architects have traditionally focused on operational energy as a proxy for designing green servers, but this ignores important environmental implications from server production (materials, manufacturing, etc.). In contrast, this paper argues for a lifecycle focus on the environmental impact of future server designs, to include both operation and production. We present a new methodology to quantify the total environmental impact of system design decisions. Our approach uses the thermodynamic metric of exergy consumption, adapted and validated for use by system architects. Using this methodology, we evaluate the lifecycle impact of several example system designs with environment-friendly optimizations. Our results show that environmental impact from production can be important (around 20% on current servers and growing) and system design choices can reduce this component (by 30--40%). Our results also highlight several, sometimes unexpected, cross-interactions between the environmental impact of production and operation that further motivate a total lifecycle emphasis for future green server designs.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {25–36},
numpages = {12},
keywords = {dematerialization, green computing, datacenter design, lifecycle impact, exergy, environmental sustainability, disaggregation, server architecture}
}

@article{10.1145/3477009,
author = {Qiu, Keni and Jao, Nicholas and Zhou, Kunyu and Liu, Yongpan and Sampson, Jack and Kandemir, Mahmut Taylan and Narayanan, Vijaykrishnan},
title = {MaxTracker: Continuously Tracking the Maximum Computation Progress for Energy Harvesting ReRAM-Based CNN Accelerators},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3477009},
doi = {10.1145/3477009},
abstract = {There is an ongoing trend to increasingly offload inference tasks, such as CNNs, to edge devices in many IoT scenarios. As energy harvesting is an attractive IoT power source, recent ReRAM-based CNN accelerators have been designed for operation on harvested energy. When addressing the instability problems of harvested energy, prior optimization techniques often assume that the load is fixed, overlooking the close interactions among input power, computational load, and circuit efficiency, or adapt the dynamic load to match the just-in-time incoming power under a simple harvesting architecture with no intermediate energy storage.Targeting a more efficient harvesting architecture equipped with both energy storage and energy delivery modules, this paper is the first effort to target whole system, end-to-end efficiency for an energy harvesting ReRAM-based accelerator. First, we model the relationships among ReRAM load power, DC-DC converter efficiency, and power failure overhead. Then, a maximum computation progress tracking scheme (MaxTracker) is proposed to achieve a joint optimization of the whole system by tuning the load power of the ReRAM-based accelerator. Specifically, MaxTracker accommodates both continuous and intermittent computing schemes and provides dynamic ReRAM load according to harvesting scenarios.We evaluate MaxTracker over four input power scenarios, and the experimental results show average speedups of 38.4%/40.3% (up to 51.3%/84.4%), over a full activation scheme (with energy storage) and order-of-magnitude speedups over the recently proposed (energy storage-less) ResiRCA technique. Furthermore, we also explore MaxTracker in combination with the Capybara reconfigurable capacitor approach to offer more flexible tuners and thus further boost the system performance.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {78},
numpages = {23},
keywords = {maximum computation progress, CNN, DC-DC efficiency, Energy harvesting, computing schemes, ReRAM crossbar}
}

@inproceedings{10.5555/3237383.3238136,
author = {OuldOuali, Lydia and Sabouret, Nicolas and Rich, Charles},
title = {I've Got the Power's Value! A Computational Model to Evaluate the Interlocutor's Behaviors in Collaborative Negotiation: Socially Interactive Agents Track},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We present in this paper a simulation-oriented theory of mind model for interpreting behaviors of power during a collaborative negotiation. This model relies on a model of negotiation that allows an agent to express behaviors of power through its strategy of negotiation. Based on the simulation theory, we adapted the decision model of the agent to reason about its interlocutor's behavior. A preliminary evaluation in the context of agent-agent interaction shows that the system correctly predicts the interlocutor's power.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2245–2246},
numpages = {2},
keywords = {reasoning about other, theory of mind, dominance},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.1145/3164541.3164608,
author = {Bui, Dinh-Mao and Huh, Eui-Nam and Lee, Sungyoung},
title = {Optimizing Power Consumption in Cloud Computing Based on Optimization and Predictive Analysis},
year = {2018},
isbn = {9781450363853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3164541.3164608},
doi = {10.1145/3164541.3164608},
abstract = {Due to the budget and the environmental issues, achieving energy efficiency gradually receives a lot of attentions these days. In our previous research, a prediction technique has been developed to improve the monitoring statistics. In this research, by adopting the predictive monitoring information, our new proposal can perform the optimization to solve the energy issue of cloud computing. Actually, the optimization technique, which is convex optimization, is coupled with the proposed prediction method to produce a near-optimal set of hosting physical machines. After that, a corresponding migrating instruction can be created eventually. Based on this instruction, the cloud orchestrator can suitably relocate virtual machines to a designed subset of infrastructure. Subsequently, the idle physical servers can be turned off in an appropriate manner to save the power as well as maintain the system performance. For the purpose of evaluation, an experiment is conducted based on 29-day period of Google traces. By utilizing this evaluation, the proposed approach shows the potential to significantly reduce the power consumption without affecting the quality of services.},
booktitle = {Proceedings of the 12th International Conference on Ubiquitous Information Management and Communication},
articleno = {93},
numpages = {6},
keywords = {Energy Efficiency, Cloud Computing, Predictive Analysis, Convex Optimization, IaaS},
location = {Langkawi, Malaysia},
series = {IMCOM '18}
}

